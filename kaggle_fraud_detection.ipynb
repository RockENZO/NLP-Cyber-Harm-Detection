{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c666a435",
   "metadata": {},
   "source": [
    "# üöÄ Multiclass Fraud Detection Training on Kaggle\n",
    "\n",
    "This notebook is optimized for Kaggle's environment with GPU acceleration and **multiclass classification**.\n",
    "\n",
    "## üìä Dataset\n",
    "- Upload your `final_fraud_detection_dataset.csv`\n",
    "- **NEW: Supports 10-class classification** (9 scam types + legitimate)\n",
    "- Classes: `legitimate`, `phishing`, `popup_scam`, `sms_spam`, `reward_scam`, `tech_support_scam`, `refund_scam`, `ssn_scam`, `job_scam`\n",
    "\n",
    "## üéØ Models\n",
    "- Traditional ML: TF-IDF + Logistic Regression/SVM (multiclass)\n",
    "- Deep Learning: BERT-based classifier (10 classes)\n",
    "\n",
    "## ‚ö° Kaggle Advantages\n",
    "- Free GPU access (Tesla P100)\n",
    "- Pre-installed ML libraries\n",
    "- Easy dataset upload\n",
    "- Community sharing\n",
    "\n",
    "## üé™ Multiclass Benefits\n",
    "- **Granular fraud detection**: Identify specific scam types\n",
    "- **Better actionable insights**: Know which type of fraud to defend against\n",
    "- **Improved model interpretability**: Understand fraud patterns by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbf1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages if needed\n",
    "!pip install transformers torch --quiet\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Environment ready!\")\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa379cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "try:\n",
    "    df = pd.read_csv('/kaggle/input/fraud-detection-dataset/final_fraud_detection_dataset.csv')\n",
    "    print(f\"‚úÖ Dataset loaded: {len(df)} samples\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    print(f\"Label distribution: {df['binary_label'].value_counts()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Dataset not found. Please upload your CSV file.\")\n",
    "    # Create sample data for demonstration\n",
    "    print(\"üìù Using sample data instead...\")\n",
    "    # [Sample data creation code here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537538ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing for MULTICLASS classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Use detailed_category for multiclass classification (10 classes)\n",
    "print(\"üìä Dataset Overview:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Classes available: {df['detailed_category'].unique()}\")\n",
    "print(f\"Class distribution:\\n{df['detailed_category'].value_counts()}\")\n",
    "\n",
    "# Split data using detailed_category for multiclass\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['detailed_category'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['detailed_category']\n",
    ")\n",
    "\n",
    "print(f\"\\nüîÑ Data Split:\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(f\"Training class distribution:\\n{y_train.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF features: {X_train_tfidf.shape[1]}\")\n",
    "print(\"‚úÖ Text vectorization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143abe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train traditional ML models for MULTICLASS classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Encode labels for multiclass (10 classes)\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "print(f\"üìã Label encoding:\")\n",
    "print(f\"Number of classes: {len(le.classes_)}\")\n",
    "print(f\"Classes: {le.classes_}\")\n",
    "\n",
    "# Logistic Regression for multiclass\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=42, \n",
    "    max_iter=1000,  # Increased iterations for multiclass\n",
    "    multi_class='ovr'  # One-vs-Rest for multiclass\n",
    ")\n",
    "lr_model.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "# SVM for multiclass\n",
    "svm_model = SVC(\n",
    "    kernel='linear', \n",
    "    probability=True, \n",
    "    random_state=42,\n",
    "    decision_function_shape='ovr'  # One-vs-Rest for multiclass\n",
    ")\n",
    "svm_model.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "print(\"‚úÖ Multiclass models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329eb2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MULTICLASS models\n",
    "models = {'Logistic Regression': lr_model, 'SVM': svm_model}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    print(f\"\\nüîç {name} Results (Multiclass):\")\n",
    "    print(classification_report(y_test_encoded, y_pred, target_names=le.classes_))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test_encoded, y_pred)\n",
    "    print(f\"\\nConfusion Matrix shape: {cm.shape}\")\n",
    "    print(\"Note: Full confusion matrix too large to display completely\")\n",
    "    \n",
    "    # Show accuracy for each class\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "    f1_macro = f1_score(y_test_encoded, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_test_encoded, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"üìä Overall Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f8bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Training for MULTICLASS classification (GPU accelerated)\n",
    "import torch\n",
    "from transformers import (\n",
    "    BertTokenizer, BertForSequenceClassification,\n",
    "    AdamW, get_linear_schedule_with_warmup\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FraudDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])\n",
    "        label = self.labels.iloc[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"üöÄ Initializing BERT for MULTICLASS classification...\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# IMPORTANT: Change num_labels to 10 for multiclass (9 scam types + 1 legitimate)\n",
    "num_classes = len(le.classes_)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased', \n",
    "    num_labels=num_classes\n",
    ")\n",
    "\n",
    "# Move to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"üéØ Multiclass setup: {num_classes} classes\")\n",
    "print(f\"Classes: {', '.join(le.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcfc7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare BERT datasets\n",
    "train_dataset = FraudDataset(X_train, y_train_encoded, tokenizer)\n",
    "test_dataset = FraudDataset(X_test, y_test_encoded, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Testing batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467170ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for MULTICLASS BERT\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(train_loader) * 3\n",
    ")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    print(f\"\\nüöÄ Epoch {epoch + 1}/3\")\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        # CrossEntropyLoss handles multiclass automatically\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Average loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"‚úÖ BERT multiclass training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee94c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate BERT MULTICLASS model\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        \n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.numpy())\n",
    "\n",
    "print(\"\\nüéØ BERT Multiclass Evaluation Results:\")\n",
    "print(classification_report(true_labels, predictions, target_names=le.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "print(f\"\\nConfusion Matrix shape: {cm.shape}\")\n",
    "\n",
    "# Overall metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1_macro = f1_score(true_labels, predictions, average='macro')\n",
    "f1_weighted = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(f\"\\nüìä BERT Overall Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-Score (Weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "# Show per-class performance\n",
    "print(f\"\\nüè∑Ô∏è Per-Class F1 Scores:\")\n",
    "f1_per_class = f1_score(true_labels, predictions, average=None)\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    print(f\"{class_name}: {f1_per_class[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1429ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models for download\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('/kaggle/working/models', exist_ok=True)\n",
    "\n",
    "# Save traditional ML models\n",
    "joblib.dump(lr_model, '/kaggle/working/models/logistic_regression.pkl')\n",
    "joblib.dump(svm_model, '/kaggle/working/models/svm.pkl')\n",
    "joblib.dump(tfidf, '/kaggle/working/models/tfidf_vectorizer.pkl')\n",
    "joblib.dump(le, '/kaggle/working/models/label_encoder.pkl')\n",
    "\n",
    "# Save BERT model\n",
    "model.save_pretrained('/kaggle/working/models/bert_model')\n",
    "tokenizer.save_pretrained('/kaggle/working/models/bert_tokenizer')\n",
    "\n",
    "print(\"üíæ Models saved to /kaggle/working/models/\")\n",
    "print(\"Download them from the Output tab!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb693577",
   "metadata": {},
   "source": [
    "# üìä Results Summary\n",
    "\n",
    "## üéØ Performance Comparison\n",
    "- Compare all models' F1-scores, precision, and recall\n",
    "- BERT typically performs best but requires more resources\n",
    "\n",
    "## üí° Next Steps\n",
    "1. **Download Models**: Get your trained models from the Output tab\n",
    "2. **Deploy**: Use the saved models in production\n",
    "3. **Experiment**: Try different hyperparameters\n",
    "4. **Share**: Publish your notebook to Kaggle community\n",
    "\n",
    "## ‚ö° Kaggle Tips\n",
    "- Use GPU accelerator for faster training\n",
    "- Save models regularly to avoid losing progress\n",
    "- Monitor memory usage with large datasets\n",
    "- Use the Discussion forum for questions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
