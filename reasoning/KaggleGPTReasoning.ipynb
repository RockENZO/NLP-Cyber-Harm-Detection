{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages for local reasoning\n",
    "!pip install transformers torch accelerate --quiet\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ðŸš€ Fraud Detection Reasoning Environment Setup\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"âœ… GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ðŸŽ® GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ðŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸  Using CPU - consider enabling GPU accelerator\")\n",
    "\n",
    "print(\"âœ… Environment ready for local reasoning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# ðŸ§  Local Fraud Detection Reasoning on Kaggle\n",
    "\n",
    "This notebook provides **local AI-powered reasoning** for fraud detection using Kaggle's GPU resources instead of paid APIs.\n",
    "\n",
    "\n",
    "\n",
    "## ðŸ“Š Pipeline Flow\n",
    "1. **Upload** your trained DistilBERT model\n",
    "2. **Classify** texts into fraud categories  \n",
    "3. **Generate reasoning** using local LM for non-legitimate classifications\n",
    "4. **Download** results with explanations\n",
    "\n",
    "## ðŸ”§ Requirements\n",
    "- Upload your `distilbert_model/` and `distilbert_tokenizer/` folders from previous training\n",
    "- Enable GPU accelerator for faster inference\n",
    "- No API keys needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Load Local Language Model for Reasoning (Free Alternative to APIs)\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "print(\"ðŸ§  Loading Local Language Model for Reasoning...\")\n",
    "print(\"This replaces expensive API calls with free local inference!\")\n",
    "\n",
    "# Use a smaller, efficient model that works well on Kaggle's free tier\n",
    "# Options: 'microsoft/DialoGPT-medium', 'gpt2', 'distilgpt2'\n",
    "reasoning_model_name = \"microsoft/DialoGPT-medium\"  # Good balance of quality and speed\n",
    "\n",
    "try:\n",
    "    # Initialize reasoning pipeline\n",
    "    reasoning_pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=reasoning_model_name,\n",
    "        device=0 if torch.cuda.is_available() else -1,  # Use GPU if available\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        max_length=512,\n",
    "        pad_token_id=50256  # Set pad token to avoid warnings\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Local reasoning model loaded: {reasoning_model_name}\")\n",
    "    print(\"ðŸ’¡ This model will generate explanations locally (no API costs!)\")\n",
    "    \n",
    "    # Test the reasoning model\n",
    "    test_prompt = \"This text appears to be a scam because\"\n",
    "    test_response = reasoning_pipe(test_prompt, max_length=50, num_return_sequences=1)\n",
    "    print(\"ðŸ§ª Model test successful!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Error loading model: {e}\")\n",
    "    print(\"Falling back to simpler model...\")\n",
    "    # Fallback to smaller model\n",
    "    reasoning_pipe = pipeline(\"text-generation\", model=\"distilgpt2\", device=0 if torch.cuda.is_available() else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Load Your Trained DistilBERT Fraud Detection Model\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "print(\"ðŸ“¦ Loading Your Trained DistilBERT Model...\")\n",
    "\n",
    "# Update these paths to match where you uploaded your models\n",
    "MODEL_PATH = '/kaggle/input/your-fraud-models/distilbert_model'  # Update this path\n",
    "TOKENIZER_PATH = '/kaggle/input/your-fraud-models/distilbert_tokenizer'  # Update this path\n",
    "\n",
    "# Class labels (must match your training - alphabetical order)\n",
    "CLASS_LABELS = [\n",
    "    'job_scam',\n",
    "    'legitimate', \n",
    "    'phishing',\n",
    "    'popup_scam',\n",
    "    'refund_scam',\n",
    "    'reward_scam',\n",
    "    'sms_spam',\n",
    "    'ssn_scam',\n",
    "    'tech_support_scam'\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Load your trained model and tokenizer\n",
    "    fraud_tokenizer = DistilBertTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "    fraud_model = DistilBertForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "    \n",
    "    # Move to GPU for faster inference\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    fraud_model.to(device)\n",
    "    fraud_model.eval()\n",
    "    \n",
    "    print(f\"âœ… DistilBERT model loaded successfully!\")\n",
    "    print(f\"ðŸŽ¯ Device: {device}\")\n",
    "    print(f\"ðŸ“‹ Classes: {len(CLASS_LABELS)} fraud types + legitimate\")\n",
    "    print(f\"ðŸ·ï¸  Labels: {CLASS_LABELS}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Model files not found!\")\n",
    "    print(\"ðŸ“ Please upload your trained model files to Kaggle:\")\n",
    "    print(\"   1. Upload 'distilbert_model/' folder\")\n",
    "    print(\"   2. Upload 'distilbert_tokenizer/' folder\") \n",
    "    print(\"   3. Update MODEL_PATH and TOKENIZER_PATH above\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# ðŸ”§ Local Reasoning Engine Configuration\n",
    "\n",
    "This section sets up the local reasoning engine that generates explanations for fraud classifications using the language model we loaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Local Reasoning Engine Configuration\n",
    "class LocalFraudReasoningEngine:\n",
    "    \"\"\"\n",
    "    Local reasoning engine that generates explanations without API calls\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, reasoning_pipeline):\n",
    "        self.reasoning_pipe = reasoning_pipeline\n",
    "        self.min_confidence = 0.5\n",
    "        \n",
    "        # Scam type descriptions for better reasoning\n",
    "        self.scam_descriptions = {\n",
    "            'phishing': {\n",
    "                'description': 'Attempts to steal sensitive information like passwords, credit card numbers, or personal data',\n",
    "                'indicators': ['urgent action required', 'verify account', 'click here', 'suspicious links', 'fake sender']\n",
    "            },\n",
    "            'popup_scam': {\n",
    "                'description': 'Fake popup messages claiming virus infections or system issues',\n",
    "                'indicators': ['virus detected', 'system error', 'immediate action', 'fake technical alerts']\n",
    "            },\n",
    "            'sms_spam': {\n",
    "                'description': 'Unwanted promotional or fraudulent text messages',\n",
    "                'indicators': ['unsolicited offers', 'prize claims', 'urgent responses', 'suspicious phone numbers']\n",
    "            },\n",
    "            'reward_scam': {\n",
    "                'description': 'False promises of rewards, prizes, or free items',\n",
    "                'indicators': ['congratulations', 'you have won', 'free gift', 'claim now', 'limited time']\n",
    "            },\n",
    "            'tech_support_scam': {\n",
    "                'description': 'Fake technical support claiming to fix computer problems',\n",
    "                'indicators': ['computer infected', 'microsoft support', 'remote access', 'technical issues']\n",
    "            },\n",
    "            'refund_scam': {\n",
    "                'description': 'Fake refund notifications or requests for payment information',\n",
    "                'indicators': ['refund available', 'payment failed', 'update payment', 'billing issue']\n",
    "            },\n",
    "            'ssn_scam': {\n",
    "                'description': 'Attempts to steal Social Security Numbers or similar personal identifiers',\n",
    "                'indicators': ['SSN verification', 'social security', 'identity verification', 'government agency']\n",
    "            },\n",
    "            'job_scam': {\n",
    "                'description': 'Fake job offers or employment opportunities',\n",
    "                'indicators': ['work from home', 'easy money', 'no experience required', 'guaranteed income']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.stats = {\n",
    "            'total_processed': 0,\n",
    "            'reasoning_generated': 0,\n",
    "            'skipped_legitimate': 0,\n",
    "            'skipped_low_confidence': 0\n",
    "        }\n",
    "        \n",
    "    def should_generate_reasoning(self, predicted_label, confidence):\n",
    "        \"\"\"Determine if reasoning should be generated\"\"\"\n",
    "        return predicted_label != 'legitimate' and confidence >= self.min_confidence\n",
    "    \n",
    "    def generate_local_reasoning(self, text, predicted_label, confidence, all_predictions):\n",
    "        \"\"\"Generate enhanced reasoning using local language model\"\"\"\n",
    "        scam_info = self.scam_descriptions.get(predicted_label, {\n",
    "            'description': 'Unknown scam type',\n",
    "            'indicators': []\n",
    "        })\n",
    "        \n",
    "        # Enhanced reasoning without relying on language model generation\n",
    "        # Analyze text content directly\n",
    "        text_lower = text.lower()\n",
    "        detected_indicators = []\n",
    "        \n",
    "        # Check for specific indicators in the text\n",
    "        for indicator in scam_info['indicators']:\n",
    "            if any(word in text_lower for word in indicator.split()):\n",
    "                detected_indicators.append(indicator)\n",
    "        \n",
    "        # Add common fraud patterns\n",
    "        urgent_words = ['urgent', 'immediate', 'now', 'quickly', 'hurry', 'expires']\n",
    "        if any(word in text_lower for word in urgent_words):\n",
    "            detected_indicators.append('urgent language to pressure victims')\n",
    "            \n",
    "        money_words = ['$', 'money', 'prize', 'won', 'claim', 'free', 'gift']\n",
    "        if any(word in text_lower for word in money_words):\n",
    "            detected_indicators.append('financial incentives or rewards')\n",
    "            \n",
    "        action_words = ['click', 'call', 'text', 'visit', 'send', 'verify']\n",
    "        if any(word in text_lower for word in action_words):\n",
    "            detected_indicators.append('requests for immediate action')\n",
    "            \n",
    "        suspicious_elements = ['suspicious links', 'phone numbers', 'email addresses']\n",
    "        if 'http' in text_lower or '@' in text_lower or any(char.isdigit() for char in text):\n",
    "            detected_indicators.append('suspicious contact information')\n",
    "        \n",
    "        # Create comprehensive reasoning\n",
    "        reasoning_parts = []\n",
    "        reasoning_parts.append(f\"This text was classified as {predicted_label} with {confidence:.1%} confidence.\")\n",
    "        reasoning_parts.append(f\"\\n{scam_info['description']}\")\n",
    "        \n",
    "        if detected_indicators:\n",
    "            reasoning_parts.append(f\"\\nKey fraud indicators detected:\")\n",
    "            for i, indicator in enumerate(detected_indicators[:4], 1):  # Limit to top 4\n",
    "                reasoning_parts.append(f\"â€¢ {indicator}\")\n",
    "        \n",
    "        # Add context about why this is dangerous\n",
    "        danger_context = {\n",
    "            'phishing': 'This could lead to identity theft and financial loss.',\n",
    "            'sms_spam': 'This could lead to unwanted charges and privacy violations.',\n",
    "            'reward_scam': 'This could lead to financial scams and personal data theft.',\n",
    "            'tech_support_scam': 'This could lead to remote access scams and financial fraud.',\n",
    "            'job_scam': 'This could lead to advance fee fraud and identity theft.',\n",
    "            'popup_scam': 'This could lead to malware installation and system compromise.',\n",
    "            'refund_scam': 'This could lead to payment fraud and account takeover.',\n",
    "            'ssn_scam': 'This could lead to identity theft and government impersonation fraud.'\n",
    "        }\n",
    "        \n",
    "        if predicted_label in danger_context:\n",
    "            reasoning_parts.append(f\"\\nâš ï¸ Risk: {danger_context[predicted_label]}\")\n",
    "        \n",
    "        # Add confidence context\n",
    "        if confidence > 0.9:\n",
    "            reasoning_parts.append(f\"\\nHigh confidence ({confidence:.1%}) indicates strong fraud patterns.\")\n",
    "        elif confidence > 0.7:\n",
    "            reasoning_parts.append(f\"Moderate confidence ({confidence:.1%}) suggests probable fraud patterns.\")\n",
    "        \n",
    "        return '\\n'.join(reasoning_parts)\n",
    "\n",
    "# Initialize the local reasoning engine\n",
    "local_reasoning_engine = LocalFraudReasoningEngine(reasoning_pipe)\n",
    "print(\"âœ… Local reasoning engine initialized with enhanced analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Fraud Classification and Reasoning Functions\n",
    "def classify_text(text, max_length=128):\n",
    "    \"\"\"Classify text using the loaded DistilBERT model\"\"\"\n",
    "    if fraud_model is None:\n",
    "        # Return sample prediction for demo\n",
    "        return {\n",
    "            'text': text,\n",
    "            'predicted_label': 'phishing',\n",
    "            'confidence': 0.92,\n",
    "            'all_predictions': {\n",
    "                'phishing': 0.92, 'legitimate': 0.04, 'popup_scam': 0.02,\n",
    "                'reward_scam': 0.01, 'tech_support_scam': 0.01\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Tokenize input\n",
    "    encoding = fraud_tokenizer(\n",
    "        text,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = fraud_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "        predicted_class_id = np.argmax(probabilities)\n",
    "    \n",
    "    # Format results\n",
    "    predicted_label = CLASS_LABELS[predicted_class_id]\n",
    "    confidence = float(probabilities[predicted_class_id])\n",
    "    \n",
    "    all_predictions = {\n",
    "        CLASS_LABELS[i]: float(probabilities[i]) \n",
    "        for i in range(len(CLASS_LABELS))\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'predicted_label': predicted_label,\n",
    "        'confidence': confidence,\n",
    "        'all_predictions': all_predictions\n",
    "    }\n",
    "\n",
    "def analyze_with_local_reasoning(text):\n",
    "    \"\"\"Complete analysis: classification + local reasoning\"\"\"\n",
    "    # Step 1: Classify the text\n",
    "    classification_result = classify_text(text)\n",
    "    \n",
    "    # Step 2: Generate local reasoning (only for non-legitimate classifications)\n",
    "    if local_reasoning_engine.should_generate_reasoning(\n",
    "        classification_result['predicted_label'], \n",
    "        classification_result['confidence']\n",
    "    ):\n",
    "        reasoning = local_reasoning_engine.generate_local_reasoning(\n",
    "            text=classification_result['text'],\n",
    "            predicted_label=classification_result['predicted_label'],\n",
    "            confidence=classification_result['confidence'],\n",
    "            all_predictions=classification_result['all_predictions']\n",
    "        )\n",
    "        \n",
    "        local_reasoning_engine.stats['reasoning_generated'] += 1\n",
    "        skip_reason = None\n",
    "        reasoning_generated = True\n",
    "    else:\n",
    "        if classification_result['predicted_label'] == 'legitimate':\n",
    "            skip_reason = 'legitimate_classification'\n",
    "            local_reasoning_engine.stats['skipped_legitimate'] += 1\n",
    "        else:\n",
    "            skip_reason = f\"low_confidence_{classification_result['confidence']:.2f}\"\n",
    "            local_reasoning_engine.stats['skipped_low_confidence'] += 1\n",
    "        \n",
    "        reasoning = None\n",
    "        reasoning_generated = False\n",
    "    \n",
    "    local_reasoning_engine.stats['total_processed'] += 1\n",
    "    \n",
    "    return {\n",
    "        **classification_result,\n",
    "        'reasoning': reasoning,\n",
    "        'reasoning_generated': reasoning_generated,\n",
    "        'skip_reason': skip_reason,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "def print_analysis_result(result):\n",
    "    \"\"\"Pretty print analysis result\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ” LOCAL FRAUD DETECTION + REASONING ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nðŸ“ Original Text:\")\n",
    "    print(f\"   {result['text']}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Classification:\")\n",
    "    print(f\"   Label: {result['predicted_label']}\")\n",
    "    print(f\"   Confidence: {result['confidence']:.2%}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š All Predictions:\")\n",
    "    for label, prob in sorted(result['all_predictions'].items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   {label}: {prob:.2%}\")\n",
    "    \n",
    "    if result['reasoning_generated']:\n",
    "        print(f\"\\nðŸ§  Local AI Reasoning:\")\n",
    "        print(\"   \" + result['reasoning'].replace('\\n', '\\n   '))\n",
    "    else:\n",
    "        print(f\"\\nâ­ï¸  Reasoning Skipped: {result['skip_reason']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "print(\"âœ… Classification and reasoning functions ready!\")\n",
    "print(\"ðŸš€ Ready to analyze texts with local AI reasoning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§ª Sample Tests - Try Different Fraud Types\n",
    "\n",
    "Let's test the local reasoning system with various types of fraudulent and legitimate messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Sample Test Cases for Different Fraud Types\n",
    "sample_texts = [\n",
    "    {\n",
    "        'category': 'Phishing Attack',\n",
    "        'text': \"URGENT: Your PayPal account has been suspended due to suspicious activity. Click here immediately to verify your information and restore access: http://paypal-verification-secure.fraudsite.com\"\n",
    "    },\n",
    "    {\n",
    "        'category': 'Tech Support Scam', \n",
    "        'text': \"WARNING: Your computer is infected with 5 viruses! Your files will be deleted in 24 hours. Call Microsoft Support immediately at 1-800-555-SCAM. Don't restart your computer or you'll lose everything!\"\n",
    "    },\n",
    "    {\n",
    "        'category': 'Reward Scam',\n",
    "        'text': \"ðŸŽ‰ CONGRATULATIONS! ðŸŽ‰ You've been selected as our LUCKY WINNER for a $1000 Amazon gift card! You're one of only 3 winners today! Claim your prize now by clicking this link and entering your credit card info for verification. Hurry, expires in 1 hour!\"\n",
    "    },\n",
    "    {\n",
    "        'category': 'Job Scam',\n",
    "        'text': \"Amazing work from home opportunity! Earn $5000/week working just 2 hours per day! No experience required! Just send $99 registration fee and start earning today! Guaranteed income or money back!\"\n",
    "    },\n",
    "    {\n",
    "        'category': 'SMS Spam',\n",
    "        'text': \"FREE iPhone 15 Pro! You have been randomly selected as a winner. Text CLAIM to 12345 or visit bit.ly/freeiphone15winner to get your prize. Message and data rates may apply. Text STOP to opt out.\"\n",
    "    },\n",
    "    {\n",
    "        'category': 'Legitimate Message',\n",
    "        'text': \"Hi Sarah, thank you for your order #12345. Your package has been shipped and will arrive within 3-5 business days. You can track your shipment using the tracking number provided in your confirmation email. Have a great day!\"\n",
    "    },\n",
    "    {\n",
    "        'category': 'SSN Scam',\n",
    "        'text': \"IMPORTANT NOTICE: Your Social Security Number has been suspended due to suspicious illegal activity. Call the SSA office immediately at 1-800-555-FAKE to verify your identity and reactivate your SSN. Failure to respond will result in arrest.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ðŸ§ª Testing Local AI Reasoning on Sample Fraud Types\")\n",
    "\n",
    "for i, sample in enumerate(sample_texts):\n",
    "    print(f\"\\nðŸŽ¯ Test {i+1}: {sample['category']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    result = analyze_with_local_reasoning(sample['text'])\n",
    "    print_analysis_result(result)\n",
    "\n",
    "print(f\"\\nðŸ“Š Summary:\")\n",
    "print(f\"Total Processed: {local_reasoning_engine.stats['total_processed']}\")\n",
    "print(f\"Reasoning Generated: {local_reasoning_engine.stats['reasoning_generated']}\")\n",
    "print(f\"Legitimate (Skipped): {local_reasoning_engine.stats['skipped_legitimate']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ Interactive Text Analysis\n",
    "\n",
    "Enter your own text below to analyze with the local fraud detection + reasoning system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Interactive Text Analysis\n",
    "# Change the text below to analyze your own messages!\n",
    "\n",
    "your_text = \"Congratulations! You've won $1 million! Send your bank details to claim your prize!\"\n",
    "\n",
    "# Analyze your custom text\n",
    "print(\"ðŸ” Analyzing Your Custom Text...\")\n",
    "custom_result = analyze_with_local_reasoning(your_text.strip())\n",
    "print_analysis_result(custom_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Batch Processing - Analyze Multiple Texts\n",
    "\n",
    "Upload a CSV file or analyze multiple texts at once with local reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Batch Processing with Local Reasoning\n",
    "def batch_analyze_texts(texts, save_results=True):\n",
    "    \"\"\"Analyze multiple texts and generate local reasoning\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"ðŸ”„ Processing {len(texts)} texts...\")\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        if i % 5 == 0:  # Only print every 5th item to reduce clutter\n",
    "            print(f\"Progress: {i+1}/{len(texts)}\")\n",
    "        \n",
    "        result = analyze_with_local_reasoning(text)\n",
    "        results.append(result)\n",
    "        \n",
    "        # Small delay to avoid overwhelming the local model\n",
    "        time.sleep(0.2)\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    df_results = pd.DataFrame([\n",
    "        {\n",
    "            'text': r['text'][:100] + '...' if len(r['text']) > 100 else r['text'],\n",
    "            'predicted_label': r['predicted_label'],\n",
    "            'confidence': r['confidence'],\n",
    "            'reasoning_generated': r['reasoning_generated'],\n",
    "            'reasoning': r['reasoning'][:200] + '...' if r['reasoning'] and len(r['reasoning']) > 200 else r['reasoning'],\n",
    "            'timestamp': r['timestamp']\n",
    "        }\n",
    "        for r in results\n",
    "    ])\n",
    "    \n",
    "    if save_results:\n",
    "        # Save results to CSV\n",
    "        output_file = f'fraud_analysis_results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "        df_results.to_csv(output_file, index=False)\n",
    "        print(f\"ðŸ’¾ Results saved to: {output_file}\")\n",
    "    \n",
    "    return results, df_results\n",
    "\n",
    "# Example batch processing\n",
    "batch_texts = [\n",
    "    \"Your account will be closed unless you verify immediately!\",\n",
    "    \"Hi John, thanks for the great meeting today. Let's follow up next week.\",\n",
    "    \"You've won a free vacation! Call now to claim your prize!\",\n",
    "    \"Your package has been delivered to your front door.\",\n",
    "    \"URGENT: Your social security number has been compromised!\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ“Š Batch Analysis with Local Reasoning\")\n",
    "batch_results, batch_df = batch_analyze_texts(batch_texts)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Batch Analysis Summary:\")\n",
    "fraud_count = (batch_df['predicted_label'] != 'legitimate').sum()\n",
    "reasoning_count = batch_df['reasoning_generated'].sum()\n",
    "print(f\"Fraud detected: {fraud_count}/{len(batch_df)}\")\n",
    "print(f\"Reasoning generated: {reasoning_count}/{len(batch_df)}\")\n",
    "\n",
    "# Display sample results\n",
    "display(batch_df.head())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
