{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9ac30c",
   "metadata": {},
   "source": [
    "# ðŸ§  Unified Classification + Reasoning (FLANâ€‘T5) â€” Kaggle Training Notebook\n",
    "\n",
    "> This notebook fine-tunes a FLANâ€‘T5 model to output both a fraud label and a short explanation in a single generation, using your compiled dataset.\n",
    "\n",
    "It mirrors `training/unified_t5_fraud.py` but is optimized for Kaggle. Make sure your CSV is provided as a Kaggle dataset input (e.g., `/kaggle/input/fraud-data/final_fraud_detection_dataset.csv`).\n",
    "\n",
    "Tip: Early stopping is enabled by a loss threshold. Adjust `EARLY_STOP_LOSS` (and `MIN_EPOCHS`) in the config cell to stop training once `eval_loss` is small enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dda46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Detect Kaggle Environment and Set Paths\n",
    "import os, glob, json, sys\n",
    "from pathlib import Path\n",
    "\n",
    "IS_KAGGLE = Path('/kaggle').exists()\n",
    "INPUT_DIR = Path('/kaggle/input') if IS_KAGGLE else Path('..')\n",
    "WORK_DIR = Path('/kaggle/working') if IS_KAGGLE else Path('.')\n",
    "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Running on Kaggle: {IS_KAGGLE}\")\n",
    "print(f\"INPUT_DIR: {INPUT_DIR}\")\n",
    "print(f\"WORK_DIR: {WORK_DIR}\")\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    print(\"\\nAvailable datasets under /kaggle/input:\")\n",
    "    for p in sorted(INPUT_DIR.glob('*')):\n",
    "        print(' -', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Import and (Optionally) Install Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import transformers as tf\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "import inspect\n",
    "\n",
    "print('PyTorch:', torch.__version__)\n",
    "print('Transformers:', tf.__version__)\n",
    "device = 'cuda' if torch.cuda.is_available() else ('mps' if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1fefc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Configuration (Seeds, Paths, Target, Problem Type)\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Point to your fraud dataset CSV under /kaggle/input\n",
    "# Adjust this path based on your dataset name\n",
    "CSV_PATH = INPUT_DIR / 'fraud-data' / 'final_fraud_detection_dataset.csv'\n",
    "if not CSV_PATH.exists():\n",
    "    # Fallback guess: sometimes users rename the dataset folder\n",
    "    matches = list(INPUT_DIR.glob('**/final_fraud_detection_dataset.csv'))\n",
    "    if matches:\n",
    "        CSV_PATH = matches[0]\n",
    "print('CSV_PATH:', CSV_PATH)\n",
    "\n",
    "TEXT_COL = 'text'\n",
    "LABEL_COL = 'detailed_category'\n",
    "\n",
    "DEFAULT_LABELS = [\n",
    "    'job_scam',\n",
    "    'legitimate',\n",
    "    'phishing',\n",
    "    'popup_scam',\n",
    "    'refund_scam',\n",
    "    'reward_scam',\n",
    "    'sms_spam',\n",
    "    'ssn_scam',\n",
    "    'tech_support_scam'\n",
    "]\n",
    "\n",
    "MODEL_NAME = 'google/flan-t5-small'\n",
    "OUTPUT_DIR = WORK_DIR / 'unified-flan-t5-small'\n",
    "MAX_SOURCE_LENGTH = 256\n",
    "MAX_TARGET_LENGTH = 64\n",
    "TRAIN_SIZE = 0.9\n",
    "NUM_EPOCHS = 3\n",
    "LR = 3e-4\n",
    "BATCH_TRAIN = 8\n",
    "BATCH_EVAL = 8\n",
    "GRAD_ACCUM = 1\n",
    "\n",
    "# Early stopping when eval_loss is small enough\n",
    "EARLY_STOP_LOSS = 0.025   # stop training once eval_loss <= this threshold\n",
    "MIN_EPOCHS = 1           # do not stop before this many epochs\n",
    "\n",
    "INSTRUCTION_PREFIX = (\n",
    "    \"Classify the message into one of these categories and explain briefly:\\n\"\n",
    "    \"Categories: job_scam, legitimate, phishing, popup_scam, refund_scam, reward_scam, sms_spam, ssn_scam, tech_support_scam\\n\"\n",
    "    \"Message: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270417da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Load Data from /kaggle/input\n",
    "assert CSV_PATH.exists(), f\"CSV not found at {CSV_PATH}. Attach your dataset to the notebook.\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print('Loaded:', df.shape)\n",
    "print(df.head(3))\n",
    "\n",
    "# Filter to known labels only\n",
    "df = df[df[LABEL_COL].isin(DEFAULT_LABELS)].copy()\n",
    "print('After label filtering:', df.shape)\n",
    "\n",
    "# 5) Basic Data Checks\n",
    "assert TEXT_COL in df.columns and LABEL_COL in df.columns, 'Missing required columns'\n",
    "print('Columns:', list(df.columns))\n",
    "print('Label distribution:')\n",
    "print(df[LABEL_COL].value_counts())\n",
    "\n",
    "# Train/Validation split (stratified)\n",
    "train_df, val_df = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=SEED, stratify=df[LABEL_COL])\n",
    "print('Train:', train_df.shape, 'Val:', val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16479f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Build Targets: label + short reason\n",
    "def default_reason_for_label(label: str) -> str:\n",
    "    templates = {\n",
    "        'legitimate': \"Message content appears normal and lacks scam indicators.\",\n",
    "        'phishing': \"Contains credential-stealing cues (links/requests for login or personal info).\",\n",
    "        'tech_support_scam': \"Mentions fake support, urgent fixes, or remote access.\",\n",
    "        'reward_scam': \"Promises winnings/prizes with urgency or fees.\",\n",
    "        'job_scam': \"Unrealistic job offers, upfront payments, or unsolicited interviews.\",\n",
    "        'sms_spam': \"Unwanted promotional or bulk messaging characteristics.\",\n",
    "        'popup_scam': \"Fake security alerts/popups demanding immediate action.\",\n",
    "        'refund_scam': \"Unexpected refund/chargeback claims with links or callbacks.\",\n",
    "        'ssn_scam': \"Requests social security info or threats about your SSN.\",\n",
    "    }\n",
    "    return templates.get(label, \"Heuristic cues indicate this category.\")\n",
    "\n",
    "def build_target(label: str, text: str, reason: str = None) -> str:\n",
    "    if not reason or not isinstance(reason, str) or len(reason.strip()) == 0:\n",
    "        reason = default_reason_for_label(label)\n",
    "    return f\"label: {label} | reason: {reason}\"\n",
    "\n",
    "def make_examples(df, text_col: str, label_col: str):\n",
    "    examples = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = str(row[text_col])\n",
    "        label = str(row[label_col])\n",
    "        examples.append({\n",
    "            'source': f\"{INSTRUCTION_PREFIX}{text}\",\n",
    "            'target': build_target(label, text),\n",
    "        })\n",
    "    return examples\n",
    "\n",
    "train_examples = make_examples(train_df, TEXT_COL, LABEL_COL)\n",
    "val_examples = make_examples(val_df, TEXT_COL, LABEL_COL)\n",
    "print('Examples:', len(train_examples), len(val_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Tokenizer and Simple Dataset Wrappers\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "model.to(device)\n",
    "\n",
    "class SimpleMapDataset:\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.examples[idx]\n",
    "        model_inputs = tokenizer(\n",
    "            e['source'],\n",
    "            max_length=MAX_SOURCE_LENGTH,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    ")\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(\n",
    "                e['target'],\n",
    "                max_length=MAX_TARGET_LENGTH,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    ")\n",
    "        model_inputs['labels'] = labels['input_ids']\n",
    "        return model_inputs\n",
    "\n",
    "train_ds = SimpleMapDataset(train_examples)\n",
    "val_ds = SimpleMapDataset(val_examples)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a8f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) TrainingArguments, Trainer, and Metrics\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def extract_label_from_text(text: str) -> str:\n",
    "    t = \" \".join(str(text).strip().lower().split())\n",
    "    if 'label:' in t:\n",
    "        after = t.split('label:', 1)[1].strip()\n",
    "        if '|' in after:\n",
    "            after = after.split('|', 1)[0].strip()\n",
    "        return \" \".join(after.split()[:5])\n",
    "    return 'unknown'\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred: Any):\n",
    "    # Support both (preds, labels) tuple and EvalPrediction object\n",
    "    preds = getattr(eval_pred, 'predictions', None)\n",
    "    labels_ids = getattr(eval_pred, 'label_ids', None)\n",
    "    if preds is None or labels_ids is None:\n",
    "        preds, labels_ids = eval_pred\n",
    "    pred_texts = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels_ids = [[(lid if lid != -100 else tokenizer.pad_token_id) for lid in seq] for seq in labels_ids]\n",
    "    gold_texts = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    pred_labels = [extract_label_from_text(t) for t in pred_texts]\n",
    "    gold_labels = [extract_label_from_text(t) for t in gold_texts]\n",
    "    canon = set(DEFAULT_LABELS)\n",
    "\n",
    "    def canonize(s: str) -> str:\n",
    "        s = s.strip()\n",
    "        if s in canon:\n",
    "            return s\n",
    "        for c in canon:\n",
    "            if s in c or c in s:\n",
    "                return c\n",
    "        return s\n",
    "\n",
    "    pred_labels = [canonize(x) for x in pred_labels]\n",
    "    gold_labels = [canonize(x) for x in gold_labels]\n",
    "    acc = accuracy_score(gold_labels, pred_labels)\n",
    "    return {'label_accuracy': acc}\n",
    "\n",
    "\n",
    "# Custom early-stopping callback based on absolute eval_loss threshold\n",
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "\n",
    "class LossThresholdEarlyStop(TrainerCallback):\n",
    "    def __init__(self, threshold: float, min_epochs: int = 0):\n",
    "        self.threshold = float(threshold)\n",
    "        self.min_epochs = int(min_epochs)\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        metrics = kwargs.get('metrics') or {}\n",
    "        eval_loss = metrics.get('eval_loss')\n",
    "        # Only consider stopping after completing at least min_epochs\n",
    "        current_epoch = state.epoch or 0\n",
    "        if eval_loss is not None and current_epoch >= self.min_epochs:\n",
    "            if eval_loss <= self.threshold:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Early stopping triggered: eval_loss={eval_loss:.4f} <= threshold={self.threshold} (epoch={current_epoch})\")\n",
    "        return control\n",
    "\n",
    "\n",
    "# Build TrainingArguments robustly against Transformers version changes\n",
    "args_dict = {\n",
    "    'output_dir': str(OUTPUT_DIR),\n",
    "    'learning_rate': LR,\n",
    "    'per_device_train_batch_size': BATCH_TRAIN,\n",
    "    'per_device_eval_batch_size': BATCH_EVAL,\n",
    "    'num_train_epochs': NUM_EPOCHS,\n",
    "    'weight_decay': 0.01,\n",
    "    'warmup_ratio': 0.05,\n",
    "    'logging_steps': 50,\n",
    "    'gradient_accumulation_steps': GRAD_ACCUM,\n",
    "    'report_to': ['none'],\n",
    "    'fp16': torch.cuda.is_available(),\n",
    "    'bf16': False,\n",
    "}\n",
    "\n",
    "sig = inspect.signature(TrainingArguments.__init__)\n",
    "if 'evaluation_strategy' in sig.parameters:\n",
    "    args_dict['evaluation_strategy'] = 'epoch'  # needed so on_evaluate fires regularly\n",
    "if 'save_strategy' in sig.parameters:\n",
    "    args_dict['save_strategy'] = 'epoch'\n",
    "if 'predict_with_generate' in sig.parameters:\n",
    "    args_dict['predict_with_generate'] = True\n",
    "if 'generation_max_length' in sig.parameters:\n",
    "    args_dict['generation_max_length'] = MAX_TARGET_LENGTH\n",
    "\n",
    "training_args = TrainingArguments(**args_dict)\n",
    "\n",
    "# Instantiate callback with configured threshold\n",
    "callbacks = [LossThresholdEarlyStop(threshold=EARLY_STOP_LOSS, min_epochs=MIN_EPOCHS)]\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Train\n",
    "trainer.train()\n",
    "trainer.save_model(str(OUTPUT_DIR))\n",
    "tokenizer.save_pretrained(str(OUTPUT_DIR))\n",
    "print('Model saved to:', OUTPUT_DIR)\n",
    "\n",
    "# Note: Training may stop early if eval_loss <= EARLY_STOP_LOSS after MIN_EPOCHS epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Quick Sanity Generation\n",
    "model.eval()\n",
    "sample_text = val_df.iloc[0][TEXT_COL] if len(val_df) else train_df.iloc[0][TEXT_COL]\n",
    "inputs = tokenizer([f\"{INSTRUCTION_PREFIX}{sample_text}\"], return_tensors='pt', truncation=True, padding=True).to(model.device)\n",
    "with torch.no_grad():\n",
    "    gen = model.generate(**inputs, max_new_tokens=64, do_sample=False)\n",
    "print('Input snippet:', sample_text[:120])\n",
    "print('Output:', tokenizer.decode(gen[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613345f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Zip Artifacts (Optional)\n",
    "import shutil\n",
    "ZIP_PATH = WORK_DIR / 'unified-flan-t5-small.zip'\n",
    "if ZIP_PATH.exists():\n",
    "    ZIP_PATH.unlink()\n",
    "shutil.make_archive(str(ZIP_PATH.with_suffix('')), 'zip', str(OUTPUT_DIR))\n",
    "print('Zipped model to:', ZIP_PATH)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
