{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1003e825",
   "metadata": {},
   "source": [
    "# NLP Multiclass Fraud Detection Baseline Model\n",
    "\n",
    "This notebook implements a comprehensive baseline model for **multiclass fraud and scam detection** using Natural Language Processing techniques. We'll build and compare multiple approaches from traditional machine learning to modern transformer-based models.\n",
    "\n",
    "## üéØ Objectives\n",
    "1. Build traditional ML baselines for **multiclass classification** (TF-IDF + Logistic Regression, SVM)\n",
    "2. Implement BERT-based multiclass classification\n",
    "3. Evaluate and compare model performance across **10 classes** (9 scam types + legitimate)\n",
    "4. Provide a foundation for more advanced fraud detection systems\n",
    "\n",
    "## üìä Dataset\n",
    "We'll work with a comprehensive fraud dataset containing:\n",
    "- **legitimate**: Normal, non-fraudulent messages  \n",
    "- **phishing**: Email/message phishing attempts\n",
    "- **popup_scam**: Fake popup advertisements and scams\n",
    "- **sms_spam**: SMS spam messages\n",
    "- **reward_scam**: Fake reward and prize scams\n",
    "- **tech_support_scam**: Fake technical support scams\n",
    "- **refund_scam**: Fake refund scams\n",
    "- **ssn_scam**: Social Security Number scams\n",
    "- **job_scam**: Fake job opportunity scams\n",
    "\n",
    "## ‚ú® Multiclass Benefits\n",
    "- **Granular Detection**: Identify specific types of fraud\n",
    "- **Better Insights**: Understand fraud patterns by category\n",
    "- **Targeted Defense**: Apply appropriate countermeasures per scam type\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54843f8",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Let's start by importing all the necessary libraries for our fraud detection system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687cb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Text processing and NLP\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy version: {np.__version__}\")\n",
    "print(f\"ü§ñ Scikit-learn version:\", end=\" \")\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14416a5a",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset\n",
    "\n",
    "We'll create a comprehensive dataset with various types of fraud and legitimate messages. In a real project, you would load your actual dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fraud_dataset():\n",
    "    \"\"\"\n",
    "    Load multiclass fraud/scam data from CSV dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the full dataset for multiclass classification\n",
    "        df = pd.read_csv('final_fraud_detection_dataset.csv')\n",
    "        print(f\"‚úÖ Loaded dataset with {len(df)} samples\")\n",
    "        \n",
    "        # Use detailed_category for multiclass classification\n",
    "        df = df[['text', 'detailed_category']].copy()\n",
    "        df.columns = ['message', 'label']\n",
    "        \n",
    "        print(f\"\\nüìä Dataset Overview:\")\n",
    "        print(f\"Total samples: {len(df)}\")\n",
    "        print(f\"Number of classes: {df['label'].nunique()}\")\n",
    "        print(f\"\\nüè∑Ô∏è Class distribution:\")\n",
    "        class_counts = df['label'].value_counts()\n",
    "        for label, count in class_counts.items():\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"  {label}: {count:,} ({percentage:.1f}%)\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Dataset file 'final_fraud_detection_dataset.csv' not found!\")\n",
    "        print(\"üìù Creating sample multiclass data for demonstration...\")\n",
    "        return create_sample_multiclass_data()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading dataset: {e}\")\n",
    "        print(\"üìù Creating sample multiclass data for demonstration...\")\n",
    "        return create_sample_multiclass_data()\n",
    "\n",
    "def create_sample_multiclass_data():\n",
    "    \"\"\"\n",
    "    Create sample multiclass fraud data for demonstration\n",
    "    \"\"\"\n",
    "    # Sample data for each class\n",
    "    data = {\n",
    "        'legitimate': [\n",
    "            \"Thank you for your purchase. Your order will ship tomorrow.\",\n",
    "            \"Meeting scheduled for 3 PM in conference room A.\",\n",
    "            \"Happy birthday! Hope you have a wonderful day.\",\n",
    "            \"The weather forecast shows rain this weekend.\",\n",
    "            \"Please review the attached quarterly report.\",\n",
    "            \"Lunch meeting confirmed for tomorrow at noon.\",\n",
    "            \"Your subscription renewal is due next month.\",\n",
    "            \"Project deadline moved to next Friday.\",\n",
    "            \"Thanks for attending today's presentation.\",\n",
    "            \"Weekend plans include hiking and relaxation.\"\n",
    "        ],\n",
    "        'phishing': [\n",
    "            \"URGENT: Verify your bank account immediately to avoid suspension.\",\n",
    "            \"Your PayPal account has been limited. Click here to restore access.\",\n",
    "            \"Security alert: Suspicious login detected. Confirm your identity.\",\n",
    "            \"Your Amazon account requires immediate verification.\",\n",
    "            \"Banking security notice: Update your credentials now.\",\n",
    "            \"IRS tax refund pending: Provide your SSN to process.\",\n",
    "            \"Credit card company: Verify transaction or account will be closed.\",\n",
    "            \"Your email will be deleted unless you confirm your password.\",\n",
    "            \"Microsoft security: Your account was accessed from unknown device.\",\n",
    "            \"Government notification: Social Security benefits suspended.\"\n",
    "        ],\n",
    "        'popup_scam': [\n",
    "            \"You've won $1,000,000! Click here to claim your prize!\",\n",
    "            \"Congratulations! You're the 1,000,000th visitor!\",\n",
    "            \"Your computer is infected! Download our antivirus now!\",\n",
    "            \"Free iPhone! Complete this survey to claim yours!\",\n",
    "            \"You've won a free vacation to Hawaii!\",\n",
    "            \"Your browser is out of date! Update now for security!\",\n",
    "            \"Free gift card worth $500! Claim now!\",\n",
    "            \"You've been selected for a special offer!\",\n",
    "            \"Warning: Your computer performance is critically low!\",\n",
    "            \"Free casino chips! Play now and win big!\"\n",
    "        ],\n",
    "        'sms_spam': [\n",
    "            \"Free msg: Txt STOP to cancel. Win cash prizes by texting WIN to 12345!\",\n",
    "            \"URGENT: Your loan application approved. Call now!\",\n",
    "            \"Free ringtones! Reply YES to get started!\",\n",
    "            \"Your mobile won a car! Claim now!\",\n",
    "            \"Get rich quick! Work from home opportunity!\",\n",
    "            \"Free credit check! Text INFO to receive details!\",\n",
    "            \"Limited time offer: Free trial, then ¬£5/week!\",\n",
    "            \"Congratulations! You've won a shopping voucher!\",\n",
    "            \"Cash advance available! No credit check needed!\",\n",
    "            \"Free dating service! Meet singles in your area!\"\n",
    "        ],\n",
    "        'reward_scam': [\n",
    "            \"Congratulations! You've won a $5000 gift card!\",\n",
    "            \"You've been selected for a luxury cruise vacation!\",\n",
    "            \"Free cash reward! Claim your $1000 now!\",\n",
    "            \"Winner notification: You've won an iPad!\",\n",
    "            \"Exclusive reward: Free shopping spree worth $2000!\",\n",
    "            \"You've won a year's supply of groceries!\",\n",
    "            \"Congratulations! Free car giveaway winner!\",\n",
    "            \"You've been chosen for a cash prize!\",\n",
    "            \"Special reward: Free vacation package!\",\n",
    "            \"Winner alert: Claim your prize money now!\"\n",
    "        ],\n",
    "        'tech_support_scam': [\n",
    "            \"Microsoft support: Your computer has been infected with malware.\",\n",
    "            \"Windows security alert: Your PC is at risk!\",\n",
    "            \"Tech support: Your computer is sending error reports.\",\n",
    "            \"Apple support: Your device has security issues.\",\n",
    "            \"Computer warning: Virus detected on your system!\",\n",
    "            \"Technical alert: Your computer performance is compromised.\",\n",
    "            \"Microsoft: Your Windows license has expired.\",\n",
    "            \"Tech support: Call immediately to fix computer problems.\",\n",
    "            \"Security warning: Your computer is infected!\",\n",
    "            \"System alert: Computer protection has expired.\"\n",
    "        ],\n",
    "        'refund_scam': [\n",
    "            \"Tax refund notification: $2847 refund pending.\",\n",
    "            \"IRS refund alert: Claim your tax refund now!\",\n",
    "            \"Government refund: You're eligible for $1500 refund.\",\n",
    "            \"Tax office: Refund of $3200 requires verification.\",\n",
    "            \"HMRC refund: You have an unclaimed tax refund.\",\n",
    "            \"Refund processing: Confirm details to receive money.\",\n",
    "            \"Government payment: Refund check is ready.\",\n",
    "            \"Tax refund urgent: Action required to process refund.\",\n",
    "            \"Refund notification: Update bank details to receive payment.\",\n",
    "            \"Official refund: You're entitled to a refund.\"\n",
    "        ],\n",
    "        'ssn_scam': [\n",
    "            \"Social Security Administration: Your SSN has been suspended.\",\n",
    "            \"SSN alert: Suspicious activity detected on your number.\",\n",
    "            \"Your Social Security number will be blocked immediately.\",\n",
    "            \"SSN security notice: Verify your number to avoid suspension.\",\n",
    "            \"Social Security fraud alert: Your number is compromised.\",\n",
    "            \"SSN suspension notice: Call immediately to reactivate.\",\n",
    "            \"Your Social Security benefits are suspended.\",\n",
    "            \"SSN alert: Update your information to avoid penalties.\",\n",
    "            \"Social Security: Your number linked to illegal activity.\",\n",
    "            \"SSN warning: Immediate action required to avoid legal issues.\"\n",
    "        ],\n",
    "        'job_scam': [\n",
    "            \"Work from home opportunity! Earn $5000 per week!\",\n",
    "            \"Easy job: Earn $200 per day stuffing envelopes!\",\n",
    "            \"Home-based business opportunity! No experience needed!\",\n",
    "            \"Data entry job: Earn $50 per hour working from home!\",\n",
    "            \"Online job: Make $3000 per month in your spare time!\",\n",
    "            \"Mystery shopper needed! Earn money while shopping!\",\n",
    "            \"Work from home: Guaranteed income with minimal effort!\",\n",
    "            \"Part-time job: Earn $100 per day online!\",\n",
    "            \"Employment opportunity: High pay for simple tasks!\",\n",
    "            \"Job offer: Make money fast with our proven system!\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Create DataFrame\n",
    "    messages = []\n",
    "    labels = []\n",
    "    \n",
    "    for label, texts in data.items():\n",
    "        messages.extend(texts)\n",
    "        labels.extend([label] * len(texts))\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'message': messages,\n",
    "        'label': labels\n",
    "    })\n",
    "    \n",
    "    # Shuffle the data\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\udcdd Created sample dataset with {len(df)} samples\")\n",
    "    print(f\"Number of classes: {df['label'].nunique()}\")\n",
    "    print(f\"\\nüè∑Ô∏è Class distribution:\")\n",
    "    for label, count in df['label'].value_counts().items():\n",
    "        print(f\"  {label}: {count}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the dataset\n",
    "print(\"\ude80 Loading multiclass fraud detection dataset...\")\n",
    "df = create_fraud_dataset()\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\nüìã Sample data:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for multiclass data exploration\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Class distribution - using bar plot for multiclass\n",
    "label_counts = df['label'].value_counts()\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(label_counts)))\n",
    "\n",
    "bars = axes[0, 0].bar(range(len(label_counts)), label_counts.values, color=colors)\n",
    "axes[0, 0].set_title('Distribution of Fraud Classes', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Fraud Classes')\n",
    "axes[0, 0].set_ylabel('Number of Messages')\n",
    "axes[0, 0].set_xticks(range(len(label_counts)))\n",
    "axes[0, 0].set_xticklabels(label_counts.index, rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, label_counts.values):\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 10,\n",
    "                    f'{count:,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 2. Message length distribution by class\n",
    "df['message_length'] = df['message'].str.len()\n",
    "\n",
    "# Create box plot for all classes\n",
    "class_data = [df[df['label'] == label]['message_length'] for label in label_counts.index]\n",
    "box_plot = axes[0, 1].boxplot(class_data, labels=label_counts.index, patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "for patch, color in zip(box_plot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "axes[0, 1].set_title('Message Length Distribution by Class', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Fraud Classes')\n",
    "axes[0, 1].set_ylabel('Message Length (characters)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Word count distribution\n",
    "df['word_count'] = df['message'].str.split().str.len()\n",
    "\n",
    "# Average metrics by class\n",
    "stats_data = df.groupby('label').agg({\n",
    "    'message_length': 'mean',\n",
    "    'word_count': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Plot average message length\n",
    "x_pos = range(len(stats_data))\n",
    "bars_length = axes[1, 0].bar(x_pos, stats_data['message_length'], color=colors)\n",
    "axes[1, 0].set_title('Average Message Length by Class', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Fraud Classes')\n",
    "axes[1, 0].set_ylabel('Average Message Length')\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels(stats_data.index, rotation=45, ha='right')\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars_length, stats_data['message_length']):\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 2,\n",
    "                    f'{value:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 4. Average word count by class\n",
    "bars_words = axes[1, 1].bar(x_pos, stats_data['word_count'], color=colors)\n",
    "axes[1, 1].set_title('Average Word Count by Class', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Fraud Classes')\n",
    "axes[1, 1].set_ylabel('Average Word Count')\n",
    "axes[1, 1].set_xticks(x_pos)\n",
    "axes[1, 1].set_xticklabels(stats_data.index, rotation=45, ha='right')\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars_words, stats_data['word_count']):\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,\n",
    "                    f'{value:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comprehensive statistics for multiclass\n",
    "print(\"\\nüìä MULTICLASS DATASET STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples: {len(df):,}\")\n",
    "print(f\"Number of classes: {df['label'].nunique()}\")\n",
    "print(f\"\\nüè∑Ô∏è Class distribution:\")\n",
    "for label, count in label_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {label}: {count:,} samples ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìè Message characteristics by class:\")\n",
    "class_stats = df.groupby('label').agg({\n",
    "    'message_length': ['mean', 'std', 'min', 'max'],\n",
    "    'word_count': ['mean', 'std', 'min', 'max']\n",
    "}).round(2)\n",
    "\n",
    "for label in df['label'].unique():\n",
    "    print(f\"\\n  {label}:\")\n",
    "    print(f\"    Avg length: {class_stats.loc[label, ('message_length', 'mean')]:.1f} chars\")\n",
    "    print(f\"    Avg words: {class_stats.loc[label, ('word_count', 'mean')]:.1f}\")\n",
    "    print(f\"    Length range: {class_stats.loc[label, ('message_length', 'min')]:.0f}-{class_stats.loc[label, ('message_length', 'max')]:.0f} chars\")\n",
    "\n",
    "print(f\"\\nüìä Overall statistics:\")\n",
    "print(f\"  Total characters: {df['message_length'].sum():,}\")\n",
    "print(f\"  Average message length: {df['message_length'].mean():.1f} characters\")\n",
    "print(f\"  Average word count: {df['word_count'].mean():.1f} words\")\n",
    "print(f\"  Length range: {df['message_length'].min()}-{df['message_length'].max()} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db94a4c2",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Text Cleaning\n",
    "\n",
    "Now we'll clean and preprocess the text data to prepare it for machine learning models. This includes removing noise, normalizing text, and creating features that our models can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f458df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    \"\"\"\n",
    "    Comprehensive text preprocessing pipeline for fraud detection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        # Add domain-specific words to stop words if needed\n",
    "        # self.stop_words.update(['would', 'could', 'should'])\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"\n",
    "        Clean and normalize text\n",
    "        \"\"\"\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "        text = re.sub(r'www\\.(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "        \n",
    "        # Remove email addresses\n",
    "        text = re.sub(r'\\S+@\\S+', '', text)\n",
    "        \n",
    "        # Remove phone numbers\n",
    "        text = re.sub(r'[\\+]?[1-9]?[0-9]{7,15}', '', text)\n",
    "        \n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def tokenize_and_lemmatize(self, text):\n",
    "        \"\"\"\n",
    "        Tokenize text and apply lemmatization\n",
    "        \"\"\"\n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and short words\n",
    "        tokens = [token for token in tokens if token not in self.stop_words and len(token) > 2]\n",
    "        \n",
    "        # Lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        \"\"\"\n",
    "        Complete preprocessing pipeline\n",
    "        \"\"\"\n",
    "        # Clean text\n",
    "        cleaned = self.clean_text(text)\n",
    "        \n",
    "        # Tokenize and lemmatize\n",
    "        processed = self.tokenize_and_lemmatize(cleaned)\n",
    "        \n",
    "        return processed\n",
    "    \n",
    "    def extract_features(self, text):\n",
    "        \"\"\"\n",
    "        Extract additional features from text\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Basic text features\n",
    "        features['char_count'] = len(text)\n",
    "        features['word_count'] = len(text.split())\n",
    "        features['sentence_count'] = len(re.findall(r'[.!?]+', text))\n",
    "        features['avg_word_length'] = np.mean([len(word) for word in text.split()]) if text.split() else 0\n",
    "        \n",
    "        # Uppercase features\n",
    "        features['upper_case_count'] = sum(1 for c in text if c.isupper())\n",
    "        features['upper_case_ratio'] = features['upper_case_count'] / len(text) if len(text) > 0 else 0\n",
    "        \n",
    "        # Punctuation features\n",
    "        features['exclamation_count'] = text.count('!')\n",
    "        features['question_count'] = text.count('?')\n",
    "        features['dollar_count'] = text.count('$')\n",
    "        \n",
    "        # Fraud-specific features\n",
    "        fraud_indicators = ['urgent', 'click', 'verify', 'winner', 'prize', 'money', 'free', 'offer']\n",
    "        features['fraud_words'] = sum(1 for word in fraud_indicators if word in text.lower())\n",
    "        \n",
    "        return features\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "print(\"üîÑ Preprocessing text data...\")\n",
    "df['cleaned_message'] = df['message'].apply(preprocessor.preprocess)\n",
    "\n",
    "# Extract additional features\n",
    "print(\"üîç Extracting additional features...\")\n",
    "feature_data = df['message'].apply(preprocessor.extract_features)\n",
    "feature_df = pd.DataFrame(list(feature_data))\n",
    "\n",
    "# Combine with main dataframe\n",
    "df = pd.concat([df, feature_df], axis=1)\n",
    "\n",
    "print(\"‚úÖ Preprocessing complete!\")\n",
    "\n",
    "# Show preprocessing examples\n",
    "print(\"\\nüìù PREPROCESSING EXAMPLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sample_indices = [0, 15, 30]  # Show examples from different categories\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    print(f\"\\nExample {i+1} - Label: {df.iloc[idx]['label'].upper()}\")\n",
    "    print(f\"Original: {df.iloc[idx]['message'][:80]}...\")\n",
    "    print(f\"Cleaned:  {df.iloc[idx]['cleaned_message'][:80]}...\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Show feature statistics\n",
    "print(\"\\nüìä EXTRACTED FEATURES STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "feature_cols = ['char_count', 'word_count', 'upper_case_ratio', 'fraud_words']\n",
    "print(df.groupby('label')[feature_cols].mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95a92b2",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering with TF-IDF\n",
    "\n",
    "We'll convert the cleaned text into numerical features that machine learning algorithms can understand using TF-IDF (Term Frequency-Inverse Document Frequency) vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,          # Limit vocabulary to top 5000 words\n",
    "    ngram_range=(1, 2),         # Use unigrams and bigrams\n",
    "    stop_words='english',       # Remove English stop words\n",
    "    min_df=2,                   # Ignore terms that appear in less than 2 documents\n",
    "    max_df=0.95,               # Ignore terms that appear in more than 95% of documents\n",
    "    lowercase=True,             # Convert to lowercase\n",
    "    sublinear_tf=True          # Apply sublinear tf scaling\n",
    ")\n",
    "\n",
    "print(\"üîÑ Creating TF-IDF features...\")\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cleaned_message'])\n",
    "\n",
    "print(f\"‚úÖ TF-IDF vectorization complete!\")\n",
    "print(f\"üìä Feature matrix shape: {X_tfidf.shape}\")\n",
    "print(f\"üìö Vocabulary size: {len(tfidf_vectorizer.vocabulary_)}\")\n",
    "\n",
    "# Get feature names\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=feature_names)\n",
    "\n",
    "print(f\"\\nüîç Sample TF-IDF features:\")\n",
    "print(f\"First 10 features: {list(feature_names[:10])}\")\n",
    "\n",
    "# Analyze most important features for each class\n",
    "print(\"\\nüìä TOP TF-IDF FEATURES BY CLASS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate mean TF-IDF scores for each class\n",
    "fraud_mask = df['label'] == 'fraud'\n",
    "normal_mask = df['label'] == 'normal'\n",
    "\n",
    "fraud_tfidf_mean = X_tfidf_df[fraud_mask].mean()\n",
    "normal_tfidf_mean = X_tfidf_df[normal_mask].mean()\n",
    "\n",
    "# Get top features for fraud class\n",
    "top_fraud_features = fraud_tfidf_mean.nlargest(10)\n",
    "print(\"üö® Top 10 Fraud Features:\")\n",
    "for feature, score in top_fraud_features.items():\n",
    "    print(f\"  {feature}: {score:.4f}\")\n",
    "\n",
    "# Get top features for normal class\n",
    "top_normal_features = normal_tfidf_mean.nlargest(10)\n",
    "print(\"\\n‚úÖ Top 10 Normal Features:\")\n",
    "for feature, score in top_normal_features.items():\n",
    "    print(f\"  {feature}: {score:.4f}\")\n",
    "\n",
    "# Visualize top features\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top fraud features\n",
    "top_fraud_features.plot(kind='barh', ax=ax1, color='red', alpha=0.7)\n",
    "ax1.set_title('Top 10 Features in Fraud Messages', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Average TF-IDF Score')\n",
    "\n",
    "# Top normal features\n",
    "top_normal_features.plot(kind='barh', ax=ax2, color='green', alpha=0.7)\n",
    "ax2.set_title('Top 10 Features in Normal Messages', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Average TF-IDF Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create word clouds for visual representation\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Fraud word cloud\n",
    "fraud_text = ' '.join(df[df['label'] == 'fraud']['cleaned_message'])\n",
    "fraud_wordcloud = WordCloud(width=400, height=300, background_color='white').generate(fraud_text)\n",
    "ax1.imshow(fraud_wordcloud, interpolation='bilinear')\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Fraud Messages Word Cloud', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Normal word cloud\n",
    "normal_text = ' '.join(df[df['label'] == 'normal']['cleaned_message'])\n",
    "normal_wordcloud = WordCloud(width=400, height=300, background_color='white').generate(normal_text)\n",
    "ax2.imshow(normal_wordcloud, interpolation='bilinear')\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Normal Messages Word Cloud', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Combine TF-IDF features with additional engineered features\n",
    "additional_features = ['char_count', 'word_count', 'upper_case_ratio', 'fraud_words', \n",
    "                      'exclamation_count', 'dollar_count']\n",
    "\n",
    "# Normalize additional features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_additional = scaler.fit_transform(df[additional_features])\n",
    "\n",
    "# Combine features\n",
    "X_combined = np.hstack([X_tfidf.toarray(), X_additional])\n",
    "print(f\"\\nüîó Combined feature matrix shape: {X_combined.shape}\")\n",
    "print(f\"   TF-IDF features: {X_tfidf.shape[1]}\")\n",
    "print(f\"   Additional features: {len(additional_features)}\")\n",
    "print(f\"   Total features: {X_combined.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318c8af",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split\n",
    "\n",
    "Now we'll split our data into training and testing sets, ensuring proper stratification to maintain class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8435ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target variable for MULTICLASS classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"üîÑ Preparing multiclass labels...\")\n",
    "\n",
    "# Use LabelEncoder for multiclass labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "print(f\"‚úÖ Label encoding complete!\")\n",
    "print(f\"Classes: {label_encoder.classes_}\")\n",
    "print(f\"Number of classes: {len(label_encoder.classes_)}\")\n",
    "\n",
    "print(\"üîÑ Splitting dataset...\")\n",
    "\n",
    "# Split the data with stratification for multiclass\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y, \n",
    "    test_size=0.3,          # 70% train, 30% test\n",
    "    random_state=42,        # For reproducibility\n",
    "    stratify=y             # Maintain class balance across all classes\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Dataset split complete!\")\n",
    "\n",
    "# Print split information\n",
    "print(f\"\\nüìä MULTICLASS DATASET SPLIT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Training samples: {len(X_train)} ({len(X_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"Testing samples: {len(X_test)} ({len(X_test)/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è MULTICLASS LABEL DISTRIBUTION\")\n",
    "print(\"-\"*40)\n",
    "print(\"Training set:\")\n",
    "train_labels = pd.Series(y_train).map({i: label for i, label in enumerate(label_encoder.classes_)})\n",
    "train_counts = train_labels.value_counts()\n",
    "for label, count in train_counts.items():\n",
    "    percentage = (count / len(y_train)) * 100\n",
    "    print(f\"  {label}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nTesting set:\")\n",
    "test_labels = pd.Series(y_test).map({i: label for i, label in enumerate(label_encoder.classes_)})\n",
    "test_counts = test_labels.value_counts()\n",
    "for label, count in test_counts.items():\n",
    "    percentage = (count / len(y_test)) * 100\n",
    "    print(f\"  {label}: {count} samples ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ec839",
   "metadata": {},
   "source": [
    "## 6. Build Baseline Models\n",
    "\n",
    "We'll implement and compare multiple baseline models to establish a strong foundation for fraud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MULTICLASS baseline models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=42, \n",
    "        max_iter=2000,\n",
    "        multi_class='ovr'  # One-vs-Rest for multiclass\n",
    "    ),\n",
    "    'SVM': SVC(\n",
    "        random_state=42, \n",
    "        probability=True,\n",
    "        decision_function_shape='ovr'  # One-vs-Rest for multiclass\n",
    "    ),\n",
    "    'Naive Bayes': MultinomialNB(),  # Naturally handles multiclass\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        random_state=42,\n",
    "        class_weight='balanced'  # Handle class imbalance\n",
    "    )\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "print(\"ü§ñ Training multiclass baseline models...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train and evaluate each model for multiclass\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîÑ Training {name} for multiclass classification...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate multiclass metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # For multiclass, use macro and weighted averages\n",
    "    precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    precision_weighted = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'accuracy': accuracy,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'precision_weighted': precision_weighted,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'f1_weighted': f1_weighted\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ {name} complete!\")\n",
    "    print(f\"   Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"   F1-Score (Macro): {f1_macro:.3f}\")\n",
    "    print(f\"   F1-Score (Weighted): {f1_weighted:.3f}\")\n",
    "\n",
    "print(f\"\\nüéØ MULTICLASS MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<18} {'Accuracy':<9} {'F1-Macro':<9} {'F1-Weighted':<11} {'Prec-Macro':<10} {'Rec-Macro':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name:<18} {metrics['accuracy']:<9.3f} {metrics['f1_macro']:<9.3f} \"\n",
    "          f\"{metrics['f1_weighted']:<11.3f} {metrics['precision_macro']:<10.3f} {metrics['recall_macro']:<10.3f}\")\n",
    "\n",
    "# Find best model based on weighted F1-score (good for imbalanced multiclass)\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['f1_weighted'])\n",
    "best_f1 = results[best_model_name]['f1_weighted']\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name} (F1-Weighted: {best_f1:.3f})\")\n",
    "\n",
    "# Show detailed classification report for best model\n",
    "print(f\"\\nüìä DETAILED CLASSIFICATION REPORT - {best_model_name}\")\n",
    "print(\"=\"*60)\n",
    "best_model = results[best_model_name]['model']\n",
    "best_y_pred = results[best_model_name]['y_pred']\n",
    "\n",
    "report = classification_report(\n",
    "    y_test, \n",
    "    best_y_pred, \n",
    "    target_names=label_encoder.classes_,\n",
    "    zero_division=0\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# Show confusion matrix for best model\n",
    "print(f\"\\nüîç CONFUSION MATRIX - {best_model_name}\")\n",
    "print(\"=\"*50)\n",
    "cm = confusion_matrix(y_test, best_y_pred)\n",
    "print(\"Classes:\", label_encoder.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf39d6",
   "metadata": {},
   "source": [
    "## 7. Model Training and Evaluation\n",
    "\n",
    "Let's perform cross-validation and detailed analysis of our models to ensure robust performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation for more robust evaluation\n",
    "print(\"üîÑ Performing cross-validation...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "cv_results = {}\n",
    "cv_folds = 5\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüìä Cross-validating {name}...\")\n",
    "    \n",
    "    # Perform cross-validation on different metrics\n",
    "    cv_accuracy = cross_val_score(model, X_combined, y, cv=cv_folds, scoring='accuracy')\n",
    "    cv_precision = cross_val_score(model, X_combined, y, cv=cv_folds, scoring='precision')\n",
    "    cv_recall = cross_val_score(model, X_combined, y, cv=cv_folds, scoring='recall')\n",
    "    cv_f1 = cross_val_score(model, X_combined, y, cv=cv_folds, scoring='f1')\n",
    "    cv_auc = cross_val_score(model, X_combined, y, cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'accuracy': cv_accuracy,\n",
    "        'precision': cv_precision,\n",
    "        'recall': cv_recall,\n",
    "        'f1': cv_f1,\n",
    "        'auc': cv_auc\n",
    "    }\n",
    "    \n",
    "    print(f\"   Accuracy:  {cv_accuracy.mean():.3f} (¬±{cv_accuracy.std()*2:.3f})\")\n",
    "    print(f\"   Precision: {cv_precision.mean():.3f} (¬±{cv_precision.std()*2:.3f})\")\n",
    "    print(f\"   Recall:    {cv_recall.mean():.3f} (¬±{cv_recall.std()*2:.3f})\")\n",
    "    print(f\"   F1-Score:  {cv_f1.mean():.3f} (¬±{cv_f1.std()*2:.3f})\")\n",
    "    print(f\"   AUC:       {cv_auc.mean():.3f} (¬±{cv_auc.std()*2:.3f})\")\n",
    "\n",
    "# Visualize cross-validation results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    \n",
    "    # Prepare data for box plot\n",
    "    data_to_plot = [cv_results[name][metric] for name in models.keys()]\n",
    "    model_names = list(models.keys())\n",
    "    \n",
    "    # Create box plot\n",
    "    box_plot = axes[row, col].boxplot(data_to_plot, labels=model_names, patch_artist=True)\n",
    "    \n",
    "    # Color the boxes\n",
    "    colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "    for patch, color in zip(box_plot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[row, col].set_title(f'{metric.upper()} - Cross Validation', fontsize=12, fontweight='bold')\n",
    "    axes[row, col].set_ylabel(metric.title())\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "    axes[row, col].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Remove the empty subplot\n",
    "axes[1, 2].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical significance testing\n",
    "print(f\"\\nüìà CROSS-VALIDATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<20} {'Metric':<12} {'Mean':<8} {'Std':<8} {'Min':<8} {'Max':<8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name in models.keys():\n",
    "    for metric in ['f1', 'precision', 'recall', 'accuracy', 'auc']:\n",
    "        scores = cv_results[name][metric]\n",
    "        print(f\"{name:<20} {metric:<12} {scores.mean():<8.3f} {scores.std():<8.3f} \"\n",
    "              f\"{scores.min():<8.3f} {scores.max():<8.3f}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "# Hyperparameter tuning for best models\n",
    "print(f\"\\nüîß HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Tune Logistic Regression\n",
    "print(\"üîÑ Tuning Logistic Regression...\")\n",
    "lr_params = {\n",
    "    'C': [0.1, 1.0, 10.0, 100.0],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    lr_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr_grid.fit(X_train, y_train)\n",
    "print(f\"‚úÖ Best LR params: {lr_grid.best_params_}\")\n",
    "print(f\"‚úÖ Best LR score: {lr_grid.best_score_:.3f}\")\n",
    "\n",
    "# Tune SVM\n",
    "print(f\"\\nüîÑ Tuning SVM...\")\n",
    "svm_params = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm_grid = GridSearchCV(\n",
    "    SVC(random_state=42, probability=True),\n",
    "    svm_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "svm_grid.fit(X_train, y_train)\n",
    "print(f\"‚úÖ Best SVM params: {svm_grid.best_params_}\")\n",
    "print(f\"‚úÖ Best SVM score: {svm_grid.best_score_:.3f}\")\n",
    "\n",
    "# Store tuned models\n",
    "tuned_models = {\n",
    "    'Tuned Logistic Regression': lr_grid.best_estimator_,\n",
    "    'Tuned SVM': svm_grid.best_estimator_\n",
    "}\n",
    "\n",
    "# Evaluate tuned models\n",
    "print(f\"\\nüéØ TUNED MODEL PERFORMANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for name, model in tuned_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall:    {recall:.3f}\")\n",
    "    print(f\"  F1-Score:  {f1:.3f}\")\n",
    "    print(f\"  AUC:       {auc:.3f}\")\n",
    "    \n",
    "    # Update results with tuned models\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_score': auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1b09f",
   "metadata": {},
   "source": [
    "## 8. Performance Metrics and Confusion Matrix\n",
    "\n",
    "Let's dive deep into the performance analysis with detailed confusion matrices and error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed confusion matrix analysis\n",
    "def plot_confusion_matrices(results, y_test):\n",
    "    \"\"\"Plot confusion matrices for all models\"\"\"\n",
    "    \n",
    "    n_models = len(results)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (name, result) in enumerate(results.items()):\n",
    "        if idx >= len(axes):\n",
    "            break\n",
    "            \n",
    "        cm = confusion_matrix(y_test, result['y_pred'])\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['Normal', 'Fraud'], \n",
    "                   yticklabels=['Normal', 'Fraud'],\n",
    "                   ax=axes[idx])\n",
    "        \n",
    "        axes[idx].set_title(f'{name}\\nAccuracy: {result[\"accuracy\"]:.3f}', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Predicted Label')\n",
    "        axes[idx].set_ylabel('True Label')\n",
    "        \n",
    "        # Add percentage annotations\n",
    "        total = cm.sum()\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                percent = cm[i, j] / total * 100\n",
    "                axes[idx].text(j + 0.5, i + 0.7, f'({percent:.1f}%)', \n",
    "                             ha='center', va='center', fontsize=10, color='red')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for idx in range(len(results), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices\n",
    "plot_confusion_matrices(results, y_test)\n",
    "\n",
    "# Detailed classification reports\n",
    "print(\"üìä DETAILED CLASSIFICATION REPORTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f\"\\nü§ñ {name}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(classification_report(y_test, result['y_pred'], \n",
    "                              target_names=['Normal', 'Fraud'],\n",
    "                              digits=3))\n",
    "\n",
    "# Error analysis\n",
    "print(f\"\\nüîç ERROR ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get the best performing model for detailed analysis\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['f1_score'])\n",
    "best_result = results[best_model_name]\n",
    "\n",
    "print(f\"Analyzing errors for: {best_model_name}\")\n",
    "print(f\"Best F1-Score: {best_result['f1_score']:.3f}\")\n",
    "\n",
    "# Get test data for error analysis\n",
    "X_test_indices = y_test.index if hasattr(y_test, 'index') else range(len(y_test))\n",
    "\n",
    "# Find misclassified samples\n",
    "y_pred_best = best_result['y_pred']\n",
    "misclassified_mask = y_test != y_pred_best\n",
    "misclassified_indices = [i for i, mask in enumerate(misclassified_mask) if mask]\n",
    "\n",
    "print(f\"\\nTotal misclassified samples: {sum(misclassified_mask)}\")\n",
    "\n",
    "# Analyze false positives and false negatives\n",
    "false_positives = [(i, y_test.iloc[i] if hasattr(y_test, 'iloc') else y_test[i], y_pred_best[i]) \n",
    "                   for i in misclassified_indices \n",
    "                   if (y_test.iloc[i] if hasattr(y_test, 'iloc') else y_test[i]) == 0 and y_pred_best[i] == 1]\n",
    "\n",
    "false_negatives = [(i, y_test.iloc[i] if hasattr(y_test, 'iloc') else y_test[i], y_pred_best[i]) \n",
    "                   for i in misclassified_indices \n",
    "                   if (y_test.iloc[i] if hasattr(y_test, 'iloc') else y_test[i]) == 1 and y_pred_best[i] == 0]\n",
    "\n",
    "print(f\"False Positives (Normal predicted as Fraud): {len(false_positives)}\")\n",
    "print(f\"False Negatives (Fraud predicted as Normal): {len(false_negatives)}\")\n",
    "\n",
    "# Show examples of misclassified samples\n",
    "if len(false_positives) > 0:\n",
    "    print(f\"\\n‚ùå FALSE POSITIVE EXAMPLES:\")\n",
    "    print(\"-\" * 30)\n",
    "    # Get original test data indices\n",
    "    df_test = df.iloc[y_test.index] if hasattr(y_test, 'index') else df.iloc[-len(y_test):]\n",
    "    \n",
    "    for i, (idx, true_label, pred_label) in enumerate(false_positives[:3]):\n",
    "        original_idx = df_test.index[idx] if hasattr(df_test, 'index') else idx\n",
    "        message = df.loc[original_idx, 'message'] if original_idx in df.index else \"Message not found\"\n",
    "        print(f\"{i+1}. {message[:100]}...\")\n",
    "        print(f\"   True: Normal, Predicted: Fraud\")\n",
    "        print()\n",
    "\n",
    "if len(false_negatives) > 0:\n",
    "    print(f\"\\n‚ùå FALSE NEGATIVE EXAMPLES:\")\n",
    "    print(\"-\" * 30)\n",
    "    df_test = df.iloc[y_test.index] if hasattr(y_test, 'index') else df.iloc[-len(y_test):]\n",
    "    \n",
    "    for i, (idx, true_label, pred_label) in enumerate(false_negatives[:3]):\n",
    "        original_idx = df_test.index[idx] if hasattr(df_test, 'index') else idx\n",
    "        message = df.loc[original_idx, 'message'] if original_idx in df.index else \"Message not found\"\n",
    "        print(f\"{i+1}. {message[:100]}...\")\n",
    "        print(f\"   True: Fraud, Predicted: Normal\")\n",
    "        print()\n",
    "\n",
    "# Cost analysis for fraud detection\n",
    "print(f\"\\nüí∞ COST ANALYSIS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Assuming costs: FN (missed fraud) = $1000, FP (false alarm) = $10\n",
    "cost_fn = 1000  # Cost of missing a fraud\n",
    "cost_fp = 10    # Cost of false alarm\n",
    "\n",
    "for name, result in results.items():\n",
    "    cm = confusion_matrix(y_test, result['y_pred'])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    total_cost = fn * cost_fn + fp * cost_fp\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  False Negatives: {fn} x ${cost_fn} = ${fn * cost_fn}\")\n",
    "    print(f\"  False Positives: {fp} x ${cost_fp} = ${fp * cost_fp}\")\n",
    "    print(f\"  Total Cost: ${total_cost}\")\n",
    "    print(f\"  Cost per sample: ${total_cost / len(y_test):.2f}\")\n",
    "    print()\n",
    "\n",
    "# Performance at different thresholds\n",
    "print(f\"\\nüìà THRESHOLD ANALYSIS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Analyze best model at different thresholds\n",
    "best_model = best_result['model']\n",
    "y_proba = best_result['y_pred_proba']\n",
    "\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"{'Threshold':<10} {'Precision':<10} {'Recall':<10} {'F1':<10} {'Cost':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    precision_thresh = precision_score(y_test, y_pred_thresh)\n",
    "    recall_thresh = recall_score(y_test, y_pred_thresh)\n",
    "    f1_thresh = f1_score(y_test, y_pred_thresh)\n",
    "    \n",
    "    # Calculate cost\n",
    "    cm_thresh = confusion_matrix(y_test, y_pred_thresh)\n",
    "    tn, fp, fn, tp = cm_thresh.ravel()\n",
    "    cost_thresh = fn * cost_fn + fp * cost_fp\n",
    "    \n",
    "    print(f\"{threshold:<10.1f} {precision_thresh:<10.3f} {recall_thresh:<10.3f} \"\n",
    "          f\"{f1_thresh:<10.3f} ${cost_thresh:<9.0f}\")\n",
    "\n",
    "# Plot precision-recall curve\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision_curve, recall_curve, thresholds_pr = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "ax1.plot(recall_curve, precision_curve, color='blue', linewidth=2)\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.set_title(f'Precision-Recall Curve\\n{best_model_name}', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot threshold vs metrics\n",
    "ax2.plot(thresholds, [precision_score(y_test, (y_proba >= t).astype(int)) for t in thresholds], \n",
    "         label='Precision', marker='o')\n",
    "ax2.plot(thresholds, [recall_score(y_test, (y_proba >= t).astype(int)) for t in thresholds], \n",
    "         label='Recall', marker='s')\n",
    "ax2.plot(thresholds, [f1_score(y_test, (y_proba >= t).astype(int)) for t in thresholds], \n",
    "         label='F1-Score', marker='^')\n",
    "\n",
    "ax2.set_xlabel('Threshold')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_title('Metrics vs Threshold', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14801b32",
   "metadata": {},
   "source": [
    "## 9. Model Prediction on New Text Samples\n",
    "\n",
    "Now let's test our trained models on new, unseen text samples to see how they perform in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDetectionPredictor:\n",
    "    \"\"\"\n",
    "    Wrapper class for making predictions on new text samples\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, vectorizer, preprocessor, scaler, feature_cols):\n",
    "        self.model = model\n",
    "        self.vectorizer = vectorizer\n",
    "        self.preprocessor = preprocessor\n",
    "        self.scaler = scaler\n",
    "        self.feature_cols = feature_cols\n",
    "        \n",
    "    def predict_message(self, message):\n",
    "        \"\"\"\n",
    "        Predict if a message is fraud or normal\n",
    "        \"\"\"\n",
    "        # Preprocess the message\n",
    "        cleaned_message = self.preprocessor.preprocess(message)\n",
    "        \n",
    "        # Extract TF-IDF features\n",
    "        tfidf_features = self.vectorizer.transform([cleaned_message])\n",
    "        \n",
    "        # Extract additional features\n",
    "        additional_features_dict = self.preprocessor.extract_features(message)\n",
    "        additional_features = np.array([[additional_features_dict[col] for col in self.feature_cols]])\n",
    "        additional_features_scaled = self.scaler.transform(additional_features)\n",
    "        \n",
    "        # Combine features\n",
    "        combined_features = np.hstack([tfidf_features.toarray(), additional_features_scaled])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(combined_features)[0]\n",
    "        probability = self.model.predict_proba(combined_features)[0]\n",
    "        \n",
    "        return {\n",
    "            'message': message,\n",
    "            'prediction': 'Fraud' if prediction == 1 else 'Normal',\n",
    "            'confidence': max(probability),\n",
    "            'fraud_probability': probability[1],\n",
    "            'normal_probability': probability[0]\n",
    "        }\n",
    "\n",
    "# Create predictor with the best model\n",
    "best_model = results[best_model_name]['model']\n",
    "predictor = FraudDetectionPredictor(\n",
    "    model=best_model,\n",
    "    vectorizer=tfidf_vectorizer,\n",
    "    preprocessor=preprocessor,\n",
    "    scaler=scaler,\n",
    "    feature_cols=additional_features\n",
    ")\n",
    "\n",
    "# Test on new sample messages\n",
    "test_messages = [\n",
    "    # Clear fraud examples\n",
    "    \"URGENT: Your account is suspended! Click here immediately to restore access or lose your money forever!\",\n",
    "    \"Congratulations! You've won $1,000,000 in our lottery! Send $500 processing fee to claim your prize now!\",\n",
    "    \"FINAL NOTICE: Pay $2000 immediately or we will take legal action against you today!\",\n",
    "    \"Your bank account has been compromised. Verify your details at suspicious-bank-link.com right now!\",\n",
    "    \n",
    "    # Clear normal examples  \n",
    "    \"Hey, thanks for helping me with the project yesterday. The presentation went really well!\",\n",
    "    \"Reminder: Your doctor's appointment is scheduled for tomorrow at 2 PM\",\n",
    "    \"The team meeting has been moved to Friday at 10 AM in conference room B\",\n",
    "    \"Happy birthday! Hope you have a wonderful celebration with your family\",\n",
    "    \n",
    "    # Ambiguous/edge cases\n",
    "    \"Limited time offer: 50% off all items. Sale ends soon!\",\n",
    "    \"Your order has been delayed due to shipping issues. Additional fees may apply\",\n",
    "    \"Security alert: We detected unusual activity on your account. Please review\",\n",
    "    \"Investment opportunity: High returns guaranteed with our new fund\"\n",
    "]\n",
    "\n",
    "print(\"üîÆ TESTING ON NEW MESSAGES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Predict for all test messages\n",
    "predictions = []\n",
    "for i, message in enumerate(test_messages, 1):\n",
    "    result = predictor.predict_message(message)\n",
    "    predictions.append(result)\n",
    "    \n",
    "    # Determine emoji and color based on prediction\n",
    "    emoji = \"üö®\" if result['prediction'] == 'Fraud' else \"‚úÖ\"\n",
    "    confidence_color = \"HIGH\" if result['confidence'] > 0.8 else \"MEDIUM\" if result['confidence'] > 0.6 else \"LOW\"\n",
    "    \n",
    "    print(f\"\\n{emoji} Test Message {i}:\")\n",
    "    print(f\"Message: {message}\")\n",
    "    print(f\"Prediction: {result['prediction']} (Confidence: {confidence_color} - {result['confidence']:.3f})\")\n",
    "    print(f\"Fraud Probability: {result['fraud_probability']:.3f}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Create visualization of predictions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# 1. Prediction distribution\n",
    "pred_counts = pd.Series([p['prediction'] for p in predictions]).value_counts()\n",
    "colors = ['green' if label == 'Normal' else 'red' for label in pred_counts.index]\n",
    "ax1.pie(pred_counts.values, labels=pred_counts.index, autopct='%1.1f%%', colors=colors, alpha=0.7)\n",
    "ax1.set_title('Prediction Distribution on Test Messages', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Confidence distribution\n",
    "confidences = [p['confidence'] for p in predictions]\n",
    "fraud_confidences = [p['confidence'] for p in predictions if p['prediction'] == 'Fraud']\n",
    "normal_confidences = [p['confidence'] for p in predictions if p['prediction'] == 'Normal']\n",
    "\n",
    "ax2.hist(fraud_confidences, alpha=0.7, label='Fraud Predictions', color='red', bins=5)\n",
    "ax2.hist(normal_confidences, alpha=0.7, label='Normal Predictions', color='green', bins=5)\n",
    "ax2.set_xlabel('Confidence Score')\n",
    "ax2.set_ylabel('Number of Predictions')\n",
    "ax2.set_title('Confidence Distribution by Prediction', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interactive prediction function\n",
    "def interactive_prediction():\n",
    "    \"\"\"\n",
    "    Interactive function for testing custom messages\n",
    "    \"\"\"\n",
    "    print(\"\\nüéØ INTERACTIVE FRAUD DETECTION\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Enter a message to test (or 'quit' to exit):\")\n",
    "    \n",
    "    while True:\n",
    "        user_message = input(\"\\nMessage: \").strip()\n",
    "        \n",
    "        if user_message.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"üëã Thanks for testing!\")\n",
    "            break\n",
    "            \n",
    "        if not user_message:\n",
    "            print(\"‚ö†Ô∏è Please enter a message.\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            result = predictor.predict_message(user_message)\n",
    "            \n",
    "            emoji = \"üö®\" if result['prediction'] == 'Fraud' else \"‚úÖ\"\n",
    "            print(f\"\\n{emoji} Prediction: {result['prediction']}\")\n",
    "            print(f\"   Confidence: {result['confidence']:.3f}\")\n",
    "            print(f\"   Fraud Probability: {result['fraud_probability']:.3f}\")\n",
    "            \n",
    "            if result['prediction'] == 'Fraud':\n",
    "                print(\"   ‚ö†Ô∏è This message appears to be fraudulent!\")\n",
    "            else:\n",
    "                print(\"   ‚úÖ This message appears to be legitimate.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing message: {e}\")\n",
    "\n",
    "# Uncomment the line below to run interactive prediction\n",
    "# interactive_prediction()\n",
    "\n",
    "# Save the best model for future use\n",
    "print(f\"\\nüíæ MODEL PERSISTENCE\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save the complete pipeline\n",
    "model_pipeline = {\n",
    "    'model': best_model,\n",
    "    'vectorizer': tfidf_vectorizer,\n",
    "    'preprocessor': preprocessor,\n",
    "    'scaler': scaler,\n",
    "    'feature_columns': additional_features,\n",
    "    'model_name': best_model_name,\n",
    "    'performance_metrics': {\n",
    "        'accuracy': results[best_model_name]['accuracy'],\n",
    "        'precision': results[best_model_name]['precision'],\n",
    "        'recall': results[best_model_name]['recall'],\n",
    "        'f1_score': results[best_model_name]['f1_score'],\n",
    "        'auc_score': results[best_model_name]['auc_score']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "# joblib.dump(model_pipeline, 'fraud_detection_pipeline.pkl')\n",
    "print(\"Model pipeline ready for saving with joblib.dump()\")\n",
    "\n",
    "print(f\"\\nTo load the model later:\")\n",
    "print(\"model_pipeline = joblib.load('fraud_detection_pipeline.pkl')\")\n",
    "print(\"predictor = FraudDetectionPredictor(**model_pipeline)\")\n",
    "\n",
    "# Summary of best practices\n",
    "print(f\"\\nüìã IMPLEMENTATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üèÜ Best Model: {best_model_name}\")\n",
    "print(f\"üìä Performance: F1-Score = {results[best_model_name]['f1_score']:.3f}\")\n",
    "print(f\"üîß Key Features:\")\n",
    "print(f\"   - TF-IDF vectorization with {X_tfidf.shape[1]} features\")\n",
    "print(f\"   - Additional engineered features: {len(additional_features)}\")\n",
    "print(f\"   - Cross-validation for robust evaluation\")\n",
    "print(f\"   - Hyperparameter tuning\")\n",
    "print(f\"   - Cost-sensitive analysis\")\n",
    "print(f\"\\n‚ú® Next Steps:\")\n",
    "print(f\"   1. Deploy as web service (Flask/FastAPI)\")\n",
    "print(f\"   2. Implement real-time monitoring\")\n",
    "print(f\"   3. Add more sophisticated features\")\n",
    "print(f\"   4. Experiment with BERT/transformer models\")\n",
    "print(f\"   5. Collect and retrain on real-world data\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
