{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51288736",
   "metadata": {
    "papermill": {
     "duration": 0.006066,
     "end_time": "2025-10-20T09:34:49.283434",
     "exception": false,
     "start_time": "2025-10-20T09:34:49.277368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ü¶ô Scam-Detector-LoRA Model Testing on Kaggle Dataset\n",
    "\n",
    "This notebook tests the **scam-detector-lora** model (Llama-3-8B with LoRA adapter) on the Kaggle fraud detection dataset.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Classification**: Predict fraud categories (job_scam, phishing, legitimate, etc.)\n",
    "2. **Reasoning**: Generate explanations for why a message is fraud or legitimate\n",
    "\n",
    "**Model Details:**\n",
    "- Base Model: `unsloth/llama-3-8b-instruct-bnb-4bit`\n",
    "- LoRA Configuration: r=16, alpha=16, targets all attention/FFN modules\n",
    "- Task Type: Causal Language Modeling with instruction tuning\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Kaggle Setup Instructions\n",
    "\n",
    "**To run this notebook on Kaggle:**\n",
    "\n",
    "1. **Add Input Datasets:**\n",
    "   - Add the `scam-detector-lora` model as input data\n",
    "     - Path will be: `/kaggle/input/scam-detector-lora/other/default/1/scam-detector-lora`\n",
    "   - Add your fraud detection dataset (e.g., `fraud-data`)\n",
    "     - Path will be: `/kaggle/input/fraud-data/final_fraud_detection_dataset.csv`\n",
    "\n",
    "2. **Enable GPU Accelerator:**\n",
    "   - Go to Settings ‚Üí Accelerator ‚Üí Select \"GPU T4 x2\" or \"GPU P100\"\n",
    "   - This is required for running the Llama-3-8B model efficiently\n",
    "\n",
    "3. **Set Internet to ON:**\n",
    "   - Required to download the base model `unsloth/llama-3-8b-instruct-bnb-4bit`\n",
    "\n",
    "4. **Run all cells sequentially**\n",
    "\n",
    "The notebook will automatically detect available paths and adjust accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f351a9d2",
   "metadata": {
    "papermill": {
     "duration": 0.004694,
     "end_time": "2025-10-20T09:34:49.293355",
     "exception": false,
     "start_time": "2025-10-20T09:34:49.288661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1Ô∏è‚É£ Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a380ad51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T09:34:49.304461Z",
     "iopub.status.busy": "2025-10-20T09:34:49.304074Z",
     "iopub.status.idle": "2025-10-20T09:34:49.323387Z",
     "shell.execute_reply": "2025-10-20T09:34:49.322220Z"
    },
    "papermill": {
     "duration": 0.027199,
     "end_time": "2025-10-20T09:34:49.325380",
     "exception": false,
     "start_time": "2025-10-20T09:34:49.298181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Available datasets in /kaggle/input:\n",
      "  üìÅ fraud-dataset\n",
      "     ‚îî‚îÄ final_fraud_detection_dataset.csv\n",
      "  üìÅ scam-detector-lora\n",
      "     ‚îî‚îÄ other\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check available input paths in Kaggle\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "if Path('/kaggle').exists():\n",
    "    print(\"üîç Available datasets in /kaggle/input:\")\n",
    "    for item in sorted(Path('/kaggle/input').iterdir()):\n",
    "        print(f\"  üìÅ {item.name}\")\n",
    "        # Show subdirectories for each dataset\n",
    "        if item.is_dir():\n",
    "            for subitem in sorted(item.iterdir())[:5]:  # Show first 5 items\n",
    "                print(f\"     ‚îî‚îÄ {subitem.relative_to(item)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c3374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T09:34:49.337267Z",
     "iopub.status.busy": "2025-10-20T09:34:49.336892Z",
     "iopub.status.idle": "2025-10-20T09:34:49.342589Z",
     "shell.execute_reply": "2025-10-20T09:34:49.341728Z"
    },
    "papermill": {
     "duration": 0.013297,
     "end_time": "2025-10-20T09:34:49.344098",
     "exception": false,
     "start_time": "2025-10-20T09:34:49.330801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_packages():\n",
    "    packages = [\n",
    "        \"transformers>=4.40.0\",\n",
    "        \"peft>=0.17.0\",\n",
    "        \"torch>=2.0.0\",\n",
    "        \"accelerate>=0.27.0\",\n",
    "        \"bitsandbytes>=0.43.0\",\n",
    "        \"pandas\",\n",
    "        \"numpy\",\n",
    "        \"scikit-learn\",\n",
    "        \"tqdm\",\n",
    "    ]\n",
    "    \n",
    "    print(\"üì¶ Installing required packages...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages)\n",
    "    print(\"‚úÖ Packages installed successfully!\")\n",
    "\n",
    "# Uncomment to install (if needed)\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca213dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T09:34:49.355989Z",
     "iopub.status.busy": "2025-10-20T09:34:49.355660Z",
     "iopub.status.idle": "2025-10-20T09:35:28.127511Z",
     "shell.execute_reply": "2025-10-20T09:35:28.126473Z"
    },
    "papermill": {
     "duration": 38.784099,
     "end_time": "2025-10-20T09:35:28.133514",
     "exception": false,
     "start_time": "2025-10-20T09:34:49.349415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 09:35:12.965660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760952913.206375      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760952913.273706      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß PyTorch version: 2.6.0+cu124\n",
      "üîß Transformers version: 4.53.3\n",
      "üîß PEFT version: 0.16.0\n",
      "üîß Device: CPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import peft\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
    "print(f\"üîß Transformers version: {transformers.__version__}\")\n",
    "print(f\"üîß PEFT version: {peft.__version__}\")\n",
    "print(f\"üîß Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55deb64",
   "metadata": {
    "papermill": {
     "duration": 0.005239,
     "end_time": "2025-10-20T09:35:28.144620",
     "exception": false,
     "start_time": "2025-10-20T09:35:28.139381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2Ô∏è‚É£ Configuration and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8827c041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T09:35:28.157246Z",
     "iopub.status.busy": "2025-10-20T09:35:28.156523Z",
     "iopub.status.idle": "2025-10-20T09:35:28.169649Z",
     "shell.execute_reply": "2025-10-20T09:35:28.168544Z"
    },
    "papermill": {
     "duration": 0.021474,
     "end_time": "2025-10-20T09:35:28.171462",
     "exception": false,
     "start_time": "2025-10-20T09:35:28.149988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÇÔ∏è  Running on: Kaggle\n",
      "üìÇ Dataset: /kaggle/input/fraud-dataset/final_fraud_detection_dataset.csv\n",
      "ü§ñ Model: /kaggle/input/scam-detector-lora/other/default/1/scam-detector-lora\n",
      "üíæ Output: /kaggle/working\n",
      "‚úÖ Dataset found!\n",
      "‚úÖ Model found!\n"
     ]
    }
   ],
   "source": [
    "# Detect environment (Kaggle or Local)\n",
    "IS_KAGGLE = Path('/kaggle').exists()\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    # Kaggle paths - update these based on your Kaggle dataset names\n",
    "    OUTPUT_DIR = Path('/kaggle/working')\n",
    "    # Dataset path - adjust the dataset name if different\n",
    "    DATASET_PATH = Path('/kaggle/input/fraud-dataset/final_fraud_detection_dataset.csv')\n",
    "    # Model path - using the uploaded scam-detector-lora\n",
    "    MODEL_PATH = Path('/kaggle/input/scam-detector-lora/other/default/1/scam-detector-lora')\n",
    "else:\n",
    "    # Local paths\n",
    "    BASE_DIR = Path('/Users/admin/Desktop/Workbench/Baseline Demo')\n",
    "    OUTPUT_DIR = BASE_DIR / 'runs'\n",
    "    DATASET_PATH = BASE_DIR / 'final_fraud_detection_dataset.csv'\n",
    "    MODEL_PATH = BASE_DIR / 'models' / 'scam-detector-lora'\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üóÇÔ∏è  Running on: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
    "print(f\"üìÇ Dataset: {DATASET_PATH}\")\n",
    "print(f\"ü§ñ Model: {MODEL_PATH}\")\n",
    "print(f\"üíæ Output: {OUTPUT_DIR}\")\n",
    "\n",
    "# Check paths exist\n",
    "if DATASET_PATH.exists():\n",
    "    print(f\"‚úÖ Dataset found!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Dataset not found at {DATASET_PATH}\")\n",
    "    # Try to find it in other locations\n",
    "    if IS_KAGGLE:\n",
    "        possible_paths = list(Path('/kaggle/input').glob('**/final_fraud_detection_dataset.csv'))\n",
    "        if possible_paths:\n",
    "            DATASET_PATH = possible_paths[0]\n",
    "            print(f\"‚úÖ Found dataset at: {DATASET_PATH}\")\n",
    "        else:\n",
    "            print(\"‚ùå Dataset not found. Please check Kaggle input datasets.\")\n",
    "\n",
    "if MODEL_PATH.exists():\n",
    "    print(f\"‚úÖ Model found!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Model not found at {MODEL_PATH}\")\n",
    "    if IS_KAGGLE:\n",
    "        # Try to find model in other locations\n",
    "        possible_models = list(Path('/kaggle/input').glob('**/scam-detector-lora'))\n",
    "        if possible_models:\n",
    "            MODEL_PATH = possible_models[0]\n",
    "            print(f\"‚úÖ Found model at: {MODEL_PATH}\")\n",
    "        else:\n",
    "            print(\"‚ùå Model not found. Please check Kaggle input datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a9899a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T09:35:28.184588Z",
     "iopub.status.busy": "2025-10-20T09:35:28.184255Z",
     "iopub.status.idle": "2025-10-20T09:35:28.190518Z",
     "shell.execute_reply": "2025-10-20T09:35:28.189531Z"
    },
    "papermill": {
     "duration": 0.014205,
     "end_time": "2025-10-20T09:35:28.191868",
     "exception": false,
     "start_time": "2025-10-20T09:35:28.177663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n"
     ]
    }
   ],
   "source": [
    "# Model Configuration\n",
    "CONFIG = {\n",
    "    'model_name': 'unsloth/llama-3-8b-instruct-bnb-4bit',\n",
    "    'adapter_path': str(MODEL_PATH),\n",
    "    'max_length': 512,\n",
    "    'generation_max_length': 256,\n",
    "    'temperature': 0.7,\n",
    "    'top_p': 0.9,\n",
    "    'top_k': 50,\n",
    "    'repetition_penalty': 1.1,\n",
    "    'test_size': 0.2,\n",
    "    'random_seed': 42,\n",
    "    'batch_size': 8,  # Adjust based on GPU memory\n",
    "    'sample_size': 500,  # Number of samples to test (set to None for full dataset)\n",
    "}\n",
    "\n",
    "# Fraud categories\n",
    "FRAUD_CATEGORIES = [\n",
    "    'job_scam',\n",
    "    'legitimate',\n",
    "    'phishing',\n",
    "    'popup_scam',\n",
    "    'refund_scam',\n",
    "    'reward_scam',\n",
    "    'sms_spam',\n",
    "    'ssn_scam',\n",
    "    'tech_support_scam'\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3242fb",
   "metadata": {
    "papermill": {
     "duration": 0.004978,
     "end_time": "2025-10-20T09:35:28.202368",
     "exception": false,
     "start_time": "2025-10-20T09:35:28.197390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3Ô∏è‚É£ Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c53293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T09:35:28.214044Z",
     "iopub.status.busy": "2025-10-20T09:35:28.213754Z",
     "iopub.status.idle": "2025-10-20T09:35:32.947582Z",
     "shell.execute_reply": "2025-10-20T09:35:32.946369Z"
    },
    "papermill": {
     "duration": 4.74158,
     "end_time": "2025-10-20T09:35:32.949238",
     "exception": false,
     "start_time": "2025-10-20T09:35:28.207658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading dataset...\n",
      "\n",
      "üìà Dataset shape: (194913, 4)\n",
      "\n",
      "üìã Columns: ['text', 'binary_label', 'detailed_category', 'data_type']\n",
      "\n",
      "üîç First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>detailed_category</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Position Summary The Asset Manager will plan, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>job_scam</td>\n",
       "      <td>text_classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We offer interns that can develop web sites re...</td>\n",
       "      <td>1</td>\n",
       "      <td>job_scam</td>\n",
       "      <td>text_classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are a Health Benefits company. Helping peop...</td>\n",
       "      <td>1</td>\n",
       "      <td>job_scam</td>\n",
       "      <td>text_classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apply using below link Clinical Director - Sur...</td>\n",
       "      <td>1</td>\n",
       "      <td>job_scam</td>\n",
       "      <td>text_classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking for an Assistant Accountant to join a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>job_scam</td>\n",
       "      <td>text_classification</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  binary_label  \\\n",
       "0  Position Summary The Asset Manager will plan, ...             1   \n",
       "1  We offer interns that can develop web sites re...             1   \n",
       "2  We are a Health Benefits company. Helping peop...             1   \n",
       "3  Apply using below link Clinical Director - Sur...             1   \n",
       "4  Looking for an Assistant Accountant to join a ...             1   \n",
       "\n",
       "  detailed_category            data_type  \n",
       "0          job_scam  text_classification  \n",
       "1          job_scam  text_classification  \n",
       "2          job_scam  text_classification  \n",
       "3          job_scam  text_classification  \n",
       "4          job_scam  text_classification  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Category distribution:\n",
      "detailed_category\n",
      "legitimate           101717\n",
      "phishing              71857\n",
      "popup_scam            11333\n",
      "sms_spam               6988\n",
      "reward_scam             606\n",
      "tech_support_scam       605\n",
      "refund_scam             604\n",
      "ssn_scam                604\n",
      "job_scam                599\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÇÔ∏è  Sampling 500 examples for testing...\n",
      "\n",
      "‚úÖ Test set size: 500 samples\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"üìä Loading dataset...\")\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "print(f\"\\nüìà Dataset shape: {df.shape}\")\n",
    "print(f\"\\nüìã Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nüîç First few rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Check category distribution\n",
    "print(\"\\nüìä Category distribution:\")\n",
    "print(df['detailed_category'].value_counts())\n",
    "\n",
    "# Sample for testing (if specified)\n",
    "if CONFIG['sample_size'] is not None:\n",
    "    print(f\"\\n‚úÇÔ∏è  Sampling {CONFIG['sample_size']} examples for testing...\")\n",
    "    df_test = df.sample(n=min(CONFIG['sample_size'], len(df)), random_state=CONFIG['random_seed'])\n",
    "else:\n",
    "    df_test = df.copy()\n",
    "\n",
    "print(f\"\\n‚úÖ Test set size: {len(df_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e3f96b",
   "metadata": {
    "papermill": {
     "duration": 0.00542,
     "end_time": "2025-10-20T09:35:32.960759",
     "exception": false,
     "start_time": "2025-10-20T09:35:32.955339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4Ô∏è‚É£ Load Model with LoRA Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22fbf2d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T09:35:32.974810Z",
     "iopub.status.busy": "2025-10-20T09:35:32.974033Z",
     "iopub.status.idle": "2025-10-20T09:35:33.213528Z",
     "shell.execute_reply": "2025-10-20T09:35:33.212328Z"
    },
    "papermill": {
     "duration": 0.247985,
     "end_time": "2025-10-20T09:35:33.215011",
     "exception": true,
     "start_time": "2025-10-20T09:35:32.967026",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Loading model and LoRA adapter...\n"
     ]
    },
    {
     "ename": "PackageNotFoundError",
     "evalue": "No package metadata was found for bitsandbytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/958759980.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Configure 4-bit quantization for efficient inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m bnb_config = BitsAndBytesConfig(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mload_in_4bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbnb_4bit_use_double_quant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load_in_8bit, load_in_4bit, llm_int8_threshold, llm_int8_skip_modules, llm_int8_enable_fp32_cpu_offload, llm_int8_has_fp16_weight, bnb_4bit_compute_dtype, bnb_4bit_quant_type, bnb_4bit_use_double_quant, bnb_4bit_quant_storage, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unused kwargs: {list(kwargs.keys())}. These kwargs are not used in {self.__class__}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36mpost_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bnb_4bit_use_double_quant must be a boolean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         if self.load_in_4bit and not version.parse(importlib.metadata.version(\"bitsandbytes\")) >= version.parse(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;34m\"0.39.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         ):\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mversion\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;34m\"Version\"\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \"\"\"\n\u001b[0;32m-> 1009\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mdistribution\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mthereof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \"\"\"\n\u001b[0;32m--> 982\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPackageNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPackageNotFoundError\u001b[0m: No package metadata was found for bitsandbytes"
     ]
    }
   ],
   "source": [
    "print(\"ü§ñ Loading model and LoRA adapter...\")\n",
    "\n",
    "# Configure 4-bit quantization for efficient inference\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load base model\n",
    "print(\"\\nüì• Loading base model...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    CONFIG['model_name'],\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "print(\"üì• Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG['adapter_path'])\n",
    "\n",
    "# Ensure tokenizer has padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load LoRA adapter\n",
    "print(\"üì• Loading LoRA adapter...\")\n",
    "model = PeftModel.from_pretrained(base_model, CONFIG['adapter_path'])\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "print(f\"üîß Model device: {next(model.parameters()).device}\")\n",
    "print(f\"üîß Model dtype: {next(model.parameters()).dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf9ed0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5Ô∏è‚É£ Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d7d61",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_classification_prompt(text):\n",
    "    \"\"\"Create prompt for classification task\"\"\"\n",
    "    prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are an expert fraud detection system. Analyze the given message and classify it into one of these categories:\n",
    "- job_scam: Fraudulent job offers or work-from-home scams\n",
    "- phishing: Attempts to steal personal information or credentials\n",
    "- popup_scam: Fake alerts or popup warnings\n",
    "- refund_scam: Fake refund or payment requests\n",
    "- reward_scam: Fake prize or lottery winnings\n",
    "- sms_spam: Unsolicited commercial messages\n",
    "- ssn_scam: Social security number theft attempts\n",
    "- tech_support_scam: Fake technical support scams\n",
    "- legitimate: Genuine, non-fraudulent messages\n",
    "\n",
    "Respond with ONLY the category name.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Classify this message:\n",
    "{text[:500]}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def create_reasoning_prompt(text):\n",
    "    \"\"\"Create prompt for reasoning/explanation task\"\"\"\n",
    "    prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are an expert fraud detection system. Analyze the given message and:\n",
    "1. Determine if it's fraudulent or legitimate\n",
    "2. Identify the specific type of fraud (if applicable)\n",
    "3. Provide a detailed explanation of your reasoning\n",
    "4. Point out specific red flags or indicators\n",
    "\n",
    "Be thorough and educational in your explanation.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Analyze this message and explain your reasoning:\n",
    "{text[:500]}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Test prompts\n",
    "test_text = \"URGENT: Your bank account has been compromised. Click here immediately to secure it.\"\n",
    "print(\"üß™ Sample Classification Prompt:\")\n",
    "print(\"=\"*80)\n",
    "print(create_classification_prompt(test_text))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nüß™ Sample Reasoning Prompt:\")\n",
    "print(\"=\"*80)\n",
    "print(create_reasoning_prompt(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9294e192",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6Ô∏è‚É£ Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39496e45",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_response(prompt, max_length=256, temperature=0.7, top_p=0.9, top_k=50):\n",
    "    \"\"\"Generate response from the model\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=CONFIG['max_length'])\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_length,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            repetition_penalty=CONFIG['repetition_penalty'],\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract only the assistant's response\n",
    "    if \"assistant\" in response:\n",
    "        response = response.split(\"assistant\")[-1].strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "def classify_message(text):\n",
    "    \"\"\"Classify a message into fraud category\"\"\"\n",
    "    prompt = create_classification_prompt(text)\n",
    "    response = generate_response(prompt, max_length=50, temperature=0.3)\n",
    "    \n",
    "    # Extract category from response\n",
    "    response_lower = response.lower().strip()\n",
    "    \n",
    "    # Try to find exact match\n",
    "    for category in FRAUD_CATEGORIES:\n",
    "        if category in response_lower:\n",
    "            return category\n",
    "    \n",
    "    # Return the first line of response if no match found\n",
    "    return response_lower.split('\\n')[0].strip()\n",
    "\n",
    "def explain_reasoning(text):\n",
    "    \"\"\"Generate explanation for fraud detection\"\"\"\n",
    "    prompt = create_reasoning_prompt(text)\n",
    "    response = generate_response(\n",
    "        prompt, \n",
    "        max_length=CONFIG['generation_max_length'],\n",
    "        temperature=CONFIG['temperature']\n",
    "    )\n",
    "    return response\n",
    "\n",
    "print(\"‚úÖ Inference functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1697a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7Ô∏è‚É£ Test on Sample Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180ee37",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test with a few examples first\n",
    "sample_messages = [\n",
    "    {\n",
    "        'text': \"URGENT: Your bank account has been compromised. Click here to verify your identity immediately or your account will be closed.\",\n",
    "        'expected': 'phishing'\n",
    "    },\n",
    "    {\n",
    "        'text': \"Hi John, thanks for your email. The meeting is scheduled for tomorrow at 2 PM in conference room B. See you there!\",\n",
    "        'expected': 'legitimate'\n",
    "    },\n",
    "    {\n",
    "        'text': \"Congratulations! You've won $10,000 in our lottery. Send your bank details to claim your prize.\",\n",
    "        'expected': 'reward_scam'\n",
    "    },\n",
    "    {\n",
    "        'text': \"ALERT: Your computer is infected with 5 viruses! Call 1-800-FAKE-TECH immediately for free virus removal.\",\n",
    "        'expected': 'tech_support_scam'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing model on sample messages\\n\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for i, sample in enumerate(sample_messages, 1):\n",
    "    print(f\"\\nüìù Example {i}:\")\n",
    "    print(f\"Text: {sample['text'][:100]}...\")\n",
    "    print(f\"Expected: {sample['expected']}\")\n",
    "    \n",
    "    # Classification\n",
    "    predicted = classify_message(sample['text'])\n",
    "    print(f\"Predicted: {predicted}\")\n",
    "    print(f\"Match: {'‚úÖ' if predicted == sample['expected'] else '‚ùå'}\")\n",
    "    \n",
    "    # Reasoning\n",
    "    print(f\"\\nüí≠ Reasoning:\")\n",
    "    reasoning = explain_reasoning(sample['text'])\n",
    "    print(reasoning[:300] + \"...\" if len(reasoning) > 300 else reasoning)\n",
    "    print(\"\\n\" + \"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90b117",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 8Ô∏è‚É£ Batch Classification on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf521d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"üöÄ Running batch classification on test set...\\n\")\n",
    "\n",
    "# Store results\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "# Process in batches\n",
    "for idx, row in tqdm(df_test.iterrows(), total=len(df_test), desc=\"Classifying\"):\n",
    "    text = row['text']\n",
    "    true_label = row['detailed_category']\n",
    "    \n",
    "    try:\n",
    "        predicted_label = classify_message(text)\n",
    "        predictions.append(predicted_label)\n",
    "        ground_truth.append(true_label)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è  Error processing sample {idx}: {e}\")\n",
    "        predictions.append('error')\n",
    "        ground_truth.append(true_label)\n",
    "\n",
    "print(\"\\n‚úÖ Classification completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1cf37",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 9Ô∏è‚É£ Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12d390",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(ground_truth, predictions)\n",
    "print(f\"\\nüìä Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\\n\")\n",
    "\n",
    "# Calculate precision, recall, F1 per class\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    ground_truth, \n",
    "    predictions, \n",
    "    labels=FRAUD_CATEGORIES,\n",
    "    average=None,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# Create metrics dataframe\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Category': FRAUD_CATEGORIES,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Support': support\n",
    "})\n",
    "\n",
    "print(\"\\nüìà Per-Category Metrics:\")\n",
    "print(\"=\"*80)\n",
    "display(metrics_df.sort_values('F1-Score', ascending=False))\n",
    "\n",
    "# Calculate macro and weighted averages\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "    ground_truth, predictions, average='macro', zero_division=0\n",
    ")\n",
    "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "    ground_truth, predictions, average='weighted', zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Average Metrics:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Macro Avg    - Precision: {precision_macro:.4f}, Recall: {recall_macro:.4f}, F1: {f1_macro:.4f}\")\n",
    "print(f\"Weighted Avg - Precision: {precision_weighted:.4f}, Recall: {recall_weighted:.4f}, F1: {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cdf3ba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## üîü Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc07447",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\nüìã Detailed Classification Report:\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(ground_truth, predictions, labels=FRAUD_CATEGORIES, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee5c29a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f285f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(ground_truth, predictions, labels=FRAUD_CATEGORIES)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=FRAUD_CATEGORIES, \n",
    "            yticklabels=FRAUD_CATEGORIES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - Scam Detector LoRA')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüíæ Confusion matrix saved to: {OUTPUT_DIR / 'confusion_matrix.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b82f54",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Generate Reasoning for Sample Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7f45c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample cases for reasoning generation (correct and incorrect predictions)\n",
    "print(\"üß† Generating detailed reasoning for sample cases...\\n\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Get some correct predictions\n",
    "correct_mask = [p == t for p, t in zip(predictions, ground_truth)]\n",
    "correct_indices = [i for i, correct in enumerate(correct_mask) if correct]\n",
    "\n",
    "# Get some incorrect predictions\n",
    "incorrect_indices = [i for i, correct in enumerate(correct_mask) if not correct]\n",
    "\n",
    "# Sample 3 correct and 3 incorrect\n",
    "sample_correct = np.random.choice(correct_indices, min(3, len(correct_indices)), replace=False)\n",
    "sample_incorrect = np.random.choice(incorrect_indices, min(3, len(incorrect_indices)), replace=False)\n",
    "\n",
    "reasoning_results = []\n",
    "\n",
    "print(\"\\n‚úÖ CORRECT PREDICTIONS:\\n\")\n",
    "for idx in sample_correct:\n",
    "    row = df_test.iloc[idx]\n",
    "    text = row['text']\n",
    "    true_label = ground_truth[idx]\n",
    "    pred_label = predictions[idx]\n",
    "    \n",
    "    print(f\"\\nüìù Text: {text[:200]}...\")\n",
    "    print(f\"‚úÖ True: {true_label} | Predicted: {pred_label}\")\n",
    "    print(f\"\\nüí≠ Reasoning:\")\n",
    "    reasoning = explain_reasoning(text)\n",
    "    print(reasoning)\n",
    "    print(\"\\n\" + \"-\"*100)\n",
    "    \n",
    "    reasoning_results.append({\n",
    "        'text': text,\n",
    "        'true_label': true_label,\n",
    "        'predicted_label': pred_label,\n",
    "        'correct': True,\n",
    "        'reasoning': reasoning\n",
    "    })\n",
    "\n",
    "print(\"\\n\\n‚ùå INCORRECT PREDICTIONS:\\n\")\n",
    "for idx in sample_incorrect:\n",
    "    row = df_test.iloc[idx]\n",
    "    text = row['text']\n",
    "    true_label = ground_truth[idx]\n",
    "    pred_label = predictions[idx]\n",
    "    \n",
    "    print(f\"\\nüìù Text: {text[:200]}...\")\n",
    "    print(f\"‚ùå True: {true_label} | Predicted: {pred_label}\")\n",
    "    print(f\"\\nüí≠ Reasoning:\")\n",
    "    reasoning = explain_reasoning(text)\n",
    "    print(reasoning)\n",
    "    print(\"\\n\" + \"-\"*100)\n",
    "    \n",
    "    reasoning_results.append({\n",
    "        'text': text,\n",
    "        'true_label': true_label,\n",
    "        'predicted_label': pred_label,\n",
    "        'correct': False,\n",
    "        'reasoning': reasoning\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ea944",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f98574",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results_df = df_test.copy()\n",
    "results_df['predicted_category'] = predictions\n",
    "results_df['correct'] = [p == t for p, t in zip(predictions, ground_truth)]\n",
    "\n",
    "# Save classification results\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "results_file = OUTPUT_DIR / f'scam_detector_lora_results_{timestamp}.csv'\n",
    "results_df.to_csv(results_file, index=False)\n",
    "print(f\"\\nüíæ Classification results saved to: {results_file}\")\n",
    "\n",
    "# Save reasoning results\n",
    "reasoning_df = pd.DataFrame(reasoning_results)\n",
    "reasoning_file = OUTPUT_DIR / f'scam_detector_lora_reasoning_{timestamp}.csv'\n",
    "reasoning_df.to_csv(reasoning_file, index=False)\n",
    "print(f\"üíæ Reasoning results saved to: {reasoning_file}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_file = OUTPUT_DIR / f'scam_detector_lora_metrics_{timestamp}.csv'\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"üíæ Metrics saved to: {metrics_file}\")\n",
    "\n",
    "# Save summary report\n",
    "summary_file = OUTPUT_DIR / f'scam_detector_lora_summary_{timestamp}.txt'\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"SCAM DETECTOR LORA - TEST RESULTS SUMMARY\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(f\"Test Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Model: {CONFIG['model_name']}\\n\")\n",
    "    f.write(f\"Adapter: {CONFIG['adapter_path']}\\n\")\n",
    "    f.write(f\"Test Samples: {len(df_test)}\\n\\n\")\n",
    "    f.write(f\"Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\\n\\n\")\n",
    "    f.write(f\"Macro Avg    - Precision: {precision_macro:.4f}, Recall: {recall_macro:.4f}, F1: {f1_macro:.4f}\\n\")\n",
    "    f.write(f\"Weighted Avg - Precision: {precision_weighted:.4f}, Recall: {recall_weighted:.4f}, F1: {f1_weighted:.4f}\\n\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"PER-CATEGORY METRICS\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(metrics_df.to_string())\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"CLASSIFICATION REPORT\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(classification_report(ground_truth, predictions, labels=FRAUD_CATEGORIES, zero_division=0))\n",
    "\n",
    "print(f\"üíæ Summary report saved to: {summary_file}\")\n",
    "print(\"\\n‚úÖ All results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f00a07",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1Ô∏è‚É£4Ô∏è‚É£ Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617a7b8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüéØ Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"\\nüìà Best Performing Categories (by F1-Score):\")\n",
    "top_categories = metrics_df.nlargest(3, 'F1-Score')[['Category', 'F1-Score', 'Support']]\n",
    "for _, row in top_categories.iterrows():\n",
    "    print(f\"   {row['Category']:20s} F1: {row['F1-Score']:.4f} (n={int(row['Support'])})\")\n",
    "\n",
    "print(f\"\\nüìâ Categories Needing Improvement (by F1-Score):\")\n",
    "bottom_categories = metrics_df.nsmallest(3, 'F1-Score')[['Category', 'F1-Score', 'Support']]\n",
    "for _, row in bottom_categories.iterrows():\n",
    "    print(f\"   {row['Category']:20s} F1: {row['F1-Score']:.4f} (n={int(row['Support'])})\")\n",
    "\n",
    "print(f\"\\nüéØ Fraud Detection Performance:\")\n",
    "fraud_categories = [c for c in FRAUD_CATEGORIES if c != 'legitimate']\n",
    "fraud_mask = [t in fraud_categories for t in ground_truth]\n",
    "fraud_accuracy = accuracy_score(\n",
    "    [ground_truth[i] for i, is_fraud in enumerate(fraud_mask) if is_fraud],\n",
    "    [predictions[i] for i, is_fraud in enumerate(fraud_mask) if is_fraud]\n",
    ")\n",
    "print(f\"   Fraud Category Accuracy: {fraud_accuracy:.4f} ({fraud_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Binary classification (fraud vs legitimate)\n",
    "binary_ground_truth = ['fraud' if t != 'legitimate' else 'legitimate' for t in ground_truth]\n",
    "binary_predictions = ['fraud' if p != 'legitimate' else 'legitimate' for p in predictions]\n",
    "binary_accuracy = accuracy_score(binary_ground_truth, binary_predictions)\n",
    "print(f\"   Binary Classification (Fraud vs Legitimate): {binary_accuracy:.4f} ({binary_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Testing completed successfully!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8286057,
     "sourceId": 13082789,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 477180,
     "modelInstanceId": 461425,
     "sourceId": 614066,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 52.327852,
   "end_time": "2025-10-20T09:35:36.624181",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-20T09:34:44.296329",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
