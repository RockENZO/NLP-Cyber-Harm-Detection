{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13082789,"sourceType":"datasetVersion","datasetId":8286057},{"sourceId":582088,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":434559,"modelId":451413}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install required packages for local reasoning\n!pip install transformers torch accelerate --quiet\n\n# Import libraries\nimport pandas as pd\nimport numpy as np\nimport torch\nimport warnings\nimport json\nimport os\nfrom pathlib import Path\nimport time\nfrom datetime import datetime\n\nwarnings.filterwarnings('ignore')\n\nprint(\"🚀 Fraud Detection Reasoning Environment Setup\")\nprint(\"=\" * 50)\nprint(f\"✅ GPU Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"🎮 GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\nelse:\n    print(\"⚠️  Using CPU - consider enabling GPU accelerator\")\n\nprint(\"✅ Environment ready for local reasoning!\")","metadata":{"colab_type":"code","vscode":{"languageId":"python"},"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:17:45.038996Z","iopub.execute_input":"2025-09-17T03:17:45.039295Z","iopub.status.idle":"2025-09-17T03:19:22.936786Z","shell.execute_reply.started":"2025-09-17T03:17:45.039272Z","shell.execute_reply":"2025-09-17T03:19:22.935882Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h🚀 Fraud Detection Reasoning Environment Setup\n==================================================\n✅ GPU Available: True\n🎮 GPU: Tesla T4\n💾 GPU Memory: 15.8 GB\n✅ Environment ready for local reasoning!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 🧠 Local Fraud Detection Reasoning on Kaggle\n\nThis notebook provides **local AI-powered reasoning** for fraud detection using Kaggle's GPU resources instead of paid APIs.\n\n## 🚀 SETUP INSTRUCTIONS FOR KAGGLE\n\n### Step 1: Upload Your Trained Model\n1. **Create a Kaggle Dataset** with your trained model files:\n   - Upload your `distilbert_model/` folder (contains config.json, model.safetensors)\n   - Upload your `distilbert_tokenizer/` folder (contains tokenizer files)\n   - Name your dataset (e.g., \"fraud-detection-models\")\n\n### Step 2: Add Dataset to This Notebook\n1. **Add your dataset as input** to this notebook:\n   - Click \"Add data\" → \"Your datasets\" → Select your model dataset\n   - This makes your model files available at `/kaggle/input/your-dataset-name/`\n\n### Step 3: Update Model Paths\n1. **Update the paths in Cell 4** to match your dataset name:\n   ```python\n   MODEL_PATH = '/kaggle/input/YOUR-DATASET-NAME/distilbert_model'\n   TOKENIZER_PATH = '/kaggle/input/YOUR-DATASET-NAME/distilbert_tokenizer'\n   ```\n\n### Step 4: Run the Notebook\n1. **Enable GPU accelerator** for faster inference\n2. **Run all cells** to load your model and start analyzing texts\n\n## 📊 Pipeline Flow\n1. **Load** your trained DistilBERT model from Kaggle dataset\n2. **Classify** texts into fraud categories using your actual model  \n3. **Generate reasoning** using local LM for non-legitimate classifications\n4. **Download** results with explanations\n\n## 🔧 Requirements\n- Your trained `distilbert_model/` and `distilbert_tokenizer/` uploaded as a Kaggle dataset\n- GPU accelerator enabled for faster inference\n- No API keys needed - everything runs locally!\n\n## ⚠️ Important Notes\n- **Without proper model upload**: Notebook will run in demo mode with simulated results\n- **With proper model upload**: You get real AI-powered fraud detection and reasoning\n- The reasoning engine works with ANY classification result (real or demo)","metadata":{"colab_type":"text"}},{"cell_type":"code","source":"# Load Local Language Model for Reasoning (Free Alternative to APIs)\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n\nprint(\"🧠 Loading Local Language Model for Reasoning...\")\n\n# Use a smaller, efficient model that works well on Kaggle's free tier\n# Options: 'microsoft/DialoGPT-medium', 'gpt2', 'distilgpt2'\nreasoning_model_name = \"microsoft/DialoGPT-medium\"  # Good balance of quality and speed\n\ntry:\n    # Initialize reasoning pipeline\n    reasoning_pipe = pipeline(\n        \"text-generation\",\n        model=reasoning_model_name,\n        device=0 if torch.cuda.is_available() else -1,  # Use GPU if available\n        do_sample=True,\n        temperature=0.7,\n        max_length=512,\n        pad_token_id=50256  # Set pad token to avoid warnings\n    )\n    \n    print(f\"✅ Local reasoning model loaded: {reasoning_model_name}\")\n    print(\"💡 This model will generate explanations locally (no API costs!)\")\n    \n    # Test the reasoning model\n    test_prompt = \"This text appears to be a scam because\"\n    test_response = reasoning_pipe(test_prompt, max_length=50, num_return_sequences=1)\n    print(\"🧪 Model test successful!\")\n    \nexcept Exception as e:\n    print(f\"⚠️  Error loading model: {e}\")\n    print(\"Falling back to simpler model...\")\n    # Fallback to smaller model\n    reasoning_pipe = pipeline(\"text-generation\", model=\"distilgpt2\", device=0 if torch.cuda.is_available() else -1)","metadata":{"colab_type":"code","vscode":{"languageId":"python"},"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:19:22.938852Z","iopub.execute_input":"2025-09-17T03:19:22.939311Z","iopub.status.idle":"2025-09-17T03:20:08.713010Z","shell.execute_reply.started":"2025-09-17T03:19:22.939281Z","shell.execute_reply":"2025-09-17T03:20:08.712122Z"}},"outputs":[{"name":"stderr","text":"2025-09-17 03:19:35.390727: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758079175.738730      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758079175.840719      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"🧠 Loading Local Language Model for Reasoning...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed91ad606ab5421693fd384aef3de406"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc53762effb946cc976784b62a3eb561"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/863M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94303b24797b445db1ed0d8c482888f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dc2972b38b1446292a2e171a34fa045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"384725ba98b3427791b38e3e9378a4f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f39ebc9a6ad47d2927c7dfcdd5413b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"895b80d942a3441bb2055675cc9bd63b"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"✅ Local reasoning model loaded: microsoft/DialoGPT-medium\n💡 This model will generate explanations locally (no API costs!)\n🧪 Model test successful!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# 🧪 LLM Testing Framework - Compare Multiple Models\n\nThis section tests different language models to find the best one for fraud detection reasoning. We'll evaluate:\n- **Quality**: How well does the model explain fraud patterns?\n- **Speed**: How fast is inference?\n- **Memory**: How much GPU/CPU memory does it use?\n- **Coherence**: How readable and logical are the explanations?\n\n## Models to Test:\n1. **microsoft/DialoGPT-medium** - Conversational AI (current)\n2. **gpt2** - Standard GPT-2 model\n3. **distilgpt2** - Smaller, faster GPT-2\n4. **microsoft/DialoGPT-small** - Smaller conversational model\n5. **EleutherAI/gpt-neo-125M** - Neo model (if available)\n\nEach model will be tested on the same fraud examples to compare output quality.","metadata":{}},{"cell_type":"code","source":"# Enhanced Multi-Model Testing Framework for Fraud Reasoning\nimport time\nimport gc\nimport traceback\nimport re\nfrom typing import Dict, List, Tuple\nfrom collections import Counter\n\nclass EnhancedLLMTester:\n    \"\"\"Test multiple language models for fraud detection reasoning with comprehensive quality metrics\"\"\"\n    \n    def __init__(self):\n        self.models_to_test = [\n            {\n                'name': 'microsoft/DialoGPT-medium',\n                'type': 'conversational',\n                'size': 'medium',\n                'description': 'Conversational AI optimized for dialogue'\n            },\n            {\n                'name': 'gpt2',\n                'type': 'causal',\n                'size': 'medium', \n                'description': 'Standard GPT-2 model'\n            },\n            {\n                'name': 'distilgpt2',\n                'type': 'causal',\n                'size': 'small',\n                'description': 'Distilled GPT-2 (faster, smaller)'\n            },\n            {\n                'name': 'microsoft/DialoGPT-small',\n                'type': 'conversational',\n                'size': 'small',\n                'description': 'Smaller conversational model'\n            }\n        ]\n        \n        # Load real test cases from CSV dataset\n        self.test_cases = []\n        self.load_real_test_cases()\n        \n        # Comprehensive quality indicators for fraud reasoning\n        self.quality_indicators = {\n            'fraud_keywords': [\n                'scam', 'fraud', 'fraudulent', 'suspicious', 'fake', 'phishing', 'deceptive', \n                'malicious', 'illegitimate', 'unauthorized', 'impersonation', 'steal', 'theft',\n                'criminal', 'illegal', 'dangerous', 'harmful', 'misleading', 'dishonest'\n            ],\n            'urgency_indicators': [\n                'urgent', 'immediate', 'emergency', 'critical', 'expires', 'deadline',\n                'limited time', 'act now', 'hurry', 'quickly', 'asap', 'time sensitive'\n            ],\n            'financial_indicators': [\n                'money', 'payment', 'prize', 'reward', 'fee', 'cost', 'charge', 'refund',\n                'billing', 'account', 'bank', 'credit', 'deposit', 'transfer', 'claim'\n            ],\n            'action_indicators': [\n                'click', 'call', 'contact', 'verify', 'confirm', 'update', 'download',\n                'install', 'visit', 'respond', 'reply', 'submit', 'provide', 'send'\n            ],\n            'technical_indicators': [\n                'virus', 'malware', 'infected', 'security', 'breach', 'hacked', 'compromised',\n                'system', 'computer', 'device', 'software', 'update', 'patch', 'support'\n            ],\n            'social_engineering': [\n                'trust', 'authority', 'official', 'government', 'legitimate', 'verify',\n                'confirm', 'identity', 'personal', 'confidential', 'private', 'secure'\n            ],\n            'emotional_manipulation': [\n                'fear', 'panic', 'worry', 'concern', 'anxiety', 'stress', 'relief',\n                'excitement', 'congratulations', 'winner', 'lucky', 'selected', 'special'\n            ],\n            'explanation_quality': [\n                'because', 'since', 'due to', 'reason', 'explains', 'indicates', 'suggests',\n                'shows', 'demonstrates', 'reveals', 'exposes', 'highlights', 'pattern'\n            ]\n        }\n        \n        self.results = {}\n    \n    def load_real_test_cases(self):\n        \"\"\"Load test cases from the actual CSV dataset\"\"\"\n        print(\"📄 Loading real test cases from CSV dataset...\")\n        \n        try:\n            # Try to load a sample of the dataset\n            import pandas as pd\n            \n            # Load dataset (adjust path as needed)\n            csv_path = '/kaggle/input/fraud-dataset/final_fraud_detection_dataset.csv'\n            if not os.path.exists(csv_path):\n                csv_path = '/kaggle/input/fraud-detection-dataset/final_fraud_detection_dataset.csv'\n            \n            if os.path.exists(csv_path):\n                # Load a sample of each fraud type for testing\n                print(f\"✅ Found dataset at: {csv_path}\")\n                \n                # Read dataset in chunks to handle large files\n                chunk_size = 1000\n                sample_cases = []\n                \n                for chunk in pd.read_csv(csv_path, chunksize=chunk_size):\n                    # Get samples from each category\n                    for category in chunk['detailed_category'].unique():\n                        category_samples = chunk[chunk['detailed_category'] == category].head(2)\n                        for _, row in category_samples.iterrows():\n                            if len(sample_cases) < 20:  # Limit to 20 test cases\n                                sample_cases.append({\n                                    'type': row['detailed_category'],\n                                    'text': row['text'][:500],  # Limit text length\n                                    'true_label': row['detailed_category']\n                                })\n                    \n                    if len(sample_cases) >= 20:\n                        break\n                \n                self.test_cases = sample_cases\n                print(f\"✅ Loaded {len(self.test_cases)} real test cases from dataset\")\n                \n                # Show categories loaded\n                categories = Counter([case['type'] for case in self.test_cases])\n                print(\"📊 Test cases by category:\")\n                for category, count in categories.items():\n                    print(f\"   {category}: {count} cases\")\n                \n            else:\n                print(\"⚠️  CSV dataset not found, using fallback test cases\")\n                self.load_fallback_test_cases()\n                \n        except Exception as e:\n            print(f\"❌ Error loading CSV dataset: {e}\")\n            print(\"🔄 Using fallback test cases instead\")\n            self.load_fallback_test_cases()\n    \n    def load_fallback_test_cases(self):\n        \"\"\"Load fallback test cases if CSV is not available\"\"\"\n        self.test_cases = [\n            {\n                'type': 'phishing',\n                'text': \"URGENT: Your PayPal account suspended. Click here to verify: http://paypal-fake.com\",\n                'true_label': 'phishing'\n            },\n            {\n                'type': 'tech_support_scam',\n                'text': \"WARNING: Virus detected! Call Microsoft Support: 1-800-FAKE\",\n                'true_label': 'tech_support_scam'\n            },\n            {\n                'type': 'reward_scam', \n                'text': \"Congratulations! You won $1000! Send $50 fee to claim prize!\",\n                'true_label': 'reward_scam'\n            },\n            {\n                'type': 'legitimate',\n                'text': \"Your package has been delivered and is waiting at your front door.\",\n                'true_label': 'legitimate'\n            }\n        ]\n        \n    def load_model(self, model_info: Dict) -> Tuple[bool, object, str]:\n        \"\"\"Load a specific model and return success status, pipeline, and error message\"\"\"\n        try:\n            print(f\"🔄 Loading {model_info['name']}...\")\n            start_time = time.time()\n            \n            # Clear GPU memory first\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n            gc.collect()\n            \n            pipeline_obj = pipeline(\n                \"text-generation\",\n                model=model_info['name'],\n                device=0 if torch.cuda.is_available() else -1,\n                do_sample=True,\n                temperature=0.7,\n                max_length=256,\n                pad_token_id=50256,\n                return_full_text=False  # Only return generated text\n            )\n            \n            load_time = time.time() - start_time\n            print(f\"✅ Loaded {model_info['name']} in {load_time:.2f}s\")\n            \n            return True, pipeline_obj, f\"Loaded successfully in {load_time:.2f}s\"\n            \n        except Exception as e:\n            error_msg = f\"Failed to load: {str(e)}\"\n            print(f\"❌ {model_info['name']}: {error_msg}\")\n            return False, None, error_msg\n    \n    def calculate_comprehensive_quality_score(self, generated_text: str, test_case: Dict) -> Dict:\n        \"\"\"Calculate comprehensive quality score using multiple indicators\"\"\"\n        text_lower = generated_text.lower()\n        scores = {}\n        total_indicators = 0\n        found_indicators = 0\n        \n        # Calculate score for each indicator category\n        for category, indicators in self.quality_indicators.items():\n            category_found = sum(1 for indicator in indicators if indicator in text_lower)\n            category_total = len(indicators)\n            category_score = (category_found / category_total) * 100 if category_total > 0 else 0\n            \n            scores[f'{category}_score'] = category_score\n            scores[f'{category}_found'] = category_found\n            scores[f'{category}_total'] = category_total\n            \n            total_indicators += category_total\n            found_indicators += category_found\n        \n        # Overall quality metrics\n        scores['overall_quality'] = (found_indicators / total_indicators) * 100 if total_indicators > 0 else 0\n        scores['total_indicators_found'] = found_indicators\n        scores['total_indicators_available'] = total_indicators\n        \n        # Additional quality metrics\n        scores['text_length'] = len(generated_text)\n        scores['word_count'] = len(generated_text.split())\n        scores['coherence_score'] = self.calculate_coherence_score(generated_text)\n        scores['relevance_score'] = self.calculate_relevance_score(generated_text, test_case)\n        \n        return scores\n    \n    def calculate_coherence_score(self, text: str) -> float:\n        \"\"\"Calculate text coherence based on sentence structure and flow\"\"\"\n        if not text or len(text.strip()) == 0:\n            return 0.0\n            \n        # Simple coherence metrics\n        sentences = text.split('.')\n        coherence_indicators = [\n            'because', 'since', 'due to', 'therefore', 'thus', 'consequently',\n            'however', 'moreover', 'furthermore', 'additionally', 'also'\n        ]\n        \n        coherence_count = sum(1 for indicator in coherence_indicators if indicator in text.lower())\n        sentence_count = len([s for s in sentences if len(s.strip()) > 3])\n        \n        # Score based on logical connectors and sentence structure\n        if sentence_count == 0:\n            return 0.0\n            \n        coherence_score = min(100, (coherence_count / sentence_count) * 100 + 20)  # Base score of 20\n        return coherence_score\n    \n    def calculate_relevance_score(self, generated_text: str, test_case: Dict) -> float:\n        \"\"\"Calculate how relevant the reasoning is to the specific fraud type\"\"\"\n        fraud_type = test_case['type']\n        text_lower = generated_text.lower()\n        \n        # Type-specific keywords\n        type_keywords = {\n            'phishing': ['phishing', 'credential', 'login', 'password', 'account', 'verify', 'click'],\n            'tech_support_scam': ['tech support', 'virus', 'computer', 'microsoft', 'infected', 'call'],\n            'reward_scam': ['prize', 'winner', 'reward', 'lottery', 'claim', 'congratulations'],\n            'job_scam': ['job', 'work', 'employment', 'income', 'opportunity', 'hiring'],\n            'sms_spam': ['text', 'sms', 'message', 'reply', 'stop', 'unsubscribe'],\n            'popup_scam': ['popup', 'alert', 'warning', 'browser', 'virus detected'],\n            'refund_scam': ['refund', 'billing', 'payment', 'charge', 'bank', 'transaction'],\n            'ssn_scam': ['social security', 'ssn', 'government', 'identity', 'verify'],\n            'legitimate': ['normal', 'safe', 'legitimate', 'genuine', 'real']\n        }\n        \n        relevant_keywords = type_keywords.get(fraud_type, [])\n        if not relevant_keywords:\n            return 50.0  # Default score for unknown types\n            \n        found_keywords = sum(1 for keyword in relevant_keywords if keyword in text_lower)\n        relevance_score = (found_keywords / len(relevant_keywords)) * 100\n        \n        return relevance_score\n    \n    def test_model_reasoning(self, pipeline_obj, model_name: str, test_case: Dict) -> Dict:\n        \"\"\"Test a model's reasoning capability with comprehensive quality assessment\"\"\"\n        try:\n            start_time = time.time()\n            \n            # Skip reasoning for legitimate cases (focus on fraud detection)\n            if test_case['type'] == 'legitimate':\n                return {\n                    'success': True,\n                    'generated_text': \"This text appears to be legitimate communication.\",\n                    'inference_time': 0.01,\n                    'quality_scores': {'overall_quality': 100, 'relevance_score': 100},\n                    'prompt_used': 'N/A (legitimate text)',\n                    'error': None,\n                    'skipped_legitimate': True\n                }\n            \n            # Create reasoning prompt for fraud cases\n            prompt = f\"This text appears to be a {test_case['type']} scam because\"\n            \n            # Generate reasoning\n            response = pipeline_obj(\n                prompt,\n                max_length=150,\n                num_return_sequences=1,\n                temperature=0.7,\n                do_sample=True\n            )\n            \n            inference_time = time.time() - start_time\n            generated_text = response[0]['generated_text'] if response else \"No response generated\"\n            \n            # Calculate comprehensive quality scores\n            quality_scores = self.calculate_comprehensive_quality_score(generated_text, test_case)\n            \n            return {\n                'success': True,\n                'generated_text': generated_text,\n                'inference_time': inference_time,\n                'quality_scores': quality_scores,\n                'prompt_used': prompt,\n                'error': None,\n                'skipped_legitimate': False\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'generated_text': None,\n                'inference_time': 0,\n                'quality_scores': {'overall_quality': 0},\n                'prompt_used': prompt if 'prompt' in locals() else 'Error before prompt creation',\n                'error': str(e),\n                'skipped_legitimate': False\n            }\n    \n    def run_comprehensive_test(self):\n        \"\"\"Run all models on all test cases with enhanced metrics\"\"\"\n        print(\"🚀 Starting Enhanced LLM Testing for Fraud Reasoning\")\n        print(\"=\" * 80)\n        print(f\"📊 Testing {len(self.models_to_test)} models on {len(self.test_cases)} real cases\")\n        print(\"🎯 Enhanced quality metrics include:\")\n        print(\"   • Fraud detection keywords (19 indicators)\")\n        print(\"   • Urgency manipulation tactics (12 indicators)\")  \n        print(\"   • Financial exploitation patterns (15 indicators)\")\n        print(\"   • Action-oriented language (13 indicators)\")\n        print(\"   • Technical deception methods (13 indicators)\")\n        print(\"   • Social engineering techniques (12 indicators)\")\n        print(\"   • Emotional manipulation patterns (13 indicators)\")\n        print(\"   • Explanation coherence and relevance\")\n        print(\"=\" * 80)\n        \n        for model_info in self.models_to_test:\n            print(f\"\\n🔍 Testing: {model_info['name']}\")\n            print(f\"📋 Type: {model_info['type']} | Size: {model_info['size']}\")\n            print(f\"💡 Description: {model_info['description']}\")\n            print(\"-\" * 60)\n            \n            # Load model\n            success, pipeline_obj, load_msg = self.load_model(model_info)\n            \n            if not success:\n                self.results[model_info['name']] = {\n                    'model_info': model_info,\n                    'load_success': False,\n                    'load_message': load_msg,\n                    'test_results': {}\n                }\n                continue\n            \n            # Test on all cases\n            model_results = {\n                'model_info': model_info,\n                'load_success': True,\n                'load_message': load_msg,\n                'test_results': {}\n            }\n            \n            total_inference_time = 0\n            total_quality_scores = {}\n            successful_tests = 0\n            fraud_tests = 0\n            \n            # Initialize quality score accumulators\n            for category in self.quality_indicators.keys():\n                total_quality_scores[f'{category}_score'] = 0\n            total_quality_scores['overall_quality'] = 0\n            total_quality_scores['coherence_score'] = 0\n            total_quality_scores['relevance_score'] = 0\n            \n            for test_case in self.test_cases:\n                fraud_type = test_case['type']\n                print(f\"  🧪 Testing {fraud_type}...\")\n                \n                result = self.test_model_reasoning(pipeline_obj, model_info['name'], test_case)\n                model_results['test_results'][f\"{fraud_type}_{successful_tests}\"] = result\n                \n                if result['success']:\n                    total_inference_time += result['inference_time']\n                    successful_tests += 1\n                    \n                    if not result.get('skipped_legitimate', False):\n                        fraud_tests += 1\n                        # Accumulate quality scores\n                        for score_name, score_value in result['quality_scores'].items():\n                            if score_name in total_quality_scores:\n                                total_quality_scores[score_name] += score_value\n                    \n                    # Show detailed results\n                    if result.get('skipped_legitimate', False):\n                        print(f\"     ⏭️  Skipped (legitimate) | Time: {result['inference_time']:.2f}s\")\n                    else:\n                        overall_q = result['quality_scores']['overall_quality']\n                        relevance_q = result['quality_scores']['relevance_score']\n                        coherence_q = result['quality_scores']['coherence_score']\n                        print(f\"     ✅ Overall: {overall_q:.1f}% | Relevance: {relevance_q:.1f}% | Coherence: {coherence_q:.1f}% | Time: {result['inference_time']:.2f}s\")\n                else:\n                    print(f\"     ❌ Failed: {result['error']}\")\n            \n            # Calculate averages\n            if successful_tests > 0:\n                model_results['avg_inference_time'] = total_inference_time / successful_tests\n                model_results['success_rate'] = (successful_tests / len(self.test_cases)) * 100\n                \n                # Calculate average quality scores (only for fraud cases)\n                if fraud_tests > 0:\n                    model_results['avg_quality_scores'] = {\n                        score_name: score_value / fraud_tests \n                        for score_name, score_value in total_quality_scores.items()\n                    }\n                    model_results['overall_quality'] = model_results['avg_quality_scores']['overall_quality']\n                else:\n                    model_results['avg_quality_scores'] = {score: 0 for score in total_quality_scores.keys()}\n                    model_results['overall_quality'] = 0\n                    \n                model_results['fraud_tests_completed'] = fraud_tests\n            else:\n                model_results['avg_inference_time'] = 0\n                model_results['overall_quality'] = 0\n                model_results['success_rate'] = 0\n                model_results['avg_quality_scores'] = {score: 0 for score in total_quality_scores.keys()}\n                model_results['fraud_tests_completed'] = 0\n            \n            self.results[model_info['name']] = model_results\n            \n            # Clean up\n            del pipeline_obj\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n            gc.collect()\n            \n            print(f\"  📊 Overall Quality: {model_results['overall_quality']:.1f}%\")\n            print(f\"  ⚡ Average Speed: {model_results['avg_inference_time']:.2f}s\")\n            print(f\"  ✅ Success Rate: {model_results['success_rate']:.1f}%\")\n            print(f\"  🎯 Fraud Cases: {model_results['fraud_tests_completed']}/{len(self.test_cases)}\")\n    \n    def generate_comparison_report(self):\n        \"\"\"Generate a detailed comparison report with enhanced metrics\"\"\"\n        print(\"\\n\" + \"=\" * 80)\n        print(\"📊 ENHANCED LLM COMPARISON REPORT\")\n        print(\"=\" * 80)\n        \n        # Sort models by performance\n        successful_models = {\n            name: results for name, results in self.results.items() \n            if results['load_success'] and results['success_rate'] > 0\n        }\n        \n        if not successful_models:\n            print(\"❌ No models successfully completed testing!\")\n            return\n        \n        # Performance ranking by overall quality\n        ranked_models = sorted(\n            successful_models.items(),\n            key=lambda x: (x[1]['overall_quality'], -x[1]['avg_inference_time']),\n            reverse=True\n        )\n        \n        print(f\"\\n🏆 PERFORMANCE RANKING (by Overall Quality + Speed)\")\n        print(\"-\" * 70)\n        \n        for rank, (name, results) in enumerate(ranked_models, 1):\n            print(f\"{rank}. {name}\")\n            print(f\"   Overall Quality: {results['overall_quality']:.1f}% | Speed: {results['avg_inference_time']:.2f}s\")\n            print(f\"   Success Rate: {results['success_rate']:.1f}% | Fraud Cases: {results['fraud_tests_completed']}\")\n            print(f\"   Size: {results['model_info']['size']} | Type: {results['model_info']['type']}\")\n        \n        # Detailed quality breakdown\n        print(f\"\\n🔍 DETAILED QUALITY BREAKDOWN\")\n        print(\"-\" * 70)\n        \n        quality_categories = [\n            ('fraud_keywords', 'Fraud Detection'),\n            ('urgency_indicators', 'Urgency Recognition'), \n            ('financial_indicators', 'Financial Patterns'),\n            ('action_indicators', 'Action-Oriented Language'),\n            ('technical_indicators', 'Technical Deception'),\n            ('social_engineering', 'Social Engineering'),\n            ('emotional_manipulation', 'Emotional Manipulation'),\n            ('coherence_score', 'Text Coherence'),\n            ('relevance_score', 'Type Relevance')\n        ]\n        \n        for name, results in ranked_models:\n            print(f\"\\n🤖 {name}:\")\n            if 'avg_quality_scores' in results:\n                for category_key, category_name in quality_categories:\n                    score_key = f'{category_key}_score' if category_key in ['fraud_keywords', 'urgency_indicators', 'financial_indicators', 'action_indicators', 'technical_indicators', 'social_engineering', 'emotional_manipulation'] else category_key\n                    score = results['avg_quality_scores'].get(score_key, 0)\n                    print(f\"   {category_name:20s}: {score:6.1f}%\")\n        \n        # Best in category analysis\n        print(f\"\\n🎖️  CATEGORY LEADERS\")\n        print(\"-\" * 50)\n        \n        for category_key, category_name in quality_categories:\n            score_key = f'{category_key}_score' if category_key in ['fraud_keywords', 'urgency_indicators', 'financial_indicators', 'action_indicators', 'technical_indicators', 'social_engineering', 'emotional_manipulation'] else category_key\n            \n            best_model = max(\n                ranked_models, \n                key=lambda x: x[1]['avg_quality_scores'].get(score_key, 0)\n            )\n            best_score = best_model[1]['avg_quality_scores'].get(score_key, 0)\n            print(f\"🏅 {category_name:20s}: {best_model[0]} ({best_score:.1f}%)\")\n        \n        # Speed analysis\n        print(f\"\\n⚡ SPEED ANALYSIS\")\n        print(\"-\" * 50)\n        \n        fastest_model = min(ranked_models, key=lambda x: x[1]['avg_inference_time'])\n        slowest_model = max(ranked_models, key=lambda x: x[1]['avg_inference_time'])\n        \n        print(f\"🥇 Fastest: {fastest_model[0]} ({fastest_model[1]['avg_inference_time']:.2f}s)\")\n        print(f\"🐌 Slowest: {slowest_model[0]} ({slowest_model[1]['avg_inference_time']:.2f}s)\")\n        \n        # Sample reasoning outputs\n        print(f\"\\n📝 SAMPLE REASONING OUTPUTS\")\n        print(\"-\" * 70)\n        \n        for name, results in ranked_models[:2]:  # Show top 2 models\n            print(f\"\\n🤖 {name}:\")\n            # Find a fraud test case to show\n            for test_name, test_result in results['test_results'].items():\n                if (test_result['success'] and \n                    not test_result.get('skipped_legitimate', False) and \n                    test_result['generated_text']):\n                    print(f\"   Sample: {test_result['generated_text'][:120]}...\")\n                    break\n        \n        # Comprehensive recommendations\n        print(f\"\\n💡 COMPREHENSIVE RECOMMENDATIONS\")\n        print(\"-\" * 70)\n        \n        if ranked_models:\n            top_model = ranked_models[0]\n            print(f\"🥇 Overall Best: {top_model[0]}\")\n            print(f\"   Best balance: {top_model[1]['overall_quality']:.1f}% quality, {top_model[1]['avg_inference_time']:.2f}s speed\")\n            \n            # Specific recommendations\n            print(f\"\\n🎯 Use Cases:\")\n            \n            # Best for accuracy\n            best_quality = max(ranked_models, key=lambda x: x[1]['overall_quality'])\n            if best_quality[1]['overall_quality'] > 50:\n                print(f\"   📊 Highest Quality: {best_quality[0]} ({best_quality[1]['overall_quality']:.1f}%)\")\n            \n            # Best for speed\n            if fastest_model[1]['avg_inference_time'] < 2.0:\n                print(f\"   ⚡ Speed Critical: {fastest_model[0]} ({fastest_model[1]['avg_inference_time']:.2f}s)\")\n            \n            # Best for specific fraud types\n            best_relevance = max(ranked_models, key=lambda x: x[1]['avg_quality_scores'].get('relevance_score', 0))\n            print(f\"   🎯 Type-Specific Detection: {best_relevance[0]} ({best_relevance[1]['avg_quality_scores'].get('relevance_score', 0):.1f}% relevance)\")\n        \n        print(f\"\\n📈 DATASET INSIGHTS\")\n        print(\"-\" * 50)\n        print(f\"Test Cases Used: {len(self.test_cases)} (from real CSV dataset)\")\n        \n        # Show category distribution\n        category_counts = Counter([case['type'] for case in self.test_cases])\n        print(\"Category Distribution:\")\n        for category, count in category_counts.most_common():\n            print(f\"   {category}: {count} cases\")\n        \n        return ranked_models\n\n# Initialize the enhanced tester\nllm_tester = EnhancedLLMTester()\nprint(\"✅ Enhanced LLM Testing Framework Ready!\")\nprint(\"🎯 Features:\")\nprint(\"   • Uses real CSV dataset for testing\")\nprint(\"   • 8 comprehensive quality indicator categories\")\nprint(\"   • 97+ individual quality indicators\")\nprint(\"   • Coherence and relevance scoring\")\nprint(\"   • Detailed performance breakdown by fraud type\")","metadata":{"vscode":{"languageId":"python"},"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:20:08.714302Z","iopub.execute_input":"2025-09-17T03:20:08.714986Z","iopub.status.idle":"2025-09-17T03:20:09.148011Z","shell.execute_reply.started":"2025-09-17T03:20:08.714953Z","shell.execute_reply":"2025-09-17T03:20:09.147384Z"}},"outputs":[{"name":"stdout","text":"📄 Loading real test cases from CSV dataset...\n✅ Found dataset at: /kaggle/input/fraud-dataset/final_fraud_detection_dataset.csv\n✅ Loaded 20 real test cases from dataset\n📊 Test cases by category:\n   job_scam: 2 cases\n   legitimate: 18 cases\n✅ Enhanced LLM Testing Framework Ready!\n🎯 Features:\n   • Uses real CSV dataset for testing\n   • 8 comprehensive quality indicator categories\n   • 97+ individual quality indicators\n   • Coherence and relevance scoring\n   • Detailed performance breakdown by fraud type\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# 🚀 RUN THE ENHANCED LLM TESTING\n# This will test all models using REAL CSV DATA and comprehensive quality metrics\n\nprint(\"🧪 Starting Enhanced LLM Testing with Real Dataset...\")\nprint(\"⚠️  This may take several minutes as we test multiple models\")\nprint(\"📊 Enhanced Features:\")\nprint(\"   • Uses real fraud detection dataset (CSV)\")\nprint(\"   • 8 quality indicator categories with 97+ individual metrics\")\nprint(\"   • Fraud keyword detection (19 indicators)\")\nprint(\"   • Urgency manipulation recognition (12 indicators)\")\nprint(\"   • Financial exploitation patterns (15 indicators)\")\nprint(\"   • Action-oriented language analysis (13 indicators)\")\nprint(\"   • Technical deception detection (13 indicators)\")\nprint(\"   • Social engineering identification (12 indicators)\")\nprint(\"   • Emotional manipulation patterns (13 indicators)\")\nprint(\"   • Text coherence and relevance scoring\")\n\n# Run the enhanced comprehensive test\nllm_tester.run_comprehensive_test()\n\n# Generate the enhanced comparison report\nprint(\"\\n\" + \"🎯\" * 40)\nranked_results = llm_tester.generate_comparison_report()\n\n# Save enhanced results for later reference\nresults_summary = {\n    'timestamp': datetime.now().isoformat(),\n    'framework_version': 'enhanced_v2',\n    'dataset_source': 'real_csv_data',\n    'models_tested': len(llm_tester.results),\n    'successful_models': len([r for r in llm_tester.results.values() if r['load_success']]),\n    'test_cases': len(llm_tester.test_cases),\n    'quality_indicators_total': sum(len(indicators) for indicators in llm_tester.quality_indicators.values()),\n    'quality_categories': list(llm_tester.quality_indicators.keys()),\n    'detailed_results': llm_tester.results\n}\n\nprint(f\"\\n📈 TESTING SUMMARY\")\nprint(\"=\" * 50)\nprint(f\"Framework: Enhanced v2.0 with Real Data\")\nprint(f\"Dataset: CSV with {len(llm_tester.test_cases)} real fraud cases\")\nprint(f\"Quality Indicators: {results_summary['quality_indicators_total']} total across 8 categories\")\nprint(f\"Models Tested: {results_summary['models_tested']}\")\nprint(f\"Successful Tests: {results_summary['successful_models']}\")\n\n# Display final recommendation with enhanced insights\nif ranked_results:\n    best_model = ranked_results[0]\n    print(f\"\\n🎖️  FINAL RECOMMENDATION (Based on Real Data)\")\n    print(\"=\" * 60)\n    print(f\"🥇 Best Model: {best_model[0]}\")\n    print(f\"📊 Overall Quality: {best_model[1]['overall_quality']:.1f}%\")\n    print(f\"⚡ Speed: {best_model[1]['avg_inference_time']:.2f}s average\")\n    print(f\"✅ Reliability: {best_model[1]['success_rate']:.1f}% success rate\")\n    print(f\"🎯 Fraud Cases: {best_model[1]['fraud_tests_completed']} completed\")\n    \n    # Show top quality categories\n    if 'avg_quality_scores' in best_model[1]:\n        print(f\"\\n🏆 Top Quality Scores:\")\n        quality_scores = best_model[1]['avg_quality_scores']\n        top_scores = sorted(\n            [(k, v) for k, v in quality_scores.items() if '_score' in k], \n            key=lambda x: x[1], reverse=True\n        )[:5]\n        \n        for score_name, score_value in top_scores:\n            clean_name = score_name.replace('_score', '').replace('_', ' ').title()\n            print(f\"   {clean_name:20s}: {score_value:.1f}%\")\n    \n    # Update the original reasoning model variable\n    recommended_model = best_model[0]\n    print(f\"\\n💡 To use this model, update your reasoning_model_name to: '{recommended_model}'\")\n    print(f\"🔄 This recommendation is based on {len(llm_tester.test_cases)} real fraud examples\")\nelse:\n    print(\"\\n❌ No models completed testing successfully!\")\n\nprint(f\"\\n✅ Enhanced testing complete! Results include real dataset analysis.\")","metadata":{"vscode":{"languageId":"python"},"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:20:09.148765Z","iopub.execute_input":"2025-09-17T03:20:09.148978Z","iopub.status.idle":"2025-09-17T03:20:34.112201Z","shell.execute_reply.started":"2025-09-17T03:20:09.148961Z","shell.execute_reply":"2025-09-17T03:20:34.111377Z"}},"outputs":[{"name":"stdout","text":"🧪 Starting Enhanced LLM Testing with Real Dataset...\n⚠️  This may take several minutes as we test multiple models\n📊 Enhanced Features:\n   • Uses real fraud detection dataset (CSV)\n   • 8 quality indicator categories with 97+ individual metrics\n   • Fraud keyword detection (19 indicators)\n   • Urgency manipulation recognition (12 indicators)\n   • Financial exploitation patterns (15 indicators)\n   • Action-oriented language analysis (13 indicators)\n   • Technical deception detection (13 indicators)\n   • Social engineering identification (12 indicators)\n   • Emotional manipulation patterns (13 indicators)\n   • Text coherence and relevance scoring\n🚀 Starting Enhanced LLM Testing for Fraud Reasoning\n================================================================================\n📊 Testing 4 models on 20 real cases\n🎯 Enhanced quality metrics include:\n   • Fraud detection keywords (19 indicators)\n   • Urgency manipulation tactics (12 indicators)\n   • Financial exploitation patterns (15 indicators)\n   • Action-oriented language (13 indicators)\n   • Technical deception methods (13 indicators)\n   • Social engineering techniques (12 indicators)\n   • Emotional manipulation patterns (13 indicators)\n   • Explanation coherence and relevance\n================================================================================\n\n🔍 Testing: microsoft/DialoGPT-medium\n📋 Type: conversational | Size: medium\n💡 Description: Conversational AI optimized for dialogue\n------------------------------------------------------------\n🔄 Loading microsoft/DialoGPT-medium...\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"✅ Loaded microsoft/DialoGPT-medium in 2.75s\n  🧪 Testing job_scam...\n     ✅ Overall: 0.0% | Relevance: 0.0% | Coherence: 20.0% | Time: 0.30s\n  🧪 Testing job_scam...\n     ✅ Overall: 0.0% | Relevance: 0.0% | Coherence: 20.0% | Time: 0.14s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  📊 Overall Quality: 0.0%\n  ⚡ Average Speed: 0.03s\n  ✅ Success Rate: 100.0%\n  🎯 Fraud Cases: 2/20\n\n🔍 Testing: gpt2\n📋 Type: causal | Size: medium\n💡 Description: Standard GPT-2 model\n------------------------------------------------------------\n🔄 Loading gpt2...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"216bb60284214838b9c04a16498f9387"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"295714c0080e4646b52de02baad3d38b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43b8902bdf734769a4c9179f9bac2ff0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5277c8cde0d4f8cacb1a4fd2225f636"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e933a9885954944a14099791f7b7c33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cdbde6f4a014080877f6c92ff36f7a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baac5b33e125431290aa8c10313678a5"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"✅ Loaded gpt2 in 4.66s\n  🧪 Testing job_scam...\n     ✅ Overall: 2.7% | Relevance: 16.7% | Coherence: 30.0% | Time: 1.58s\n  🧪 Testing job_scam...\n     ✅ Overall: 3.6% | Relevance: 33.3% | Coherence: 36.7% | Time: 1.33s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  📊 Overall Quality: 3.1%\n  ⚡ Average Speed: 0.15s\n  ✅ Success Rate: 100.0%\n  🎯 Fraud Cases: 2/20\n\n🔍 Testing: distilgpt2\n📋 Type: causal | Size: small\n💡 Description: Distilled GPT-2 (faster, smaller)\n------------------------------------------------------------\n🔄 Loading distilgpt2...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91b2b47cb79c4867b82a074791aae516"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e610692e18d84d81821bc8c58d75e388"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a641b063f2b142429ebe19feaab43408"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef3dfe6f9b2b4d5abf1d480fb711a80e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83497408cb5046c382e8d9f5228ef427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c7c452476b8467682960ba7f44921b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a771c2d8f274a71a84931c235b54cc3"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"✅ Loaded distilgpt2 in 5.02s\n  🧪 Testing job_scam...\n     ✅ Overall: 0.0% | Relevance: 0.0% | Coherence: 20.0% | Time: 0.79s\n  🧪 Testing job_scam...\n     ✅ Overall: 1.8% | Relevance: 16.7% | Coherence: 20.0% | Time: 0.91s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  📊 Overall Quality: 0.9%\n  ⚡ Average Speed: 0.09s\n  ✅ Success Rate: 100.0%\n  🎯 Fraud Cases: 2/20\n\n🔍 Testing: microsoft/DialoGPT-small\n📋 Type: conversational | Size: small\n💡 Description: Smaller conversational model\n------------------------------------------------------------\n🔄 Loading microsoft/DialoGPT-small...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b061f50fabf042279896de288ef8ba07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/351M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"034fbc3f3b0443ee8ff5e21545642bf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9be648a81f14f44973f3599aa4e76fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"585638d2da7548909bd5891cef4b3af4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c38f23120b7b4a279544de640358fff1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d4fe2f291f342f1a264c5010e376ade"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"✅ Loaded microsoft/DialoGPT-small in 3.54s\n  🧪 Testing job_scam...\n     ✅ Overall: 0.9% | Relevance: 0.0% | Coherence: 20.0% | Time: 0.08s\n  🧪 Testing job_scam...\n     ✅ Overall: 0.0% | Relevance: 0.0% | Coherence: 20.0% | Time: 0.08s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  🧪 Testing legitimate...\n     ⏭️  Skipped (legitimate) | Time: 0.01s\n  📊 Overall Quality: 0.4%\n  ⚡ Average Speed: 0.02s\n  ✅ Success Rate: 100.0%\n  🎯 Fraud Cases: 2/20\n\n🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯🎯\n\n================================================================================\n📊 ENHANCED LLM COMPARISON REPORT\n================================================================================\n\n🏆 PERFORMANCE RANKING (by Overall Quality + Speed)\n----------------------------------------------------------------------\n1. gpt2\n   Overall Quality: 3.1% | Speed: 0.15s\n   Success Rate: 100.0% | Fraud Cases: 2\n   Size: medium | Type: causal\n2. distilgpt2\n   Overall Quality: 0.9% | Speed: 0.09s\n   Success Rate: 100.0% | Fraud Cases: 2\n   Size: small | Type: causal\n3. microsoft/DialoGPT-small\n   Overall Quality: 0.4% | Speed: 0.02s\n   Success Rate: 100.0% | Fraud Cases: 2\n   Size: small | Type: conversational\n4. microsoft/DialoGPT-medium\n   Overall Quality: 0.0% | Speed: 0.03s\n   Success Rate: 100.0% | Fraud Cases: 2\n   Size: medium | Type: conversational\n\n🔍 DETAILED QUALITY BREAKDOWN\n----------------------------------------------------------------------\n\n🤖 gpt2:\n   Fraud Detection     :    5.3%\n   Urgency Recognition :    0.0%\n   Financial Patterns  :    0.0%\n   Action-Oriented Language:    7.1%\n   Technical Deception :    7.1%\n   Social Engineering  :    0.0%\n   Emotional Manipulation:    0.0%\n   Text Coherence      :   33.3%\n   Type Relevance      :   25.0%\n\n🤖 distilgpt2:\n   Fraud Detection     :    2.6%\n   Urgency Recognition :    0.0%\n   Financial Patterns  :    0.0%\n   Action-Oriented Language:    0.0%\n   Technical Deception :    0.0%\n   Social Engineering  :    4.2%\n   Emotional Manipulation:    0.0%\n   Text Coherence      :   20.0%\n   Type Relevance      :    8.3%\n\n🤖 microsoft/DialoGPT-small:\n   Fraud Detection     :    2.6%\n   Urgency Recognition :    0.0%\n   Financial Patterns  :    0.0%\n   Action-Oriented Language:    0.0%\n   Technical Deception :    0.0%\n   Social Engineering  :    0.0%\n   Emotional Manipulation:    0.0%\n   Text Coherence      :   20.0%\n   Type Relevance      :    0.0%\n\n🤖 microsoft/DialoGPT-medium:\n   Fraud Detection     :    0.0%\n   Urgency Recognition :    0.0%\n   Financial Patterns  :    0.0%\n   Action-Oriented Language:    0.0%\n   Technical Deception :    0.0%\n   Social Engineering  :    0.0%\n   Emotional Manipulation:    0.0%\n   Text Coherence      :   20.0%\n   Type Relevance      :    0.0%\n\n🎖️  CATEGORY LEADERS\n--------------------------------------------------\n🏅 Fraud Detection     : gpt2 (5.3%)\n🏅 Urgency Recognition : gpt2 (0.0%)\n🏅 Financial Patterns  : gpt2 (0.0%)\n🏅 Action-Oriented Language: gpt2 (7.1%)\n🏅 Technical Deception : gpt2 (7.1%)\n🏅 Social Engineering  : distilgpt2 (4.2%)\n🏅 Emotional Manipulation: gpt2 (0.0%)\n🏅 Text Coherence      : gpt2 (33.3%)\n🏅 Type Relevance      : gpt2 (25.0%)\n\n⚡ SPEED ANALYSIS\n--------------------------------------------------\n🥇 Fastest: microsoft/DialoGPT-small (0.02s)\n🐌 Slowest: gpt2 (0.15s)\n\n📝 SAMPLE REASONING OUTPUTS\n----------------------------------------------------------------------\n\n🤖 gpt2:\n   Sample:  it is not a job posting. It is a job posting on this website.\n\nThe message that the post received is:\n\nI thought you mi...\n\n🤖 distilgpt2:\n   Sample:  it can be found in the 'disappearances' section of this page.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n...\n\n💡 COMPREHENSIVE RECOMMENDATIONS\n----------------------------------------------------------------------\n🥇 Overall Best: gpt2\n   Best balance: 3.1% quality, 0.15s speed\n\n🎯 Use Cases:\n   ⚡ Speed Critical: microsoft/DialoGPT-small (0.02s)\n   🎯 Type-Specific Detection: gpt2 (25.0% relevance)\n\n📈 DATASET INSIGHTS\n--------------------------------------------------\nTest Cases Used: 20 (from real CSV dataset)\nCategory Distribution:\n   legitimate: 18 cases\n   job_scam: 2 cases\n\n📈 TESTING SUMMARY\n==================================================\nFramework: Enhanced v2.0 with Real Data\nDataset: CSV with 20 real fraud cases\nQuality Indicators: 112 total across 8 categories\nModels Tested: 4\nSuccessful Tests: 4\n\n🎖️  FINAL RECOMMENDATION (Based on Real Data)\n============================================================\n🥇 Best Model: gpt2\n📊 Overall Quality: 3.1%\n⚡ Speed: 0.15s average\n✅ Reliability: 100.0% success rate\n🎯 Fraud Cases: 2 completed\n\n🏆 Top Quality Scores:\n   Coherence           : 33.3%\n   Relevance           : 25.0%\n   Action Indicators   : 7.1%\n   Technical Indicators: 7.1%\n   Fraud Keywords      : 5.3%\n\n💡 To use this model, update your reasoning_model_name to: 'gpt2'\n🔄 This recommendation is based on 20 real fraud examples\n\n✅ Enhanced testing complete! Results include real dataset analysis.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# 🔍 Individual Model Deep Dive Testing\n# Test a specific model in detail to see actual reasoning outputs\n\ndef test_single_model_detailed(model_name, test_cases=None):\n    \"\"\"Test a single model with detailed output analysis\"\"\"\n    \n    if test_cases is None:\n        test_cases = [\n            \"URGENT: Your PayPal account has been suspended. Click here to verify: http://fake-paypal.com\",\n            \"WARNING: Your computer is infected with 5 viruses! Call Microsoft: 1-800-FAKE-TECH\",\n            \"Congratulations! You've won $5000! Send $100 processing fee to claim your prize!\",\n            \"Your package from Amazon has been delivered and is waiting at your front door.\",\n            \"NOTICE: Your Social Security Number has been suspended. Call SSA: 1-800-FAKE-SSA\"\n        ]\n    \n    print(f\"🔍 Deep Testing: {model_name}\")\n    print(\"=\" * 60)\n    \n    try:\n        # Load the specific model\n        print(f\"🔄 Loading {model_name}...\")\n        start_time = time.time()\n        \n        test_pipeline = pipeline(\n            \"text-generation\",\n            model=model_name,\n            device=0 if torch.cuda.is_available() else -1,\n            do_sample=True,\n            temperature=0.7,\n            max_length=300,\n            pad_token_id=50256\n        )\n        \n        load_time = time.time() - start_time\n        print(f\"✅ Loaded in {load_time:.2f}s\")\n        \n        print(f\"\\n📝 Testing {len(test_cases)} fraud examples:\")\n        print(\"-\" * 60)\n        \n        for i, test_text in enumerate(test_cases, 1):\n            print(f\"\\n🧪 Test {i}: {test_text[:50]}...\")\n            \n            # Create reasoning prompt\n            prompt = f\"This message appears to be fraudulent because\"\n            \n            # Generate reasoning\n            start_inference = time.time()\n            try:\n                response = test_pipeline(\n                    prompt,\n                    max_length=200,\n                    num_return_sequences=1,\n                    temperature=0.7,\n                    do_sample=True,\n                    return_full_text=False\n                )\n                \n                inference_time = time.time() - start_inference\n                reasoning = response[0]['generated_text'] if response else \"No response\"\n                \n                print(f\"   ⚡ Time: {inference_time:.2f}s\")\n                print(f\"   🧠 Reasoning: {reasoning}\")\n                \n                # Simple quality assessment\n                quality_keywords = ['scam', 'fraud', 'suspicious', 'fake', 'phishing', 'deceptive', 'malicious']\n                quality_score = sum(1 for word in quality_keywords if word in reasoning.lower())\n                print(f\"   📊 Quality indicators found: {quality_score}/{len(quality_keywords)}\")\n                \n            except Exception as e:\n                print(f\"   ❌ Error: {str(e)}\")\n        \n        # Clean up\n        del test_pipeline\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        gc.collect()\n        \n        print(f\"\\n✅ Deep testing of {model_name} complete!\")\n        \n    except Exception as e:\n        print(f\"❌ Failed to test {model_name}: {str(e)}\")\n\n# Example: Test a specific model in detail\nprint(\"🎯 Choose a model to test in detail:\")\nprint(\"1. microsoft/DialoGPT-medium (current default)\")\nprint(\"2. gpt2 (standard GPT-2)\")  \nprint(\"3. distilgpt2 (faster, smaller)\")\nprint(\"4. microsoft/DialoGPT-small (smaller conversational)\")\n\n# Test the current default model\ntest_model = \"microsoft/DialoGPT-medium\"\nprint(f\"\\n🚀 Testing {test_model} in detail...\")\ntest_single_model_detailed(test_model)","metadata":{"vscode":{"languageId":"python"},"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:20:34.113234Z","iopub.execute_input":"2025-09-17T03:20:34.113667Z","iopub.status.idle":"2025-09-17T03:20:37.901331Z","shell.execute_reply.started":"2025-09-17T03:20:34.113638Z","shell.execute_reply":"2025-09-17T03:20:37.900636Z"}},"outputs":[{"name":"stdout","text":"🎯 Choose a model to test in detail:\n1. microsoft/DialoGPT-medium (current default)\n2. gpt2 (standard GPT-2)\n3. distilgpt2 (faster, smaller)\n4. microsoft/DialoGPT-small (smaller conversational)\n\n🚀 Testing microsoft/DialoGPT-medium in detail...\n🔍 Deep Testing: microsoft/DialoGPT-medium\n============================================================\n🔄 Loading microsoft/DialoGPT-medium...\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"✅ Loaded in 2.39s\n\n📝 Testing 5 fraud examples:\n------------------------------------------------------------\n\n🧪 Test 1: URGENT: Your PayPal account has been suspended. Cl...\n   ⚡ Time: 0.19s\n   🧠 Reasoning:  you didn't pay to view it.\n   📊 Quality indicators found: 0/7\n\n🧪 Test 2: WARNING: Your computer is infected with 5 viruses!...\n   ⚡ Time: 0.22s\n   🧠 Reasoning:  it's not a scam, just not a scam.\n   📊 Quality indicators found: 1/7\n\n🧪 Test 3: Congratulations! You've won $5000! Send $100 proce...\n   ⚡ Time: 0.16s\n   🧠 Reasoning:  the person who wrote it is a woman\n   📊 Quality indicators found: 0/7\n\n🧪 Test 4: Your package from Amazon has been delivered and is...\n   ⚡ Time: 0.14s\n   🧠 Reasoning:  the text is not in English.\n   📊 Quality indicators found: 0/7\n\n🧪 Test 5: NOTICE: Your Social Security Number has been suspe...\n   ⚡ Time: 0.19s\n   🧠 Reasoning:  the text itself is not part of the image.\n   📊 Quality indicators found: 0/7\n\n✅ Deep testing of microsoft/DialoGPT-medium complete!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# 🔄 Easy Model Switching Based on Test Results\n# Use this cell to switch to your preferred model after testing\n\ndef switch_reasoning_model(new_model_name):\n    \"\"\"Switch to a different reasoning model\"\"\"\n    global reasoning_pipe, reasoning_model_name\n    \n    print(f\"🔄 Switching from {reasoning_model_name} to {new_model_name}...\")\n    \n    try:\n        # Clean up current model\n        if 'reasoning_pipe' in globals():\n            del reasoning_pipe\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n            gc.collect()\n        \n        # Load new model\n        start_time = time.time()\n        reasoning_pipe = pipeline(\n            \"text-generation\",\n            model=new_model_name,\n            device=0 if torch.cuda.is_available() else -1,\n            do_sample=True,\n            temperature=0.7,\n            max_length=512,\n            pad_token_id=50256\n        )\n        \n        load_time = time.time() - start_time\n        reasoning_model_name = new_model_name\n        \n        print(f\"✅ Successfully switched to {new_model_name} in {load_time:.2f}s\")\n        \n        # Test the new model\n        test_prompt = \"This text appears to be a scam because\"\n        test_response = reasoning_pipe(test_prompt, max_length=60, num_return_sequences=1)\n        print(f\"🧪 Test successful: {test_response[0]['generated_text'][:100]}...\")\n        \n        # Update the reasoning engine\n        global local_reasoning_engine\n        local_reasoning_engine = LocalFraudReasoningEngine(reasoning_pipe)\n        print(f\"🔄 Local reasoning engine updated with new model\")\n        \n        return True\n        \n    except Exception as e:\n        print(f\"❌ Error switching to {new_model_name}: {str(e)}\")\n        return False\n\n# 📊 Model Performance Summary (update after running tests)\nmodel_recommendations = {\n    \"Best Overall\": \"microsoft/DialoGPT-medium\",  # Update based on test results\n    \"Fastest\": \"distilgpt2\",\n    \"Most Conversational\": \"microsoft/DialoGPT-medium\", \n    \"Smallest\": \"distilgpt2\",\n    \"Best Quality\": \"gpt2\"  # Update based on test results\n}\n\nprint(\"🎯 Model Recommendations (update after testing):\")\nfor category, model in model_recommendations.items():\n    print(f\"   {category}: {model}\")\n\nprint(f\"\\n💡 Current model: {reasoning_model_name}\")\nprint(\"🔄 To switch models, run: switch_reasoning_model('model-name')\")\n\n# Example: Uncomment to switch to a different model\n# switch_reasoning_model(\"distilgpt2\")  # Switch to faster model\n# switch_reasoning_model(\"gpt2\")        # Switch to standard GPT-2","metadata":{"vscode":{"languageId":"python"},"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:20:37.902165Z","iopub.execute_input":"2025-09-17T03:20:37.902440Z","iopub.status.idle":"2025-09-17T03:20:37.911057Z","shell.execute_reply.started":"2025-09-17T03:20:37.902422Z","shell.execute_reply":"2025-09-17T03:20:37.910266Z"}},"outputs":[{"name":"stdout","text":"🎯 Model Recommendations (update after testing):\n   Best Overall: microsoft/DialoGPT-medium\n   Fastest: distilgpt2\n   Most Conversational: microsoft/DialoGPT-medium\n   Smallest: distilgpt2\n   Best Quality: gpt2\n\n💡 Current model: microsoft/DialoGPT-medium\n🔄 To switch models, run: switch_reasoning_model('model-name')\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Load Your Trained DistilBERT Fraud Detection Model\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n\nprint(\"📦 Loading Your Trained DistilBERT Model...\")\n\n# KAGGLE PATHS - Update these to match your uploaded dataset name\nMODEL_PATH = '/kaggle/input/distilbert/transformers/default/1/distilbert_model'  # Update this path to your dataset\nTOKENIZER_PATH = '/kaggle/input/distilbert/transformers/default/1/distilbert_tokenizer'  # Update this path to your dataset\n\n\n\n# Class labels (must match your training - alphabetical order)\nCLASS_LABELS = [\n    'job_scam',\n    'legitimate', \n    'phishing',\n    'popup_scam',\n    'refund_scam',\n    'reward_scam',\n    'sms_spam',\n    'ssn_scam',\n    'tech_support_scam'\n]\n\nprint(f\"🔍 Checking paths:\")\nprint(f\"   Model: {MODEL_PATH}\")\nprint(f\"   Tokenizer: {TOKENIZER_PATH}\")\n\n# Check if paths exist\nimport os\nmodel_exists = os.path.exists(MODEL_PATH)\ntokenizer_exists = os.path.exists(TOKENIZER_PATH)\nprint(f\"   Model exists: {model_exists}\")\nprint(f\"   Tokenizer exists: {tokenizer_exists}\")\n\nif not model_exists or not tokenizer_exists:\n    print(\"\\n❌ Model files not found!\")\n    print(\"📁 Make sure you've uploaded your model files to Kaggle:\")\n    print(\"   1. Go to Kaggle Datasets\")\n    print(\"   2. Create a new dataset\")\n    print(\"   3. Upload your 'distilbert_model/' and 'distilbert_tokenizer/' folders\")\n    print(\"   4. Update the paths above to match your dataset name\")\n    print(\"   5. Add your dataset as input to this notebook\")\n    fraud_model = None\n    fraud_tokenizer = None\nelse:\n    try:\n        # Load your trained model and tokenizer\n        print(\"🔄 Loading tokenizer...\")\n        fraud_tokenizer = DistilBertTokenizer.from_pretrained(TOKENIZER_PATH)\n        \n        print(\"🔄 Loading model...\")\n        fraud_model = DistilBertForSequenceClassification.from_pretrained(MODEL_PATH)\n        \n        # Move to GPU for faster inference\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        fraud_model.to(device)\n        fraud_model.eval()\n        \n        print(f\"✅ DistilBERT model loaded successfully!\")\n        print(f\"🎯 Device: {device}\")\n        print(f\"📋 Classes: {len(CLASS_LABELS)} fraud types + legitimate\")\n        print(f\"🏷️  Labels: {CLASS_LABELS}\")\n        \n        # Quick test to verify model works\n        test_text = \"Your package has been successfully delivered and left at your front door. If you do not locate the parcel, please check with members of your household or nearby areas where it may have been placed for security.\"\n        test_encoding = fraud_tokenizer(\n            test_text,\n            max_length=128,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        test_input_ids = test_encoding['input_ids'].to(device)\n        test_attention_mask = test_encoding['attention_mask'].to(device)\n        \n        with torch.no_grad():\n            test_outputs = fraud_model(input_ids=test_input_ids, attention_mask=test_attention_mask)\n            test_probabilities = torch.softmax(test_outputs.logits, dim=1).cpu().numpy()[0]\n            test_predicted_class = CLASS_LABELS[np.argmax(test_probabilities)]\n        \n        print(f\"\\n🧪 Model test - '{test_text}':\")\n        print(f\"   Predicted: {test_predicted_class} ({test_probabilities[np.argmax(test_probabilities)]:.2%})\")\n        print(\"   ✅ Model is working!\" if test_predicted_class == 'legitimate' else f\"   ⚠️ Unexpected result: {test_predicted_class}\")\n        \n    except Exception as e:\n        print(f\"❌ Error loading model: {e}\")\n        print(\"🔧 This will cause the classification to use demo mode.\")\n        fraud_model = None\n        fraud_tokenizer = None","metadata":{"colab_type":"code","vscode":{"languageId":"python"},"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:20:37.913468Z","iopub.execute_input":"2025-09-17T03:20:37.913977Z","iopub.status.idle":"2025-09-17T03:20:46.265888Z","shell.execute_reply.started":"2025-09-17T03:20:37.913952Z","shell.execute_reply":"2025-09-17T03:20:46.265248Z"}},"outputs":[{"name":"stdout","text":"📦 Loading Your Trained DistilBERT Model...\n🔍 Checking paths:\n   Model: /kaggle/input/distilbert/transformers/default/1/distilbert_model\n   Tokenizer: /kaggle/input/distilbert/transformers/default/1/distilbert_tokenizer\n   Model exists: True\n   Tokenizer exists: True\n🔄 Loading tokenizer...\n🔄 Loading model...\n✅ DistilBERT model loaded successfully!\n🎯 Device: cuda\n📋 Classes: 9 fraud types + legitimate\n🏷️  Labels: ['job_scam', 'legitimate', 'phishing', 'popup_scam', 'refund_scam', 'reward_scam', 'sms_spam', 'ssn_scam', 'tech_support_scam']\n\n🧪 Model test - 'Your package has been successfully delivered and left at your front door. If you do not locate the parcel, please check with members of your household or nearby areas where it may have been placed for security.':\n   Predicted: legitimate (72.74%)\n   ✅ Model is working!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# 🔧 Local Reasoning Engine Configuration\n\nThis section sets up the local reasoning engine that generates explanations for fraud classifications using the language model we loaded earlier.","metadata":{"colab_type":"text"}},{"cell_type":"code","source":"# Local Reasoning Engine Configuration\nclass LocalFraudReasoningEngine:\n    \"\"\"\n    Local reasoning engine that generates explanations without API calls\n    \"\"\"\n    \n    def __init__(self, reasoning_pipeline):\n        self.reasoning_pipe = reasoning_pipeline\n        self.min_confidence = 0.5\n        \n        # Scam type descriptions for better reasoning\n        self.scam_descriptions = {\n            'phishing': {\n                'description': 'Attempts to steal sensitive information like passwords, credit card numbers, or personal data',\n                'indicators': ['urgent action required', 'verify account', 'click here', 'suspicious links', 'fake sender']\n            },\n            'popup_scam': {\n                'description': 'Fake popup messages claiming virus infections or system issues',\n                'indicators': ['virus detected', 'system error', 'immediate action', 'fake technical alerts']\n            },\n            'sms_spam': {\n                'description': 'Unwanted promotional or fraudulent text messages',\n                'indicators': ['unsolicited offers', 'prize claims', 'urgent responses', 'suspicious phone numbers']\n            },\n            'reward_scam': {\n                'description': 'False promises of rewards, prizes, or free items',\n                'indicators': ['congratulations', 'you have won', 'free gift', 'claim now', 'limited time']\n            },\n            'tech_support_scam': {\n                'description': 'Fake technical support claiming to fix computer problems',\n                'indicators': ['computer infected', 'microsoft support', 'remote access', 'technical issues']\n            },\n            'refund_scam': {\n                'description': 'Fake refund notifications or requests for payment information',\n                'indicators': ['refund available', 'payment failed', 'update payment', 'billing issue']\n            },\n            'ssn_scam': {\n                'description': 'Attempts to steal Social Security Numbers or similar personal identifiers',\n                'indicators': ['SSN verification', 'social security', 'identity verification', 'government agency']\n            },\n            'job_scam': {\n                'description': 'Fake job offers or employment opportunities',\n                'indicators': ['work from home', 'easy money', 'no experience required', 'guaranteed income']\n            }\n        }\n        \n        self.stats = {\n            'total_processed': 0,\n            'reasoning_generated': 0,\n            'skipped_legitimate': 0,\n            'skipped_low_confidence': 0\n        }\n        \n    def should_generate_reasoning(self, predicted_label, confidence):\n        \"\"\"Determine if reasoning should be generated\"\"\"\n        return predicted_label != 'legitimate' and confidence >= self.min_confidence\n    \n    def generate_local_reasoning(self, text, predicted_label, confidence, all_predictions):\n        \"\"\"Generate enhanced reasoning using local language model\"\"\"\n        scam_info = self.scam_descriptions.get(predicted_label, {\n            'description': 'Unknown scam type',\n            'indicators': []\n        })\n        \n        # Enhanced reasoning without relying on language model generation\n        # Analyze text content directly\n        text_lower = text.lower()\n        detected_indicators = []\n        \n        # Check for specific indicators in the text\n        for indicator in scam_info['indicators']:\n            if any(word in text_lower for word in indicator.split()):\n                detected_indicators.append(indicator)\n        \n        # Add common fraud patterns\n        urgent_words = ['urgent', 'immediate', 'now', 'quickly', 'hurry', 'expires']\n        if any(word in text_lower for word in urgent_words):\n            detected_indicators.append('urgent language to pressure victims')\n            \n        money_words = ['$', 'money', 'prize', 'won', 'claim', 'free', 'gift']\n        if any(word in text_lower for word in money_words):\n            detected_indicators.append('financial incentives or rewards')\n            \n        action_words = ['click', 'call', 'text', 'visit', 'send', 'verify']\n        if any(word in text_lower for word in action_words):\n            detected_indicators.append('requests for immediate action')\n            \n        suspicious_elements = ['suspicious links', 'phone numbers', 'email addresses']\n        if 'http' in text_lower or '@' in text_lower or any(char.isdigit() for char in text):\n            detected_indicators.append('suspicious contact information')\n        \n        # Create comprehensive reasoning\n        reasoning_parts = []\n        reasoning_parts.append(f\"This text was classified as {predicted_label} with {confidence:.1%} confidence.\")\n        reasoning_parts.append(f\"\\n{scam_info['description']}\")\n        \n        if detected_indicators:\n            reasoning_parts.append(f\"\\nKey fraud indicators detected:\")\n            for i, indicator in enumerate(detected_indicators[:4], 1):  # Limit to top 4\n                reasoning_parts.append(f\"• {indicator}\")\n        \n        # Add context about why this is dangerous\n        danger_context = {\n            'phishing': 'This could lead to identity theft and financial loss.',\n            'sms_spam': 'This could lead to unwanted charges and privacy violations.',\n            'reward_scam': 'This could lead to financial scams and personal data theft.',\n            'tech_support_scam': 'This could lead to remote access scams and financial fraud.',\n            'job_scam': 'This could lead to advance fee fraud and identity theft.',\n            'popup_scam': 'This could lead to malware installation and system compromise.',\n            'refund_scam': 'This could lead to payment fraud and account takeover.',\n            'ssn_scam': 'This could lead to identity theft and government impersonation fraud.'\n        }\n        \n        if predicted_label in danger_context:\n            reasoning_parts.append(f\"\\n⚠️ Risk: {danger_context[predicted_label]}\")\n        \n        # Add confidence context\n        if confidence > 0.9:\n            reasoning_parts.append(f\"\\nHigh confidence ({confidence:.1%}) indicates strong fraud patterns.\")\n        elif confidence > 0.7:\n            reasoning_parts.append(f\"Moderate confidence ({confidence:.1%}) suggests probable fraud patterns.\")\n        \n        return '\\n'.join(reasoning_parts)\n\n# Initialize the local reasoning engine\nlocal_reasoning_engine = LocalFraudReasoningEngine(reasoning_pipe)\nprint(\"✅ Local reasoning engine initialized with enhanced analysis!\")","metadata":{"colab_type":"code","vscode":{"languageId":"python"},"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:20:46.266669Z","iopub.execute_input":"2025-09-17T03:20:46.266937Z","iopub.status.idle":"2025-09-17T03:20:46.280354Z","shell.execute_reply.started":"2025-09-17T03:20:46.266907Z","shell.execute_reply":"2025-09-17T03:20:46.279647Z"}},"outputs":[{"name":"stdout","text":"✅ Local reasoning engine initialized with enhanced analysis!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Fraud Classification and Reasoning Functions\ndef classify_text(text, max_length=128):\n    \"\"\"Classify text using the loaded DistilBERT model\"\"\"\n    if fraud_model is None or fraud_tokenizer is None:\n        print(\"🚨 WARNING: Model not loaded! Using demo mode.\")\n        print(\"💡 Please check model paths and ensure your dataset is properly uploaded to Kaggle.\")\n        print(\"🔄 Demo mode always returns 'phishing' - this is NOT real classification!\")\n        \n        # Return a more realistic demo that varies by text content\n        text_lower = text.lower()\n        if any(word in text_lower for word in ['thanks', 'meeting', 'delivered', 'shipped', 'hi ', 'hello']):\n            demo_label = 'legitimate'\n            demo_conf = 0.75\n        elif any(word in text_lower for word in ['urgent', 'click', 'verify', 'suspended']):\n            demo_label = 'phishing'\n            demo_conf = 0.85\n        elif any(word in text_lower for word in ['won', 'prize', 'congratulations']):\n            demo_label = 'reward_scam'\n            demo_conf = 0.80\n        else:\n            demo_label = 'phishing'  # Default fallback\n            demo_conf = 0.70\n            \n        return {\n            'text': text,\n            'predicted_label': demo_label,\n            'confidence': demo_conf,\n            'all_predictions': {\n                demo_label: demo_conf,\n                'legitimate': 0.15 if demo_label != 'legitimate' else demo_conf,\n                'phishing': 0.10 if demo_label != 'phishing' else demo_conf,\n                'reward_scam': 0.05,\n                'tech_support_scam': 0.05\n            },\n            'demo_mode': True\n        }\n    \n    # Real model classification\n    try:\n        # Tokenize input\n        encoding = fraud_tokenizer(\n            text,\n            max_length=max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        # Move to device\n        input_ids = encoding['input_ids'].to(device)\n        attention_mask = encoding['attention_mask'].to(device)\n        \n        # Get predictions\n        with torch.no_grad():\n            outputs = fraud_model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            probabilities = torch.softmax(logits, dim=1).cpu().numpy()[0]\n            predicted_class_id = np.argmax(probabilities)\n        \n        # Format results\n        predicted_label = CLASS_LABELS[predicted_class_id]\n        confidence = float(probabilities[predicted_class_id])\n        \n        all_predictions = {\n            CLASS_LABELS[i]: float(probabilities[i]) \n            for i in range(len(CLASS_LABELS))\n        }\n        \n        return {\n            'text': text,\n            'predicted_label': predicted_label,\n            'confidence': confidence,\n            'all_predictions': all_predictions,\n            'demo_mode': False\n        }\n        \n    except Exception as e:\n        print(f\"❌ Error during classification: {e}\")\n        return {\n            'text': text,\n            'predicted_label': 'error',\n            'confidence': 0.0,\n            'all_predictions': {'error': 1.0},\n            'demo_mode': True\n        }\n\ndef analyze_with_local_reasoning(text):\n    \"\"\"Complete analysis: classification + local reasoning\"\"\"\n    # Step 1: Classify the text\n    classification_result = classify_text(text)\n    \n    # Check if we're in demo mode and warn user\n    if classification_result.get('demo_mode', False):\n        if classification_result['predicted_label'] == 'error':\n            print(\"🚨 CLASSIFICATION ERROR - Please check your model setup!\")\n        else:\n            print(\"🚨 DEMO MODE ACTIVE - Results are simulated, not real model predictions!\")\n    \n    # Step 2: Generate local reasoning (only for non-legitimate classifications)\n    if local_reasoning_engine.should_generate_reasoning(\n        classification_result['predicted_label'], \n        classification_result['confidence']\n    ):\n        reasoning = local_reasoning_engine.generate_local_reasoning(\n            text=classification_result['text'],\n            predicted_label=classification_result['predicted_label'],\n            confidence=classification_result['confidence'],\n            all_predictions=classification_result['all_predictions']\n        )\n        \n        local_reasoning_engine.stats['reasoning_generated'] += 1\n        skip_reason = None\n        reasoning_generated = True\n    else:\n        if classification_result['predicted_label'] == 'legitimate':\n            skip_reason = 'legitimate_classification'\n            local_reasoning_engine.stats['skipped_legitimate'] += 1\n        elif classification_result['predicted_label'] == 'error':\n            skip_reason = 'classification_error'\n            local_reasoning_engine.stats['skipped_low_confidence'] += 1\n        else:\n            skip_reason = f\"low_confidence_{classification_result['confidence']:.2f}\"\n            local_reasoning_engine.stats['skipped_low_confidence'] += 1\n        \n        reasoning = None\n        reasoning_generated = False\n    \n    local_reasoning_engine.stats['total_processed'] += 1\n    \n    return {\n        **classification_result,\n        'reasoning': reasoning,\n        'reasoning_generated': reasoning_generated,\n        'skip_reason': skip_reason,\n        'timestamp': datetime.now().isoformat()\n    }\n\ndef print_analysis_result(result):\n    \"\"\"Pretty print analysis result\"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"🔍 LOCAL FRAUD DETECTION + REASONING ANALYSIS\")\n    print(\"=\"*80)\n    \n    # Show demo mode warning prominently\n    if result.get('demo_mode', False):\n        print(\"🚨 DEMO MODE ACTIVE - NOT REAL MODEL PREDICTIONS!\")\n        print(\"📋 Upload your trained model to Kaggle and update paths to get real results\")\n        print(\"=\"*80)\n    \n    print(f\"\\n📝 Original Text:\")\n    print(f\"   {result['text']}\")\n    \n    print(f\"\\n🎯 Classification:\")\n    print(f\"   Label: {result['predicted_label']}\")\n    print(f\"   Confidence: {result['confidence']:.2%}\")\n    \n    if not result.get('demo_mode', False):\n        print(f\"\\n📊 All Predictions:\")\n        for label, prob in sorted(result['all_predictions'].items(), key=lambda x: x[1], reverse=True):\n            print(f\"   {label}: {prob:.2%}\")\n    \n    if result['reasoning_generated']:\n        print(f\"\\n🧠 Local AI Reasoning:\")\n        print(\"   \" + result['reasoning'].replace('\\n', '\\n   '))\n    else:\n        print(f\"\\n⏭️  Reasoning Skipped: {result['skip_reason']}\")\n    \n    print(\"\\n\" + \"=\"*80)\n\nprint(\"✅ Classification and reasoning functions ready!\")\nprint(\"🚀 Ready to analyze texts with local AI reasoning!\")\nprint(\"💡 Note: Make sure to upload your trained model to Kaggle for real predictions!\")","metadata":{"colab_type":"code","vscode":{"languageId":"python"},"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:20:46.281099Z","iopub.execute_input":"2025-09-17T03:20:46.281351Z","iopub.status.idle":"2025-09-17T03:20:46.308034Z","shell.execute_reply.started":"2025-09-17T03:20:46.281326Z","shell.execute_reply":"2025-09-17T03:20:46.307385Z"}},"outputs":[{"name":"stdout","text":"✅ Classification and reasoning functions ready!\n🚀 Ready to analyze texts with local AI reasoning!\n💡 Note: Make sure to upload your trained model to Kaggle for real predictions!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# 🧪 Sample Tests - Try Different Fraud Types\n\nLet's test the local reasoning system with various types of fraudulent and legitimate messages.","metadata":{}},{"cell_type":"code","source":"# Sample Test Cases for Different Fraud Types\nsample_texts = [\n    {\n        'category': 'Phishing Attack',\n        'text': \"URGENT: Your PayPal account has been suspended due to suspicious activity. Click here immediately to verify your information and restore access: http://paypal-verification-secure.fraudsite.com\"\n    },\n    {\n        'category': 'Tech Support Scam', \n        'text': \"WARNING: Your computer is infected with 5 viruses! Your files will be deleted in 24 hours. Call Microsoft Support immediately at 1-800-555-SCAM. Don't restart your computer or you'll lose everything!\"\n    },\n    {\n        'category': 'Reward Scam',\n        'text': \"🎉 CONGRATULATIONS! 🎉 You've been selected as our LUCKY WINNER for a $1000 Amazon gift card! You're one of only 3 winners today! Claim your prize now by clicking this link and entering your credit card info for verification. Hurry, expires in 1 hour!\"\n    },\n    {\n        'category': 'Job Scam',\n        'text': \"Amazing work from home opportunity! Earn $5000/week working just 2 hours per day! No experience required! Just send $99 registration fee and start earning today! Guaranteed income or money back!\"\n    },\n    {\n        'category': 'SMS Spam',\n        'text': \"FREE iPhone 15 Pro! You have been randomly selected as a winner. Text CLAIM to 12345 or visit bit.ly/freeiphone15winner to get your prize. Message and data rates may apply. Text STOP to opt out.\"\n    },\n    {\n        'category': 'Legitimate Message',\n        'text': \"Hi Sarah, thank you for your order #12345. Your package has been shipped and will arrive within 3-5 business days. You can track your shipment using the tracking number provided in your confirmation email. Have a great day!\"\n    },\n    {\n        'category': 'SSN Scam',\n        'text': \"IMPORTANT NOTICE: Your Social Security Number has been suspended due to suspicious illegal activity. Call the SSA office immediately at 1-800-555-FAKE to verify your identity and reactivate your SSN. Failure to respond will result in arrest.\"\n    }\n]\n\nprint(\"🧪 Testing Local AI Reasoning on Sample Fraud Types\")\n\nfor i, sample in enumerate(sample_texts):\n    print(f\"\\n🎯 Test {i+1}: {sample['category']}\")\n    print(\"-\" * 50)\n    \n    result = analyze_with_local_reasoning(sample['text'])\n    print_analysis_result(result)\n\nprint(f\"\\n📊 Summary:\")\nprint(f\"Total Processed: {local_reasoning_engine.stats['total_processed']}\")\nprint(f\"Reasoning Generated: {local_reasoning_engine.stats['reasoning_generated']}\")\nprint(f\"Legitimate (Skipped): {local_reasoning_engine.stats['skipped_legitimate']}\")\n","metadata":{"vscode":{"languageId":"python"},"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:20:46.308715Z","iopub.execute_input":"2025-09-17T03:20:46.308899Z","iopub.status.idle":"2025-09-17T03:20:46.393452Z","shell.execute_reply.started":"2025-09-17T03:20:46.308884Z","shell.execute_reply":"2025-09-17T03:20:46.392695Z"}},"outputs":[{"name":"stdout","text":"🧪 Testing Local AI Reasoning on Sample Fraud Types\n\n🎯 Test 1: Phishing Attack\n--------------------------------------------------\n\n================================================================================\n🔍 LOCAL FRAUD DETECTION + REASONING ANALYSIS\n================================================================================\n\n📝 Original Text:\n   URGENT: Your PayPal account has been suspended due to suspicious activity. Click here immediately to verify your information and restore access: http://paypal-verification-secure.fraudsite.com\n\n🎯 Classification:\n   Label: sms_spam\n   Confidence: 72.69%\n\n📊 All Predictions:\n   sms_spam: 72.69%\n   phishing: 26.92%\n   legitimate: 0.20%\n   job_scam: 0.06%\n   refund_scam: 0.06%\n   popup_scam: 0.04%\n   ssn_scam: 0.01%\n   tech_support_scam: 0.01%\n   reward_scam: 0.01%\n\n🧠 Local AI Reasoning:\n   This text was classified as sms_spam with 72.7% confidence.\n   \n   Unwanted promotional or fraudulent text messages\n   \n   Key fraud indicators detected:\n   • urgent responses\n   • suspicious phone numbers\n   • urgent language to pressure victims\n   • requests for immediate action\n   \n   ⚠️ Risk: This could lead to unwanted charges and privacy violations.\n   Moderate confidence (72.7%) suggests probable fraud patterns.\n\n================================================================================\n\n🎯 Test 2: Tech Support Scam\n--------------------------------------------------\n\n================================================================================\n🔍 LOCAL FRAUD DETECTION + REASONING ANALYSIS\n================================================================================\n\n📝 Original Text:\n   WARNING: Your computer is infected with 5 viruses! Your files will be deleted in 24 hours. Call Microsoft Support immediately at 1-800-555-SCAM. Don't restart your computer or you'll lose everything!\n\n🎯 Classification:\n   Label: sms_spam\n   Confidence: 91.07%\n\n📊 All Predictions:\n   sms_spam: 91.07%\n   phishing: 4.55%\n   tech_support_scam: 2.54%\n   legitimate: 0.73%\n   popup_scam: 0.71%\n   refund_scam: 0.25%\n   job_scam: 0.12%\n   ssn_scam: 0.01%\n   reward_scam: 0.01%\n\n🧠 Local AI Reasoning:\n   This text was classified as sms_spam with 91.1% confidence.\n   \n   Unwanted promotional or fraudulent text messages\n   \n   Key fraud indicators detected:\n   • urgent language to pressure victims\n   • requests for immediate action\n   • suspicious contact information\n   \n   ⚠️ Risk: This could lead to unwanted charges and privacy violations.\n   \n   High confidence (91.1%) indicates strong fraud patterns.\n\n================================================================================\n\n🎯 Test 3: Reward Scam\n--------------------------------------------------\n\n================================================================================\n🔍 LOCAL FRAUD DETECTION + REASONING ANALYSIS\n================================================================================\n\n📝 Original Text:\n   🎉 CONGRATULATIONS! 🎉 You've been selected as our LUCKY WINNER for a $1000 Amazon gift card! You're one of only 3 winners today! Claim your prize now by clicking this link and entering your credit card info for verification. Hurry, expires in 1 hour!\n\n🎯 Classification:\n   Label: sms_spam\n   Confidence: 99.50%\n\n📊 All Predictions:\n   sms_spam: 99.50%\n   reward_scam: 0.24%\n   phishing: 0.21%\n   legitimate: 0.04%\n   job_scam: 0.00%\n   refund_scam: 0.00%\n   tech_support_scam: 0.00%\n   popup_scam: 0.00%\n   ssn_scam: 0.00%\n\n🧠 Local AI Reasoning:\n   This text was classified as sms_spam with 99.5% confidence.\n   \n   Unwanted promotional or fraudulent text messages\n   \n   Key fraud indicators detected:\n   • prize claims\n   • urgent language to pressure victims\n   • financial incentives or rewards\n   • requests for immediate action\n   \n   ⚠️ Risk: This could lead to unwanted charges and privacy violations.\n   \n   High confidence (99.5%) indicates strong fraud patterns.\n\n================================================================================\n\n🎯 Test 4: Job Scam\n--------------------------------------------------\n\n================================================================================\n🔍 LOCAL FRAUD DETECTION + REASONING ANALYSIS\n================================================================================\n\n📝 Original Text:\n   Amazing work from home opportunity! Earn $5000/week working just 2 hours per day! No experience required! Just send $99 registration fee and start earning today! Guaranteed income or money back!\n\n🎯 Classification:\n   Label: sms_spam\n   Confidence: 99.54%\n\n📊 All Predictions:\n   sms_spam: 99.54%\n   phishing: 0.18%\n   legitimate: 0.14%\n   job_scam: 0.10%\n   reward_scam: 0.01%\n   refund_scam: 0.01%\n   tech_support_scam: 0.01%\n   popup_scam: 0.01%\n   ssn_scam: 0.00%\n\n🧠 Local AI Reasoning:\n   This text was classified as sms_spam with 99.5% confidence.\n   \n   Unwanted promotional or fraudulent text messages\n   \n   Key fraud indicators detected:\n   • financial incentives or rewards\n   • requests for immediate action\n   • suspicious contact information\n   \n   ⚠️ Risk: This could lead to unwanted charges and privacy violations.\n   \n   High confidence (99.5%) indicates strong fraud patterns.\n\n================================================================================\n\n🎯 Test 5: SMS Spam\n--------------------------------------------------\n\n================================================================================\n🔍 LOCAL FRAUD DETECTION + REASONING ANALYSIS\n================================================================================\n\n📝 Original Text:\n   FREE iPhone 15 Pro! You have been randomly selected as a winner. Text CLAIM to 12345 or visit bit.ly/freeiphone15winner to get your prize. Message and data rates may apply. Text STOP to opt out.\n\n🎯 Classification:\n   Label: sms_spam\n   Confidence: 99.98%\n\n📊 All Predictions:\n   sms_spam: 99.98%\n   phishing: 0.01%\n   legitimate: 0.01%\n   job_scam: 0.00%\n   refund_scam: 0.00%\n   tech_support_scam: 0.00%\n   reward_scam: 0.00%\n   popup_scam: 0.00%\n   ssn_scam: 0.00%\n\n🧠 Local AI Reasoning:\n   This text was classified as sms_spam with 100.0% confidence.\n   \n   Unwanted promotional or fraudulent text messages\n   \n   Key fraud indicators detected:\n   • prize claims\n   • suspicious phone numbers\n   • financial incentives or rewards\n   • requests for immediate action\n   \n   ⚠️ Risk: This could lead to unwanted charges and privacy violations.\n   \n   High confidence (100.0%) indicates strong fraud patterns.\n\n================================================================================\n\n🎯 Test 6: Legitimate Message\n--------------------------------------------------\n\n================================================================================\n🔍 LOCAL FRAUD DETECTION + REASONING ANALYSIS\n================================================================================\n\n📝 Original Text:\n   Hi Sarah, thank you for your order #12345. Your package has been shipped and will arrive within 3-5 business days. You can track your shipment using the tracking number provided in your confirmation email. Have a great day!\n\n🎯 Classification:\n   Label: legitimate\n   Confidence: 99.03%\n\n📊 All Predictions:\n   legitimate: 99.03%\n   phishing: 0.90%\n   job_scam: 0.03%\n   refund_scam: 0.01%\n   sms_spam: 0.01%\n   reward_scam: 0.01%\n   tech_support_scam: 0.00%\n   ssn_scam: 0.00%\n   popup_scam: 0.00%\n\n⏭️  Reasoning Skipped: legitimate_classification\n\n================================================================================\n\n🎯 Test 7: SSN Scam\n--------------------------------------------------\n\n================================================================================\n🔍 LOCAL FRAUD DETECTION + REASONING ANALYSIS\n================================================================================\n\n📝 Original Text:\n   IMPORTANT NOTICE: Your Social Security Number has been suspended due to suspicious illegal activity. Call the SSA office immediately at 1-800-555-FAKE to verify your identity and reactivate your SSN. Failure to respond will result in arrest.\n\n🎯 Classification:\n   Label: sms_spam\n   Confidence: 79.28%\n\n📊 All Predictions:\n   sms_spam: 79.28%\n   phishing: 13.43%\n   ssn_scam: 4.30%\n   legitimate: 1.65%\n   refund_scam: 0.74%\n   job_scam: 0.40%\n   tech_support_scam: 0.11%\n   popup_scam: 0.07%\n   reward_scam: 0.03%\n\n🧠 Local AI Reasoning:\n   This text was classified as sms_spam with 79.3% confidence.\n   \n   Unwanted promotional or fraudulent text messages\n   \n   Key fraud indicators detected:\n   • suspicious phone numbers\n   • urgent language to pressure victims\n   • requests for immediate action\n   • suspicious contact information\n   \n   ⚠️ Risk: This could lead to unwanted charges and privacy violations.\n   Moderate confidence (79.3%) suggests probable fraud patterns.\n\n================================================================================\n\n📊 Summary:\nTotal Processed: 7\nReasoning Generated: 6\nLegitimate (Skipped): 1\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# 📝 Interactive Text Analysis\n\nEnter your own text below to analyze with the local fraud detection + reasoning system.","metadata":{}},{"cell_type":"code","source":"# Interactive Text Analysis\n# Change the text below to analyze your own messages!\n\nyour_text = \"Congratulations! You've won $1 million! Send your bank details to claim your prize!\"\n\n# Analyze your custom text\nprint(\"🔍 Analyzing Your Custom Text...\")\ncustom_result = analyze_with_local_reasoning(your_text.strip())\nprint_analysis_result(custom_result)","metadata":{"vscode":{"languageId":"python"},"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:20:46.394283Z","iopub.execute_input":"2025-09-17T03:20:46.394545Z","iopub.status.idle":"2025-09-17T03:20:46.408283Z","shell.execute_reply.started":"2025-09-17T03:20:46.394522Z","shell.execute_reply":"2025-09-17T03:20:46.407678Z"}},"outputs":[{"name":"stdout","text":"🔍 Analyzing Your Custom Text...\n\n================================================================================\n🔍 LOCAL FRAUD DETECTION + REASONING ANALYSIS\n================================================================================\n\n📝 Original Text:\n   Congratulations! You've won $1 million! Send your bank details to claim your prize!\n\n🎯 Classification:\n   Label: phishing\n   Confidence: 50.99%\n\n📊 All Predictions:\n   phishing: 50.99%\n   reward_scam: 46.17%\n   sms_spam: 2.20%\n   legitimate: 0.51%\n   job_scam: 0.06%\n   refund_scam: 0.04%\n   tech_support_scam: 0.01%\n   ssn_scam: 0.00%\n   popup_scam: 0.00%\n\n🧠 Local AI Reasoning:\n   This text was classified as phishing with 51.0% confidence.\n   \n   Attempts to steal sensitive information like passwords, credit card numbers, or personal data\n   \n   Key fraud indicators detected:\n   • financial incentives or rewards\n   • requests for immediate action\n   • suspicious contact information\n   \n   ⚠️ Risk: This could lead to identity theft and financial loss.\n\n================================================================================\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# 📊 Batch Processing - Analyze Multiple Texts\n\nUpload a CSV file or analyze multiple texts at once with local reasoning.","metadata":{}},{"cell_type":"code","source":"# Batch Processing with Local Reasoning\ndef batch_analyze_texts(texts, save_results=True):\n    \"\"\"Analyze multiple texts and generate local reasoning\"\"\"\n    results = []\n    \n    print(f\"🔄 Processing {len(texts)} texts...\")\n    \n    for i, text in enumerate(texts):\n        if i % 5 == 0:  # Only print every 5th item to reduce clutter\n            print(f\"Progress: {i+1}/{len(texts)}\")\n        \n        result = analyze_with_local_reasoning(text)\n        results.append(result)\n        \n        # Small delay to avoid overwhelming the local model\n        time.sleep(0.2)\n    \n    # Create summary DataFrame\n    df_results = pd.DataFrame([\n        {\n            'text': r['text'][:100] + '...' if len(r['text']) > 100 else r['text'],\n            'predicted_label': r['predicted_label'],\n            'confidence': r['confidence'],\n            'reasoning_generated': r['reasoning_generated'],\n            'reasoning': r['reasoning'][:200] + '...' if r['reasoning'] and len(r['reasoning']) > 200 else r['reasoning'],\n            'timestamp': r['timestamp']\n        }\n        for r in results\n    ])\n    \n    if save_results:\n        # Save results to CSV\n        output_file = f'fraud_analysis_results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n        df_results.to_csv(output_file, index=False)\n        print(f\"💾 Results saved to: {output_file}\")\n    \n    return results, df_results\n\n# Example batch processing\nbatch_texts = [\n    \"Your account will be closed unless you verify immediately!\",\n    \"Hi John, thanks for the great meeting today. Let's follow up next week.\",\n    \"You've won a free vacation! Call now to claim your prize!\",\n    \"Your package has been delivered to your front door.\",\n    \"URGENT: Your social security number has been compromised!\"\n]\n\nprint(\"📊 Batch Analysis with Local Reasoning\")\nbatch_results, batch_df = batch_analyze_texts(batch_texts)\n\nprint(\"\\n📈 Batch Analysis Summary:\")\nfraud_count = (batch_df['predicted_label'] != 'legitimate').sum()\nreasoning_count = batch_df['reasoning_generated'].sum()\nprint(f\"Fraud detected: {fraud_count}/{len(batch_df)}\")\nprint(f\"Reasoning generated: {reasoning_count}/{len(batch_df)}\")\n\n# Display sample results\ndisplay(batch_df.head())","metadata":{"vscode":{"languageId":"python"},"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:20:46.409176Z","iopub.execute_input":"2025-09-17T03:20:46.409436Z","iopub.status.idle":"2025-09-17T03:20:47.488112Z","shell.execute_reply.started":"2025-09-17T03:20:46.409421Z","shell.execute_reply":"2025-09-17T03:20:47.487538Z"}},"outputs":[{"name":"stdout","text":"📊 Batch Analysis with Local Reasoning\n🔄 Processing 5 texts...\nProgress: 1/5\n💾 Results saved to: fraud_analysis_results_20250917_032047.csv\n\n📈 Batch Analysis Summary:\nFraud detected: 4/5\nReasoning generated: 4/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                text predicted_label  \\\n0  Your account will be closed unless you verify ...        phishing   \n1  Hi John, thanks for the great meeting today. L...      legitimate   \n2  You've won a free vacation! Call now to claim ...        sms_spam   \n3  Your package has been delivered to your front ...        phishing   \n4  URGENT: Your social security number has been c...        phishing   \n\n   confidence  reasoning_generated  \\\n0    0.999425                 True   \n1    0.999687                False   \n2    0.999620                 True   \n3    0.991633                 True   \n4    0.990928                 True   \n\n                                           reasoning  \\\n0  This text was classified as phishing with 99.9...   \n1                                               None   \n2  This text was classified as sms_spam with 100....   \n3  This text was classified as phishing with 99.2...   \n4  This text was classified as phishing with 99.1...   \n\n                    timestamp  \n0  2025-09-17T03:20:46.424069  \n1  2025-09-17T03:20:46.633400  \n2  2025-09-17T03:20:46.843076  \n3  2025-09-17T03:20:47.052811  \n4  2025-09-17T03:20:47.262321  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>predicted_label</th>\n      <th>confidence</th>\n      <th>reasoning_generated</th>\n      <th>reasoning</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Your account will be closed unless you verify ...</td>\n      <td>phishing</td>\n      <td>0.999425</td>\n      <td>True</td>\n      <td>This text was classified as phishing with 99.9...</td>\n      <td>2025-09-17T03:20:46.424069</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hi John, thanks for the great meeting today. L...</td>\n      <td>legitimate</td>\n      <td>0.999687</td>\n      <td>False</td>\n      <td>None</td>\n      <td>2025-09-17T03:20:46.633400</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You've won a free vacation! Call now to claim ...</td>\n      <td>sms_spam</td>\n      <td>0.999620</td>\n      <td>True</td>\n      <td>This text was classified as sms_spam with 100....</td>\n      <td>2025-09-17T03:20:46.843076</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Your package has been delivered to your front ...</td>\n      <td>phishing</td>\n      <td>0.991633</td>\n      <td>True</td>\n      <td>This text was classified as phishing with 99.2...</td>\n      <td>2025-09-17T03:20:47.052811</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>URGENT: Your social security number has been c...</td>\n      <td>phishing</td>\n      <td>0.990928</td>\n      <td>True</td>\n      <td>This text was classified as phishing with 99.1...</td>\n      <td>2025-09-17T03:20:47.262321</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12}]}